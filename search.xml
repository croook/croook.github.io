<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[EfficientDet]]></title>
    <url>%2F2020%2F10%2F28%2FEfficientDet%2F</url>
    <content type="text"><![CDATA[EfficientNetEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks论文链接： https://arxiv.org/pdf/1905.11946.pdf官方源码： https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet第三方PyTorch源码： https://github.com/lukemelas/EfficientNet-PyTorch 简介 一般情况下通过扩大网络深度、宽度、分辨率（如Gpipe采用480*480的图像） 来提升模型精度。作者提出了一种compound scaling method ，综合考虑深度、宽度、分辨率。 Depth、Width、Resolution 一个卷积层$i$可以被定义为一个函数：$Y_i = F_i ( X_i )$，其中是$F_i$卷积操作，$Y_i$是输出的张量，$X_i$是输入的张量且张量的形状为$$。此外CNN通常被划分为多个阶段，每个阶段的所有层结构是相同的，比如ResNet中有五个阶段，每个阶段的所有层都具有相同的卷积类型，除了第一层执行下采样。因此一个神经网络N NN可以表示为其中$F_i^{L_i}$表示在第$i$个阶段的第$L_i$次重复的$F_i$层，$$是第$i$层输入的张量$X$形状。不同于之前普通的网络设计是集中在寻找更好的$F_i$层架构，模型缩放则是扩展网络长度、宽度和分辨率($H_i,W_i$）而不改变baseline网络中的$F_i$。为了进一步减少设计空间的大小，限制所有参数必须以恒定的比例均匀地缩放。目标是为了在给定资源限制时最大化模型精度，可以被定义为一个优化问题：其中$w,d,r$是对网络的宽度、深度和分辨率缩放的参数，$\hat{F_i},\hat{L_i},\hat{H_i},\hat{W_i},\hat{C_i}$是baseline网络中预先定义好的参数 通过增加宽度、深度、分辨率都可以一定程度上提升准确率。但是对于大型网络提升有限（ResNet 1000 和 ResNet 101准备率相似） 可以看到当精度达到80%左右时会饱和。 Compound scaling method $α,β,γ$是可以通过小型网格搜索确定的常量，而$ϕ$从直观上解释是是用户按照能够提供的额外计算资源开销（相对于baseline将网络扩展时需要额外计算资源）的多少来指定的参数。$α , β , γ$则是确定如何分别为网络宽度、深度和分辨率分配这些额外资源。 常规卷积运算的FLOPS与$d,w^2,r^2$成正比，例如将网络深度加倍会加倍FLOPS，而将网络宽度或者分辨率加倍会使得FLOPS大致增加四倍，因此用上述公式对网络进行缩放时，会使得总体FLOPS增加大约$(\alpha\cdot\beta^2\cdot\gamma^2)^ϕ$倍，在本文中，通过约束$ \alpha\cdot\beta^2\cdot\gamma^2\approx2$使得对任意的$\phi$整体的FLOPS将会增加$2^\phi$倍 EfficientNet Architecture首先作者使用MnasNet的方法，利用多目标神经网络架构搜索，同时优化准确率和FLOPS，得到了FLOPS为400M的baseline网络EfficientNet-B0，网络架构如下表 然后从这个baseline着手，使用两个步骤： STEP 1： 固定$\phi=1$，即假设有两倍以上的可用资源，并做一个小的网格搜索得到了最佳值$α = 1.2 , β = 1.1 , γ = 1.15$，在$\alpha\cdot\beta^2\cdot\gamma^2\approx2$的约束下。这样做的原因是因为在大模型上搜索成本太高了。 STEP 2： 固定$\alpha,\beta,\gamma$并使用不同的$\phi$对baseline网络进行扩展，得到了EfficientNet-B1到B7 结果 对MobileNet和ResNet采用这种方法进行网络扩展 在ImageNet上的模型参数量与精度对比图 在其它数据集上迁移学习的效果，在5个数据集上达到了SOTA，参数平均减少9.6倍。 可以看出复合缩放方法比任何单一效果都好 EfficientDet: Scalable and Efficient Object Detection代码 EfficientDet-D7 ：在 326B FLOPS，参数量 52 M的情况下，COCO 2017 validation 数据集上取得了 51.0 的 mAP，state-of-the-art 的结果。和 AmoebaNet + NAS-FPN 相比，FLOPS 仅为其十分之一的情况下取得了更好的结果 本文首先提出了两个挑战： efficient multi-scale feature fusion .之前的多尺度特征融合方式FPN、PANet、NAS_FPN等，在融合不同的输入特征时，只是不加区分地简单相加。但是，由于这些不同输入特征的分辨率不同，通常它们对融合后的输出特征的贡献不并相同。为了解决这个问题，本文提出双向加权特征金字塔网络（weighted bi-directional feature pyramid network (BiFPN) ），它使用了可学习的权重，来学习不同输入特征的贡献，并重复应用在自上而下和自下而上的多尺度特征融合中。 model scaling. 借助之前提出的EfficientNet网络，提出了应用在目标检测领域的compound scaling method。将EfficientNet的主干网络与BiFPN结合，提出了新的目标检测网络，EfficientDet，同时在语义分割领域也取得了更好的效果。 BiFPN FPN: NAS-FPN : 使用neural architecture search来搜索更好的跨尺度特征网络拓扑，但是在搜索过程中需要数千个GPU小时，并且网络是不规则的，难以解释或修改。 PANet: 在FPN基础上增加了额外的自下而上的网络融合路径。 三种方式中，PANet精度最高，但是参数和计算量最多。 本文提出的优化方法： 删除只有一个输入边的节点。理由是我们的目的是融合不同特征，而只有一个输入的节点没有进行特征融合，因此它的贡献较小。 如果原始输入节点和输出节点在同一层，那么增加一条额外的边，以便在不增加过多cost的情况下融合更多特征。 和PANet只有一条top-down和bottom-up路径不同，我们将每一条双向路径视为一个特征网络层，并通过将这个层重复多次来实现更高级别的特征融合。 Weighted Feature Fusion为了解决不同层特征贡献不同的问题，对于每一个输入都增加一个权重，让网络去学习不同输入特征的重要性。基于这个想法，提出了三种加权特征融合方式： Unbounded fusion ：$O=\sum_iw_i.I_i$，$w_i$是可学习的权重，形式可以是scalar(pre-feature)，vector(per-channel)，multi-dimensional tensor(per-pixel)，scalar可以取得和其他方法相近的精度，并有着最小的cost，但是scalar weight is unbounded，所以可能导致训练不稳定，因此，使用weight normalization来限定weight取值范围 Softmax-based fusion：$O=\sum_i\frac{e^{w_i}}{\sum_je^{w_j}}·I_i$，直观的想法是应用Softmax，将所有权重归一化到0~1，表示其重要性。但根据消融分析，额外的Softmax会导致GPU减速。 Fast normalization fusion：$O=\sum_i\frac{w_i}{\epsilon+\sum_jw_j}·I_i$，通过在每个$w_i$后加Relu层来保证$w_i\geq0$，同时$\epsilon=0.0001$来避免数值不稳定。这样值也会归一化，但因为没有Softmax层会更加高效。通过消融分析证明这种方法和基于Softmax的方法表现和精度相当，但在GPU上会快30%。 level6 for BiFPN shown in Figure 2(d)： EfficientDetEfficientDet Architecture Compound Scaling和EfficientNet不同的是，和分类模型相比目标检测有更多的scaling dimensions，所以在所有dimension上进行grid search代价过高。因此采用启发式scaling方法，但思想上仍然是联合放大所有维度。 Backbone network：和EfficientNet B0-B6使用相同的放大系数。 BiFPN network： Box/class prediction network：它的宽度和BiFPN保持一致（$W{pred}=W{bifpn}$）,深度线性增加：$D{box}=D{class}=3+\left \lfloor \phi/3 \right \rfloor$ Input image resolution：因为BiFPN使用了3-7层的特征，所以输入的分辨率需要能被$2^7=128$整除：$R_{input}=512+\phi·128$， 基于以上三个公式，拓展开发了EfficientDet D0-D7。 Ablation StudyDisentangling Backbone and BiFPN BiFPN CrossScale Connections Softmax vs Fast Normalized Fusion Compound Scaling]]></content>
      <categories>
        <category>AI</category>
        <category>CV</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测汇总]]></title>
    <url>%2F2020%2F10%2F16%2F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[目标检测（物体检测, Object Detection) 专知荟萃 入门学习 进阶文章 综述 Tutorial 视频教程 代码 领域专家 入门学习 图像目标检测（Object Detection）原理与实现 （1-6） [http://www.voidcn.com/article/p-xnjyqlkj-ua.html] [http://www.voidcn.com/article/p-ypylfzuk-ua.html] [http://www.voidcn.com/article/p-pfihszbt-ua.html] [http://www.voidcn.com/article/p-hcvjcaqy-ua.html] [http://www.voidcn.com/article/p-kjogyjfz-ua.html] [http://www.voidcn.com/article/p-zqfjjomb-u.html] . 基于特征共享的高效物体检测 Faster R-CNN和ResNet的作者任少卿 博士毕业论文 中文 [https://pan.baidu.com/s/1gfxTbNl] R-CNN：论文笔记 [http://www.cnblogs.com/kingstrong/p/4969472.html], [http://blog.gater.vip/articles/2015/11/02/1478607351098.html] Fast-RCNN: 深度学习物体检测（三）——FAST-RCNN： [http://www.itwendao.com/article/detail/374785.html] Fast-RCNN:[https://zhuanlan.zhihu.com/p/24780395] Faster-RCNN: [http://blog.csdn.net/zy1034092330/article/details/62044941] FPN: Feature Pyramid Networks for Object Detection 论文笔记： [http://blog.csdn.net/jesse_mx/article/details/54588085] CVPR 2017论文解读：特征金字塔网络FPN： [http://www.sohu.com/a/159780794_465975] FPN（feature pyramid networks）算法讲解： [http://blog.csdn.net/u014380165/article/details/72890275] R-FCN: 基于区域的全卷积网络来检测物体: [http://blog.csdn.net/shadow_guo/article/details/51767036] [译] 基于R-FCN的物体检测: [http://www.jianshu.com/p/db1b74770e52] SSD: Single Shot MultiBox Detector论文阅读： [http://blog.csdn.net/u010167269/article/details/52563573] 【深度学习：目标检测】RCNN学习笔记(10)：SSD:Single Shot MultiBox Detector： [http://blog.csdn.net/smf0504/article/details/52745070] 翻译SSD论文(Single Shot MultiBox Detector)，仅作交流： [http://blog.csdn.net/Ai_Smith/article/details/52997456?locationNum=2&amp;fps=1] CNN目标检测与分割（三）：SSD详解： [http://blog.csdn.net/zy1034092330/article/details/72862030] SSD关键源码解析： [https://zhuanlan.zhihu.com/p/25100992] YOLO: YOLO：实时快速目标检测： [https://zhuanlan.zhihu.com/p/25045711] YOLO详解: [https://zhuanlan.zhihu.com/p/25236464] YOLO升级版：YOLOv2和YOLO9000解析: [https://zhuanlan.zhihu.com/p/29816334] YOLO升级版：YOLOv2和YOLO9000解析： [https://zhuanlan.zhihu.com/p/29816334] YOLO v2之总结篇（linux+windows）： [http://blog.csdn.net/qq_14845119/article/details/53589282] YOLOv2 论文笔记： [http://blog.csdn.net/jesse_mx/article/details/53925356] DenseBox:余凯特邀报告：基于密集预测图的物体检测技术造就全球领先的ADAS系统 [http://mp.weixin.qq.com/s/9Z9mO3DJ7uPuirMAbPkDcw] PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection - [http://www.cnblogs.com/xueyuxiaolang/p/5959442.html] 深度学习论文笔记：DSSD - [http://jacobkong.github.io/posts/2938514597/] DSOD 复旦大学Ph.D沈志强：用于目标检测的DSOD模型（ICCV 2017） | 分享总结: [http://www.sohu.com/a/198226907_114877] 目标检测—DSOD: Learning Deeply Supervised Object Detectors from Scratch： [http://blog.csdn.net/zhangjunhit/article/details/77247695] Focal Loss: Focal Loss: [http://blog.csdn.net/u014380165/article/details/77019084] 读Focal Loss: [https://zhuanlan.zhihu.com/p/28873248] Soft-NMS: 一行代码改进NMS: [http://blog.csdn.net/shuzfan/article/details/71036040] OHEM: 论文笔记 OHEM: Training Region-based Object Detectors with Online Hard Example Mining: [http://blog.csdn.net/u012905422/article/details/52760669] Mask-RCNN 2017: Mask-RCNN 2017: [http://blog.csdn.net/inuchiyo_china/article/details/70860939] 目标检测分割—Mask R-CNN: [http://blog.csdn.net/zhangjunhit/article/details/64920075?locationNum=6&amp;fps=1] 解读|Facebook 何凯明发大招：Mask R-CNN 狙击目标实例分割: [http://www.sohu.com/a/130676187_642762] 目标检测之比较 目标检测之RCNN，SPP-NET，Fast-RCNN，Faster-RCNN： [http://lanbing510.info/2017/08/24/RCNN-FastRCNN-FasterRCNN.html] RCNN, Fast-RCNN, Faster-RCNN的一些事： [http://closure11.com/rcnn-fast-rcnn-faster-rcnn%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/] 机器视觉目标检测补习贴之R-CNN系列 — R-CNN, Fast R-CNN, Faster R-CNN ， 目标检测补习贴之YOLO实时检测, You only look once ： [http://nooverfit.com/wp/] 目标检测算法：RCNN、YOLO vs DPM： [https://juejin.im/entry/59564e1f6fb9a06b9c7408f9] 如何评价rcnn、fast-rcnn和faster-rcnn这一系列方法？: [https://www.zhihu.com/question/35887527] 视觉目标检测和识别之过去，现在及可能 [https://zhuanlan.zhihu.com/p/27546796] 进阶文章 Deep Neural Networks for Object Detection （基于DNN的对象检测）NIPS2013: [https://cis.temple.edu/~yuhong/teach/2014_spring/papers/NIPS2013_DNN_OD.pdf] R-CNN Rich feature hierarchies for accurate object detection and semantic segmentation: [https://arxiv.org/abs/1311.2524] Fast R-CNN : [http://arxiv.org/abs/1504.08083] Faster R-CNN Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks: [http://arxiv.org/abs/1506.01497] Scalable Object Detection using Deep Neural Networks [http://arxiv.org/abs/1312.2249] Scalable, High-Quality Object Detection [http://arxiv.org/abs/1412.1441] SPP-Net Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition [http://arxiv.org/abs/1406.4729] DeepID-Net DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection [http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html] Object Detectors Emerge in Deep Scene CNNs [http://arxiv.org/abs/1412.6856] segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection [https://arxiv.org/abs/1502.04275] Object Detection Networks on Convolutional Feature Maps [http://arxiv.org/abs/1504.06066] Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction [http://arxiv.org/abs/1504.03293] DeepBox: Learning Objectness with Convolutional Networks [http://arxiv.org/abs/1504.03293] Object detection via a multi-region &amp; semantic segmentation-aware CNN model [http://arxiv.org/abs/1505.01749] You Only Look Once: Unified, Real-Time Object Detection [http://arxiv.org/abs/1506.02640] YOLOv2 YOLO9000: Better, Faster, Stronger [https://arxiv.org/abs/1612.08242] AttentionNet: Aggregating Weak Directions for Accurate Object Detection [http://arxiv.org/abs/1506.07704] DenseBox: Unifying Landmark Localization with End to End Object Detection [http://arxiv.org/abs/1509.04874] SSD: Single Shot MultiBox Detector [http://arxiv.org/abs/1512.02325] DSSD : Deconvolutional Single Shot Detector [https://arxiv.org/abs/1701.06659] G-CNN: an Iterative Grid Based Object Detector [http://arxiv.org/abs/1512.07729] HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection [http://arxiv.org/abs/1604.00600] A MultiPath Network for Object Detection [http://arxiv.org/abs/1604.02135] R-FCN: Object Detection via Region-based Fully Convolutional Networks [http://arxiv.org/abs/1605.06409] A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection [http://arxiv.org/abs/1607.07155] PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection [http://arxiv.org/abs/1608.08021] Feature Pyramid Networks for Object Detection [https://arxiv.org/abs/1612.03144] Learning Chained Deep Features and Classifiers for Cascade in Object Detection [https://arxiv.org/abs/1702.07054] DSOD: Learning Deeply Supervised Object Detectors from Scratch [https://arxiv.org/abs/1708.01241] Focal Loss for Dense Object Detection ICCV 2017 Best student paper award. Facebook AI Research [https://arxiv.org/abs/1708.02002] Mask-RCNN 2017 ICCV 2017 Best paper award. Facebook AI Research http://arxiv.org/abs/1703.06870 综述 深度学习之 “物体检测” 方法梳理 [http://zhwhong.ml/2017/02/24/Detection-CNN/] 地平线黄李超开讲：深度学习和物体检测！： [http://www.sohu.com/a/163460329_642762] 对话CVPR2016：目标检测新进展： [https://zhuanlan.zhihu.com/p/21533724] 基于深度学习的目标检测技术演进：R-CNN、Fast R-CNN、Faster R-CNN： [http://www.cnblogs.com/skyfsm/p/6806246.html] 基于深度学习的目标检测研究进展 [https://mp.weixin.qq.com/s/RxogMJ86FkQHrzaF4SxFNQ] 讲堂干货No.1｜山世光－基于深度学习的目标检测技术进展与展望 [https://mp.weixin.qq.com/s/NV2hWofOCractLt45-wI1A] Tutorial CVPR’17 Tutorial Deep Learning for Objects and Scenes by Kaiming He Ross Girshick [http://deeplearning.csail.mit.edu/] ICCV 2015 Tools for Efficient Object Detection [http://mp7.watson.ibm.com/ICCV2015/ObjectDetectionICCV2015.html] Object Detection [http://class.inrialpes.fr/tutorials/triggs-icvss1.pdf] Image Recognition and Object Detection : Part 1 [https://www.learnopencv.com/image-recognition-and-object-detection-part1/] R-CNN for Object Detection [https://courses.cs.washington.edu/courses/cse590v/14au/cse590v_wk1_rcnn.pdf\] 视频教程 cs231 第11讲 Detection and Segmentation PPT ：[http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf\] 视频：[https://www.youtube.com/watch?v=nDPWywWRIRo&amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv] Deep Learning for Instance-level Object Understanding by Ross Girshick. PPT：[http://deeplearning.csail.mit.edu/instance_ross.pdf\] 视频：[https://youtu.be/jHv37mKAhV4?t=2349] 代码 R-CNN [https://github.com/rbgirshick/rcnn] Fast R-CNN: [https://github.com/rbgirshick/fast-rcnn] github(“Fast R-CNN in MXNet”): https://github.com/precedenceguo/mx-rcnn github: https://github.com/mahyarnajibi/fast-rcnn-torch github: https://github.com/apple2373/chainer-simple-fast-rnn github: https://github.com/zplizzi/tensorflow-fast-rcnn Faster R-CNN github(official, Matlab): https://github.com/ShaoqingRen/faster_rcnn github: https://github.com/rbgirshick/py-faster-rcnn github: https://github.com/mitmul/chainer-faster-rcnn github: https://github.com/andreaskoepf/faster-rcnn.torch github: https://github.com/ruotianluo/Faster-RCNN-Densecap-torch github: https://github.com/smallcorgi/Faster-RCNN_TF github: https://github.com/CharlesShang/TFFRCNN github(C++ demo): https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus github: https://github.com/yhenon/keras-frcnn SPP-Net [https://github.com/ShaoqingRen/SPP_net\] YOLO github: https://github.com/gliese581gg/YOLO_tensorflow github: https://github.com/xingwangsfu/caffe-yolo github: https://github.com/frankzhangrui/Darknet-Yolo github: https://github.com/BriSkyHekun/py-darknet-yolo github: https://github.com/tommy-qichang/yolo.torch github: https://github.com/frischzenger/yolo-windows github: https://github.com/AlexeyAB/yolo-windows github: https://github.com/nilboy/tensorflow-yolo YOLOv2 github(Chainer): https://github.com/leetenki/YOLOv2 github(Keras): https://github.com/allanzelener/YAD2K github(PyTorch): https://github.com/longcw/yolo2-pytorch github(Tensorflow): https://github.com/hizhangp/yolo_tensorflow github(Windows): https://github.com/AlexeyAB/darknet github: https://github.com/choasUp/caffe-yolo9000 github: https://github.com/philipperemy/yolo-9000 SSD github: https://github.com/zhreshold/mxnet-ssd github: https://github.com/zhreshold/mxnet-ssd.cpp github: https://github.com/rykov8/ssd_keras github: https://github.com/balancap/SSD-Tensorflow github: https://github.com/amdegroot/ssd.pytorch github(Caffe): https://github.com/chuanqi305/MobileNet-SSD Recurrent Scale Approximation for Object Detection in CNN [https://github.com/sciencefans/RSA-for-object-detection] Mask-RCNN 2017 Keras [https://github.com/matterport/Mask_RCNN\] TensorFlow [https://github.com/CharlesShang/FastMaskRCNN] Pytorch [https://github.com/felixgwu/mask_rcnn_pytorch\] caffe [https://github.com/jasjeetIM/Mask-RCNN] MXNet [https://github.com/TuSimple/mx-maskrcnn] 领域专家 Ross Girshick (rbg 大神) [http://www.rossgirshick.info/] Kaiming He, Facebook人工智能实验室科学家Kaiming He [http://kaiminghe.com/] Shaoqing Ren [http://shaoqingren.com/] Jian Sun [http://www.jiansun.org/] phd，zdz]]></content>
      <categories>
        <category>AI</category>
        <category>CV</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测五]]></title>
    <url>%2F2020%2F10%2F16%2F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BA%94%2F</url>
    <content type="text"><![CDATA[目标检测五SSDSSD，全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测算法，截至目前是主要的检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势（不过已经被CVPR 2017的YOLO9000超越）。 论文链接：https://arxiv.org/abs/1512.02325 论文翻译：https://blog.csdn.net/denghecsdn/article/details/77429978 论文详解：https://blog.csdn.net/WZZ18191171661/article/details/79444217 论文代码：https://github.com/balancap/SSD-Tensorflow 项目参考：https://blog.csdn.net/zzz_cming/article/details/81128460 参考：https://zhuanlan.zhihu.com/p/33544892 参考：https://zhuanlan.zhihu.com/p/31427288 SSD具有如下主要特点： 从YOLO中继承了将detection转化为regression的思路，一次完成目标定位与分类 基于Faster RCNN中的Anchor，提出了相似的Prior box； 加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，即在不同感受野的feature map上预测目标（FPN思路） 网络结构 算法步骤 输入一幅图片（300x300），将其输入到预训练好的分类网络中来获得不同大小的特征映射，修改了传统的VGG16网络； 将VGG16的FC6和FC7层转化为卷积层，如图1上的Conv6和Conv7； 去掉所有的Dropout层和FC8层； 添加了Atrous算法（hole算法）； 将Pool5从2x2-S2变换到3x3-S1； 抽取Conv4_3、Conv7、Conv8_2、Conv9_2、Conv10_2、Conv11_2层的feature map，然后分别在这些feature map层上面的每一个点构造6个不同尺度大小的bbox，然后分别进行检测和分类，生成多个bbox，如图2所示； 将不同feature map获得的bbox结合起来，经过NMS（非极大值抑制）方法来抑制掉一部分重叠或者不正确的bbox，生成最终的bbox集合（即检测结果）； Prior box 如上图所示，在特征图的每个位置预测K个bbox，对于每一个bbox，预测C个类别得分，以及相对于Prior box(Default box)的4个偏移量值，这样总共需要 (C+4)×K个预测器，则在m×n的feature map上面将会产生 (C+4)×K×m×n个预测值 对于每个单元的每个先验框，其都输出一套独立的检测值，对应一个边界框，主要分为两个部分。第一部分是各个类别的置信度或者评分，值得注意的是SSD将背景也当做了一个特殊的类别，如果检测目标共有 $c$ 个类别，SSD其实需要预测 $c+1$ 个置信度值，其中第一个置信度指的是不含目标或者属于背景的评分。后面当我们说 $c$ 个类别置信度时，请记住里面包含背景那个特殊的类别，即真实的检测类别只有 $c-1$ 个。在预测过程中，置信度最高的那个类别就是边界框所属的类别，特别地，当第一个置信度值最高时，表示边界框中并不包含目标 作者认为仅仅靠同一层上的多个anchor来回归，还远远不够。因为有很大可能这层上所有anchor的IOU都比较小，就是说所有anchor离ground truth都比较远，用这种anchor来训练误差会很大。 SSD中的Defalut box和Faster-rcnn中的anchor机制很相似。就是预设一些目标预选框，后续通过softmax分类+bounding box regression获得真实目标的位置。对于不同尺度的feature map 上使用不同的Default boxes。如上图所示，我们选取的feature map包括38x38x512、19x19x1024、10x10x512、5x5x256、3x3x256、1x1x256，Conv4_3之后的feature map默认的box是4个，我们在38x38的这个平面上的每一点上面获得4个box，那么我们总共可以获得38x38x4=5776个；同理，我们依次将FC7、Conv8_2、Conv9_2、Conv10_2和Conv11_2的box数量设置为6、6、6、4、4，那么我们可以获得的box分别为2166、600、150、36、4，即我们总共可以获得8732个box，然后我们将这些box送入NMS模块中，获得最终的检测结果。 Prior box生成规则 以feature map上每个点的中点为中心（offset=0.5），生成一系列同心的Defalut box（然后中心点的坐标会乘以step，相当于从feature map位置映射回原图位置） 正方形prior box最小边长为$min_size$，最大边长为$\sqrt{min_size*max_size}$ 每一个aspect radio会生成两个长方形，使用不同的ratio值，[1, 2, 3, 1/2, 1/3]，长宽为$\sqrt{aspect_radio}min_size$和$\frac{1}{\sqrt{aspect_radio}}min_size$ 使用m(SSD300中m=6)个不同大小的feature map 来做预测，最底层的 feature map 的 scale 值为 Smin=0.2，最高层的为Smax=0.9，其他层通过下面的公式计算得到： 第一层feature map对应的min_size=S1*300，max_size=S2*300；第二层min_size=S2*300，max_size=S3*300；其他类推。在原文中，Smin=0.2，Smax=0.9，但是在SSD 300中prior box设置并不能和paper中上述公式对应： 而对于ratio=0的情况，指定的scale如下所示，即总共有 6 中不同的 default box。 SSD使用低层feature map检测小目标，使用高层feature map检测大目标 先验框匹配在训练过程中，首先要确定训练图片中的ground truth（真实目标）与哪个先验框来进行匹配，与之匹配的先验框所对应的边界框将负责预测它。在Yolo中，ground truth的中心落在哪个单元格，该单元格中与其IOU最大的边界框负责预测它。但是在SSD中却完全不一样，SSD的先验框与ground truth的匹配原则主要有两点。首先，对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配，这样，可以保证每个ground truth一定与某个先验框匹配。通常称与ground truth匹配的先验框为正样本（其实应该是先验框对应的预测box，不过由于是一一对应的就这样称呼了），反之，若一个先验框没有与任何ground truth进行匹配，那么该先验框只能与背景匹配，就是负样本。一个图片中ground truth是非常少的， 而先验框却很多，如果仅按第一个原则匹配，很多先验框会是负样本，正负样本极其不平衡，所以需要第二个原则。第二个原则是：对于剩余的未匹配先验框，若某个ground truth的 $IOU$ 大于某个阈值（一般是0.5），那么该先验框也与这个ground truth进行匹配。这意味着某个ground truth可能与多个先验框匹配，这是可以的。但是反过来却不可以，因为一个先验框只能匹配一个ground truth，如果多个ground truth与某个先验框 $IOU$大于阈值，那么先验框只与IOU最大的那个ground truth进行匹配。第二个原则一定在第一个原则之后进行，仔细考虑一下这种情况，如果某个ground truth所对应最大 $IOU$小于阈值，并且所匹配的先验框却与另外一个ground truth的 $IOU$大于阈值，那么该先验框应该匹配谁，答案应该是前者，首先要确保某个ground truth一定有一个先验框与之匹配。但是，这种情况我觉得基本上是不存在的。由于先验框很多，某个ground truth的最大 $IOU$肯定大于阈值，所以可能只实施第二个原则既可以了，这里的TensorFlow版本就是只实施了第二个原则，但是这里的Pytorch两个原则都实施了。图8为一个匹配示意图，其中绿色的GT是ground truth，红色为先验框，FP表示负样本，TP表示正样本。 尽管一个ground truth可以与多个先验框匹配，但是ground truth相对先验框还是太少了，所以负样本相对正样本会很多。为了保证正负样本尽量平衡，SSD采用了hard negative mining，就是对负样本进行抽样，抽样时按照置信度误差（预测背景的置信度越小，误差越大）进行降序排列，选取误差的较大的top-k作为训练的负样本，以保证正负样本比例接近1:3。 预测过程预测过程比较简单，对于每个预测框，首先根据类别置信度确定其类别（置信度最大者）与置信度值，并过滤掉属于背景的预测框。然后根据置信度阈值（如0.5）过滤掉阈值较低的预测框。对于留下的预测框进行解码，根据先验框得到其真实的位置参数（解码后一般还需要做clip，防止预测框位置超出图片）。解码之后，一般需要根据置信度进行降序排列，然后仅保留top-k（如400）个预测框。最后就是进行NMS算法，过滤掉那些重叠度较大的预测框。最后剩余的预测框就是检测结果了。 训练技巧数据增强 SSD训练过程中使用的数据增强对网络性能影响很大，大约有6.7%的mAP提升。 随机剪裁：采样一个片段，使剪裁部分与目标重叠分别为0.1, 0.3, 0.5, 0.7, 0.9，剪裁完resize到固定尺寸。 以0.5的概率随机水平翻转。 conv4_3检测基础网络部分特征图分辨率高，原图中信息更完整，感受野较小，可以用来检测图像中的小目标，这也是SSD相对于YOLO检测小目标的优势所在。增加对基础网络conv4_3的特征图的检测可以使mAP提升4%。 长方形默认框挑选合适形状的默认框能够提高检测效果。作者实验得出使用瘦高与宽扁默认框相对于只使用正方形默认框有2.9%mAP提升。 使用atrous卷积 通常卷积过程中为了使特征图尺寸特征图尺寸保持不变，通过会在边缘打padding，但人为加入的padding值会引入噪声，因此，使用atrous卷积能够在保持感受野不变的条件下，减少padding噪声，关于atrous参考。本文SSD训练过程中并且没有使用atrous卷积，但预训练过程使用的模型为VGG-16-atrous，意味着作者给的预训练模型是使用atrous卷积训练出来的。使用atrous版本VGG-16作为预训模型比较普通VGG-16要提高0.7%mAP。 Lossloss函数分为两部分：计算相应的default box与目标类别的confidence loss以及相应的位置回归。 其中N先验框的正样本数量， 这里 $x^p{ij}\in{1,0}$ 为一个指示参数，当 $x^p{ij}=1$ 时表示第 $i$个先验框与第 $j$个ground truth匹配，并且ground truth的类别为$j$。 !$c$为类别置信度预测值。$l$为先验框的所对应边界框的位置预测值，而$g$是ground truth的位置参数 ；而alpha参数用于调整confidence loss和location loss之间的比例，默认alpha=1。 位置回归则是采用 Smooth L1 loss，loss函数为: 由于 $x_{ij}^p$ 的存在，所以位置误差仅针对正样本进行计算。值得注意的是，要先对ground truth的$g$进行编码得到 $\hat{g}$ ，因为预测值$l$也是编码值，若设置variance_encoded_in_target=True，编码时要加上variance： confidence loss是典型的softmax loss： Retina NET代码地址：https://github.com/facebookresearch/Detectron 论文地址：https://arxiv.org/abs/1708.02002 Focal loss主要贡献为提出了Focal Loss， 解决了one-stage算法中正负样本的比例严重失衡的问题，不需要改变网络结构 。 当样本不均衡的时候，如负样本很大，而且很多都是容易分类的（置信度很高的）,这样模型的优化方向就不是我们想要的方向，我是想让正负样本分开的，所以我们要把很多的注意力放在困难、难分类的样本上，所以作者在标准交叉熵损失的基础上进行了改进，首先我们把交叉熵二分类loss定义为： 然后 $y\in{-1,1}$表示正负样本的标签，$p$ 表示模型预测 $y=1$的概率，所以我们定义$p_t$ 如下： 然后我们重写交叉熵损失为 首先我们要解决样本不平衡的问题，我们使用一个平衡因子 $\alpha_t$ ,其范围是0到1，对于类别1乘以$\alpha_t$ ,而对于类别-1乘以$1-\alpha_t$ ，然后我们把损失函数重写为： 虽然上面的方法使得可以调节正负样本对loss的贡献度，但是我们希望那些容易分的样本（置信度高的）提供的loss小一些，而那些难分的样本提供的loss几乎不变化，让分类器优化的方向更关注那些难分的样本。 假如有这么一个样本，且 $\gamma=2$时，如果其$p_t=0.9$ 时，FL loss会比原来的CE loss小100多倍，如果其 $p_t=0.968$ ，那就会小1000多倍。 最后我们把完整版的loss函数写下来，为： 本文中，将$\gamma$定义为2时效果最好！ 可以看出，蓝色的线为CE loss, 随着$\gamma$ 的增加，那些容易分类的样本所贡献的loss就越小，所以可以使模型的优化方向更加关注那些难分类的样本，这样就可以提高模型的精度，同时兼顾了速度。]]></content>
      <categories>
        <category>AI</category>
        <category>CV</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测四]]></title>
    <url>%2F2020%2F10%2F16%2F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[目标检测四YOLO v1参考：https://zhuanlan.zhihu.com/p/32525231 参考：https://zhuanlan.zhihu.com/p/31427164 yolo (you only look once)。 Yolo算法采用一个单独的CNN模型实现end-to-end的目标检测 ，整个系统如下图所示：首先将输入图片resize到448x448，然后送入CNN网络，最后处理网络预测结果得到检测的目标。相比R-CNN算法，其是一个统一的框架，其速度更快，而且Yolo的训练过程也是end-to-end的。 原理YOLO将输入图像分成SxS个格子，每个格子负责检测‘落入’该格子的物体。 每个格子输出B个bounding box（包含物体的矩形区域）信息，以及C个物体属于某种类别的概率信息。 YOLO的bounding box并不是Faster RCNN的Anchor 。Faster RCNN等一些算法采用每个grid中手工设置n个Anchor（先验框，预先设置好位置的bounding box）的设计，每个Anchor有不同的大小和宽高比。YOLO的bounding box看起来很像一个grid中2个Anchor，但它们不是。YOLO并没有预先设置2个bounding box的大小和形状，也没有对每个bounding box分别输出一个对象的预测。它的意思仅仅是对一个对象预测出2个bounding box，选择预测得相对比较准的那个。 Bounding box信息包含5个数据值，分别是x,y,w,h,和confidence。其中x,y是指当前格子预测得到的物体的bounding box的中心位置的坐标。w,h是bounding box的宽度和高度。 x,y 是相对于每个单元格左上角坐标点的偏移值，并且单位是相对于单元格大小的，被归一化到[0,1]。注意：实际训练过程中，w和h的值使用图像的宽度和高度进行归一化到[0,1]区间内。 confidence反映当前bounding box是否包含物体以及物体位置的准确性。前者记为$Pr(object)$ ，当该边界框是背景时（即不包含目标），此时$Pr(object)=0$。而当该边界框包含目标时 $Pr(object=1)$。边界框的准确度可以用预测框与实际框（ground truth）的IOU（intersection over union，交并比）来表征，记为 $IOU^{truth}_{pred}$ 。因此置信度可以定义为 $Pr(object)=0$。 每个单元格需要预测$(B5+C)$个值。如果将输入图片划分为$S S$ 网格，那么最终预测值为$S×S×(B*5+C)$大小的张量。整个模型的预测值结构如下图所示。对于PASCAL VOC数据，其共有20个类别，如果使用$S=7，B=2$ ，那么最终的预测结果就是$7×7×30$大小的张量。 网络结构Yolo采用卷积网络来提取特征，然后使用全连接层来得到预测值。网络结构参考GooLeNet模型，包含24个卷积层和2个全连接层，如图8所示。对于卷积层，主要使用1x1卷积来做channle reduction，然后紧跟3x3卷积。对于卷积层和全连接层，采用Leaky ReLU激活函数：$max(x,0.1x)$。但是最后一层采用线性激活函数。 网络训练在训练之前，先在ImageNet上进行了预训练，其预训练的分类模型采用上图前20个卷积层，然后添加一个average-pool层和全连接层。预训练之后，在预训练得到的20层卷积层之上加上随机初始化的4个卷积层和2个全连接层。由于检测任务一般需要更高清的图片，所以将网络的输入从224x224增加到了448x448。整个网络的流程如下图所示： 在test的时候，每个网格预测的class信息和bounding box预测的confidence信息相乘，就得到每个bounding box的class-specific confidence score: 等式左边第一项就是每个网格预测的类别信息，第二三项就是每个bounding box预测的confidence。这个乘积即encode了预测的box属于某一类的概率，也有该box准确度的信息。 得到每个box的class-specific confidence score以后，设置阈值，滤掉得分低的boxes，对保留的boxes进行NMS处理，就得到最终的检测结果。 损失函数下面是训练损失函数的分析，Yolo算法将目标检测看成回归问题，所以采用的是均方差损失函数。 其中，coordError、iouError和classError分别代表预测数据与标定数据之间的坐标误差、IOU误差和分类误差。 首先区分定位误差和分类误差，位置相关误差（坐标、IOU）与分类误差对网络loss的贡献值是不同的：对于定位误差，即边界框坐标预测误差，采用较大的权重$\lambda_{coord}=5$ 。 然后其区分不包含目标的边界框与含有目标的边界框的置信度，对于前者，采用较小的权重值$ λ {noobj}=0.5$ 。其它权重值均设为1。这是因为在计算IOU误差时，包含物体的格子与不包含物体的格子，二者的IOU误差对网络loss的贡献值是不同的。若采用相同的权值，那么不包含物体的格子的confidence值近似为0，变相放大了包含物体的格子的confidence误差在计算网络参数梯度时的影响。为解决这个问题，YOLO 使用$λ{noobj} = 0.5$修正iouError。（注此处的‘包含’是指存在一个物体，它的中心坐标落入到格子内）。 然后采用均方误差，其同等对待大小不同的边界框，但是实际上较小的边界框的坐标误差应该要比较大的边界框要更敏感。为了保证这一点，将网络的边界框的宽与高预测改为对其平方根的预测，即预测值变为$(x,y,\sqrt{w},\sqrt{h})$。 另外一点是，由于每个单元格预测多个边界框。但是其对应类别只有一个。那么在训练时，如果该单元格内确实存在目标，那么只选择与ground truth的IOU最大的那个边界框来负责预测该目标，而其它边界框认为不存在目标。这样设置的一个结果将会使一个单元格对应的边界框更加专业化，其可以分别适用不同大小，不同高宽比的目标，从而提升模型性能。大家可能会想如果一个单元格内存在多个目标怎么办，其实这时候Yolo算法就只能选择其中一个来训练，这也是Yolo算法的缺点之一。要注意的一点时，对于不存在对应目标的边界框，其误差项就是只有置信度，坐标项误差是没法计算的。而只有当一个单元格内确实存在目标时，才计算分类误差项，否则该项也是无法计算的。 其中第一项是边界框中心坐标的误差项，$1^{obj}{ij}$ 指的是第$i$个单元格存在目标，且该单元格中的第$j$个边界框负责预测该目标。第二项是边界框的高与宽的误差项。第三项是包含目标的边界框的置信度误差项。第四项是不包含目标的边界框的置信度误差项。而最后一项是包含目标的单元格的分类误差项， $1^{obj}{i}$ 指的是第 $i$个单元格存在目标。这里特别说一下置信度的target值$Ci$ ，如果是不存在目标，此时由于$Pr{object}=0$，那么 $Ci=0$。如果存在目标$Pr{object}=1$， ，此时需要确定 $IOU^{truth}_{pred}$，当然你希望最好的话，可以将IOU取1，这样$C_i$=1，但是在YOLO实现中，使用了一个控制参数rescore（默认为1），当其为1时，IOU不是设置为1，而就是计算truth和pred之间的真实IOU。不过很多复现YOLO的项目还是取 $C_i=1$，这个差异应该不会太影响结果吧。 性能 Yolo的Correct的是低于Fast R-CNN。另外Yolo的Localization误差偏高，即定位不是很准确。但是Yolo的Background误差很低，说明其对背景的误判率较低。 优点：Yolo采用一个CNN网络来实现检测，是单管道策略，其训练与预测都是end-to-end，所以Yolo算法比较简洁且速度快。第二点由于Yolo是对整张图片做卷积，所以其在检测目标有更大的视野，它不容易对背景误判。其实我觉得全连接层也是对这个有贡献的，因为全连接起到了attention的作用。另外，Yolo的泛化能力强，在做迁移时，模型鲁棒性高。 缺点：最后不得不谈一下Yolo的缺点，首先Yolo各个单元格仅仅预测两个边界框，而且属于一个类别。对于小物体，Yolo的表现会不如人意。这方面的改进可以看SSD，其采用多尺度单元格。也可以看Faster R-CNN，其采用了anchor boxes。Yolo对于在物体的宽高比方面泛化率低，就是无法定位不寻常比例的物体。当然Yolo的定位不准确也是很大的问题。]]></content>
      <categories>
        <category>AI</category>
        <category>CV</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测三]]></title>
    <url>%2F2020%2F10%2F15%2F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%89%2F</url>
    <content type="text"><![CDATA[目标检测三参考：https://www.cnblogs.com/skyfsm/p/6806246.html Fast R-CNN原理论文地址： Fast R-CNN 代码地址： 代码地址：rbgirshick/fast-rcnn 相对于R-CNN，Fast R-CNN主要有三点改进： 提出了RoIPooling，避免了对提取的region proposals进行缩放到224x224，然后经过pre-trained CNN进行检测的步骤，加速了整个网络的learning与inference过程，这个是巨大的改进，并且RoIPooling是可导的，因此使得整个网络可以实现end-to-end learning，这个可以认为是Fast R-CNN相对于R-CNN最大的改进之处。将R-CNN中三个模块(CNN, SVM, Regression)整合, 极大了减少了计算量和加快了速度 采用了Multi-task loss进行边框回归，这个在R-CNN中也有这方面的实验。 利用了截断的奇异值分解（Truncated SVD for faster detection）加速了网络。 网络结构 流程图 步骤 预训练一个分类CNN 修改CNN, 将最后一个flatten层以及后面的层删掉, 换成ROI Pooling层 将图像经过CNN, 得到特征图, 使用selective search选出2k个候选区域 在ROI Pooling层后跟几个FC, 最后输出2个分支: 第一个分支是softmax层, 输出k+1个分类 第二个分支是regression, 预测输出k个类别的box参数 Multi-task LossR-CNN中在获取到最终的CNN特征后先采用SVM进行类别判断，再进行bounding-box的回归得到位置信息。整个过程是个串行的流程。这极大地影响了网络的检测速度。Fast R-CNN中则将Classification和regression的任务合二为一，变成一个multi-task的模型，实现了特征的共享与速度的进一步提升。 使用Smooth L1的优点： 0点可导 loss减小时，梯度随之下降，有助于收敛 ROI PoolingFast R-CNN中借鉴了SPP-Net的金字塔池化思想，在此基础上进行改进。 将sppnet中多尺度的池化简化为单尺度，只输出固定尺寸为（w, h）的feature map。 ROI Pooling时，将输入的h w大小的feature map分割成H W大小的子窗口（每个子窗口的大小约为h/H，w/W，其中H、W为超参数，如设定为7 x 7），对每个子窗口进行max-pooling操作，得到固定输出大小的feature map。而后进行后续的全连接层操作。 ROI Pooling的实现可以参考github上Caffe版本的代码：roi_pooling_layer.cpp Faster R-CNN代码地址：https://github.com/rbgirshick/py-faster-rcnn 血细胞检测 由于Fast R-CNN仍然采用ss产生候选框，非常耗时，Faster R-CNN提出使用神经网络来产生候选框， Region Proposal Network(RPN) 。 网络结构 1）卷积层(conv layers)，用于提取图片的特征，输入为整张图片，输出为提取出的特征称为feature maps2）RPN网络(Region Proposal Network)，用于推荐候选区域，这个网络是用来代替之前的search selective的。输入为图片为featrue maps，输出为多个候选区域。3）RoI pooling，和Fast R-CNN一样，将不同大小的输入转换为固定长度的输出，输入输出和Fast R-CNN中RoI pooling一样。4）分类和回归，这一层的输出是最终目的，输出候选区域所属的类，和候选区域在图像中的精确位置。 RPN网络首先作者自己设想原图上或者说featuremap上每个位置可能会产生k种可能的区域，下图所示，每个位置三种面积可能，三种长宽表示样式。三种面积分别是128×128，256×256，512×512，每种面积又分成3种长宽比，分别是2:1,1:2,1:1 ，k=9。 一个锚点框被标记为正样本的条件： 这个框与ground-trueth box有着最大重叠率 这个框与ground-trueth box重叠率大于0.7 如果一个锚点框与所有ground-trueth的重合率都小于0.3，那么被标记为负样本 训练时一个batch中，正负样本的比例控制在50%：50% RPN网络直接放在最后一个卷积层的后面，经过训练直接得到候选区域。 先将一幅图片经过CNN网络得到第五个卷积层，然后将第五个卷积层用3*3卷积核卷积得到一个256通道的特征图，之后再分为两路，一路用1*1卷积降维到原尺寸下2*k个通道（这2*k个分别对应是/否为对的候选区域，总共有k个框，所以是2k个，由于RPN是提取候选框，并不需要区分类别，所以两个分数是指物体的分数和背景的分数 ），另一路用1\1的卷积降维到原尺寸下4*k个通道（这个就是左上角坐标，右下角坐标，k种）注意：这里尺寸没有变，因为每个位置都要输出这么个得分情况，我们最后确定比较好的中心位置还有它的尺寸。 由于对每个向量都进行同样的全连接操作，等同于对整个特征图做1X1的卷积.训练程序会在合适的anchors中随机选取128个positive anchors+128个negative anchors进行训练 训练要将RPN网络和Fast R-CNN网络组合起来，实现权值共享。 Faster R-CNN的训练过程如下所示： 先在imagenet上预训练一个CNN模型，得到一个初始的RPN网络 另外训练一个imagenet模型CNN2，然后把在步骤1得到的Region proposals用来训练Fast R-CNN模型。 有了一个比较好的Fast R-CNN模型也就是步骤2的模型，我们把这个CNN部分固定再去矫正RPN网络，会产生新的proposal ，此时CNN部分就用CNN2（把CNN1直接丢掉了！）然后去调参RPN后面那一部分，调好了这时的RPN模型基本可以了。 完事候选区域又变了，回去在调FastR-CNN模型，此时CNN部分不动了，这两个网络已经共享了！我们去调后面的全连接。 训练中有四种损失： 区域生成网络的前后景分类损失（Object or not object） 区域生成网络的区域位置损失（Bounding box proposal） Fast RCNN物体分类损失（Normal object classification） Fast RCNN区域位置损失（Improve previous Bounding box proposal） 整体结构 FPN 卷积神经网络中越靠近分类器的层，提取的语义信息越强，但是分辨率越小。 为了兼顾分辨率和语义信息，FPN将高层提取到的语义信息自上而下进行融合。 借用Resnet的思想，使用跨层连接，上层进行2倍上采样。 RFCN代码：https://github.com/daijifeng001/r-fcn 参考：https://blog.csdn.net/baidu_32173921/article/details/71741970 出发点：图片分类的平移不变性与物体检测之间的平移变换性之间的矛盾 一方面，图像级别的分类任务侧重于平移不变性（在一幅图片中平移一个物体而不改变它的判别结果），因此深度全卷积网络结构很适合处理这类图片分类的问题。 另一方面，物体检测任务需要定义物体的具体位置，因此需要平移变换特性。为了解决这矛盾，在检测方法中插入了ROI pooling layer到卷积层。然而，这个设计牺牲了训练和测试的效率，因为它引入了大量的region-wise layers。 RCNN：由于直接在图片上生成proposal，所以没有共享的卷积层 网络结构 Backbone architecture: ResNet 101——去掉原始ResNet101的最后一层全连接层，保留前100层，再接一个1*1*1024的全卷积层（100层输出是2048，为了降维，再引入了一个1*1的卷积层） k^2(C+1)的conv: ResNet101的输出是W*H*1024，用K\^2(C+1)个1024*1*1的卷积核去卷积即可得到K^2(C+1)个大小为W*H的position sensitive的score map。这步的卷积操作就是在做prediction。k = 3，表示把一个ROI划分成3*3，对应的9个位置分别是：上左（左上角），上中，上右，中左，中中，中右，下左，下中，下右（右下角）。 k^2(C+1)个feature map的物理意义: 共有k*k = 9个颜色，每个颜色的立体块（W*H*(C+1)）表示的是不同位置存在目标的概率值（第一块黄色表示的是左上角位置，最后一块淡蓝色表示的是右下角位置）。共有k^2*(C+1)个feature map。每个feature map，z(i,j,c)是第i+k(j-1)个立体块上的第c个map（1&lt;= i,j &lt;=3）。(i,j)决定了9种位置的某一种位置，假设为左上角位置（i=j=1），c决定了哪一类，假设为person类。在z(i,j,c)这个feature map上的某一个像素的位置是（x,y），像素值是value，则value表示的是原图对应的(x,y)这个位置上可能是人（c=‘person’）且是人的左上部位（i=j=1）的概率值。 原始图片经过conv卷积得到feature map1，其中一个subnetwork如同FastRCNN：使用RPN在featuremap1上滑动产生region proposal备用；另一个subnetwork则继续卷积，得到k^2(k=3)深度的featuremap2，根据RPN产生的RoI(region proposal)在这些featuremap2上进行池化和打分分类操作，得到最终的检测结果。 ROI pooling: 就是faster RCNN中的ROI pooling，也就是一层的SPP结构。主要用来将不同大小的ROI对应的feature map映射成同样维度的特征，思路是不论对多大的ROI，规定在上面画一个n*n 个bin的网格，每个网格里的所有像素值做一个pooling（平均），这样不论图像多大，pooling后的ROI特征维度都是n*n。注意一点ROI pooling是每个feature map单独做，不是多个channel一起的。 ROI pooling的输入和输出：ROI pooling操作的输入（对于C+1个类）是k^2*(C+1)*W’ *H’（W’和H’是ROI的宽度和高度）的score map上某ROI对应的那个立体块，且该立体块组成一个新的k^2(C+1)\W’ *H’的立体块：每个颜色的立体块（C+1）都只抠出对应位置的一个bin，把这k*k个bin组成新的立体块，大小为（C+1）*W’*H’。例如，下图中的第一块黄色只取左上角的bin，最后一块淡蓝色只取右下角的bin。所有的bin重新组合后就变成了类似右图的那个薄的立体块（图中的这个是池化后的输出，即每个面上的每个bin上已经是一个像素。池化前这个bin对应的是一个区域，是多个像素）。ROI pooling的输出为为一个（C+1）*k*k的立体块，如下图中的右图 识别结果 识别成功的情况： 下面这张figure3描述了一次成功的位置敏感性识别，figure3中间的九张featuremap实际上就是位置敏感结构图左侧的九层featuremap，每一层分别对应物体的一个感兴趣部位，就比如[2,2]这张图上中位置代表人体的头部。因而所有位置的响应经过一次池化都保存在figure3右侧33(C+1)的对应位置了（原来是上中现在还是上中，原来是左下现在还是左下），如此位置敏感性得到保留。 当poolingmap九个方框得分都超过一定阈值，我们可以相信这个region proposal中是存在物体的。 识别失败的情况： 优点 比Faster R-CNN更快 思路更简单 考虑了位置敏感区域信息，更适合目标检测 总结 RCNN 1. 在图像中确定约1000-2000个候选框 (使用选择性搜索) 2. 每个候选框内图像块缩放至相同大小，并输入到CNN内进行特征提取 3. 对候选框中提取出的特征，使用分类器判别是否属于一个特定类 4. 对于属于某一特征的候选框，用回归器进一步调整其位置 Fast RCNN 在图像中确定约1000-2000个候选框 (使用选择性搜索) 对整张图片输进CNN，得到feature map 找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层 对候选框中提取出的特征，使用分类器判别是否属于一个特定类 对于属于某一特征的候选框，用回归器进一步调整其位置 Faster RCNN 对整张图片输进CNN，得到feature map 卷积特征输入到RPN，得到候选框的特征信息 对候选框中提取出的特征，使用分类器判别是否属于一个特定类 对于属于某一特征的候选框，用回归器进一步调整其位置]]></content>
      <categories>
        <category>AI</category>
        <category>CV</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测二]]></title>
    <url>%2F2020%2F10%2F12%2F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[目标检测二R-CNN论文： 《Rich feature hierarchies for accurate oject detection and semantic segmentation》 项目地址：https://github.com/rbgirshick/rcnn R-CNN概括起来就是selective search+CNN+L-SVM的检测器 用selective search代替传统的滑动窗口，提取出2k个候选region proposal 对于每个region，用摘掉了最后一层softmax层的AlexNet来提取特征 训练出来K个L-SVM作为分类器(每个目标类一个SVM分类器，K目标类个数)，使用AlexNet提取出来的特征作为输出，得到每个region属于某一类的得分 最后对每个类别用NMS(non-maximum-suppression)来舍弃掉一部分region，得到detection的结果(对得到的结果做针对boundingbox回归，用来修正预测的boundingbox的位置) 迁移学习采用在 ImageNet （ ImageNet ILSVC 2012 ， 一千万图像，1000类 ）上已经训练好的模型，然后在 PASCAL VOC （ PASCAL VOC 2007 ， 一万图像，20类 ）数据集上进行 fine-tune。 因为 ImageNet 的图像高达几百万张，利用卷积神经网络充分学习浅层的特征，然后在小规模数据集做规模化训练，从而可以达到好的效果。 这里在 ImageNet 上训练的是模型识别物体类型的能力，而不是预测 bbox 位置的能力 特征提取R-CNN 抽取了一个 4096 维的特征向量，采用的是 Alexnet，基于 Caffe 进行代码开发，之后送入4096-&gt;1000的全连接层进行分类，学习率0.01。 需要注意的是 Alextnet 的输入图像大小是 227x227。 而通过 Selective Search 产生的候选区域大小不一，为了与 Alexnet 兼容，R-CNN 采用了非常暴力的手段，那就是无视候选区域的大小和形状，统一变换到 227*227 的尺寸。 有一个细节，在对 Region 进行变换的时候，首先对这些区域进行膨胀处理，在其 box 周围附加了 p 个像素，也就是人为添加了边框，在这里 p=16。 调优训练同样使用上述网络，最后一层换成4096-&gt;21的全连接网络。学习率0.001，每一个batch包含32个正样本（属于20类）和96个背景（主要由于正样本过少）。 使用PASCAL VOC 2007的训练集，输入一张图片，输出21维的类别标号，表示20类+背景。考察一个候选框和当前图像上所有标定框重叠面积最大的一个。如果重叠比例大于0.5，则认为此候选框为此标定的类别；否则认为此候选框为背景。 分类器对每一类目标，使用一个线性SVM二类分类器进行判别。输入为深度网络输出的4096维特征，输出是否属于此类。由于负样本很多，使用hard negative mining方法。正样本 ：本类的真值标定框。负样本 ：考察每一个候选框，如果和本类所有标定框的重叠都小于0.3，认定其为负样本 bbox回归输入为深度网络pool5层的4096维特征，输出为xy方向的缩放和平移。 训练样本判定为本类的候选框中，和真值重叠面积大于0.6的候选框。 SPP-Net论文：《Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》 消除了CNN对于图像输入尺寸的限制， SPP-net结构能够产生固定大小的表示（fixed-length representation）,而不关心输入图像的尺寸或比例。金字塔池化对物体形变很鲁棒(robust to object deformations)。 由于以上优点，SPP-net可普遍改进各种基于CNN的图像分类方法。 SPP-net在目标检测上也表现突出。用SPP-net，我们只需要从整张图片计算一次特征图（feature map），然后对任意尺寸的区域（子图像）进行特征池化，以产生一个固定尺寸的表示(representation)用于训练检测器(detectors)。 这个方法避免了反复计算卷积特征。在处理测试图像时，我们的方法在VOC2007数据集上，达到相同或更好的性能情况下，比R-CNN方法快24-102X倍。 为了解决剪裁带来的信息丢失和变形导致的信息扭曲，采用空间金字塔池化( spatial pyramid pooling，SPP)层，移除对网络固定尺寸的限制（通常将其放在卷积后，FC层之前）。 SPP原理 三种颜色的网格，是将从conv5得到的特征分别映射成16、4、1份，16X256中的256表示的是channel，即SPP对每一层都分成16份(不一定是等比分)。将特征映射后进行最大池化。 通过SPP，对任意的输入可以得到固定的21*256大小的输出，21指的是20个类别加上1个背景。 公式 因此，当输出的尺寸为224224时，conv5后得到的特征图大小为13\13，设为a，第一个映射为4*4，设为n。 如果想要运算后得到的大小也为n。那么令： $windows_size=[a/n]$ 向上取整 ， $stride_size=[a/n]$向下取整。 一般情况下这时有：$ans = (a-n)/(a/n)+1=n$ 但如果对于输入：(7,11)，金字塔bins=(4,4)，这时K=(2,3)，Stride=(1,2)，结果为(6,5)，并不是(4,4) 修订公式后： 代码 marsggbo/sppnet-pytorch 123456789101112131415161718192021222324252627282930313233import mathimport torchimport torch.nn.functional as F# 构建SPP层(空间金字塔池化层)class SPPLayer(torch.nn.Module): def __init__(self, num_levels, pool_type='max_pool'): super(SPPLayer, self).__init__() self.num_levels = num_levels self.pool_type = pool_type def forward(self, x): num, c, h, w = x.size() # num:样本数量 c:通道数 h:高 w:宽 for i in range(self.num_levels): level = i+1 kernel_size = (math.ceil(h / level), math.ceil(w / level)) stride = (math.ceil(h / level), math.ceil(w / level)) pooling = (math.floor((kernel_size[0]*level-h+1)/2), math.floor((kernel_size[1]*level-w+1)/2)) # 选择池化方式 if self.pool_type == 'max_pool': tensor = F.max_pool2d(x, kernel_size=kernel_size, stride=stride, padding=pooling).view(num, -1) else: tensor = F.avg_pool2d(x, kernel_size=kernel_size, stride=stride, padding=pooling).view(num, -1) # 展开、拼接 if (i == 0): x_flatten = tensor.view(num, -1) else: x_flatten = torch.cat((x_flatten, tensor.view(num, -1)), 1) return x_flatten 多尺度训练除此之外， 训练阶段，图像可以有各种尺寸和缩放尺度。使用各种尺寸的图像进行训练,可以提高缩放不变性，以及减少过拟合。基于此的多尺度训练方法： 每个epoch，我们针对一个给定的输入尺寸进行网络训练，然后在下一个epoch，再切换到另一个尺寸。实验表明，这种多尺度训练和传统的单一尺度训练一样可以收敛，并且能达到更好的测试精度。 多尺寸训练的主要目的是在保证已经充分利用现在被较好优化的固定尺寸网络实现的同时，模拟不同的输入尺寸。 R-CNN vs SPP-Net R-CNN 首先通过选择性搜索，对待检测的图片进行搜索出~2000个候选窗口。 把这2k个候选窗口的图片都缩放到227*227，然后分别输入CNN中，每个proposal提取出一个特征向量，也就是说利用CNN对每个proposal进行提取特征向量。 把上面每个候选窗口的对应特征向量，利用SVM算法进行分类识别。 SPP-Net 首先通过选择性搜索，对待检测的图片进行搜索出2000个候选窗口。这一步和R-CNN一样。 特征提取阶段。这一步就是和R-CNN最大的区别了，这一步骤的具体操作如下：把整张待检测的图片，输入CNN中，进行一次性特征提取，得到feature maps，然后在feature maps中找到各个候选框的区域，再对各个候选框采用金字塔空间池化，提取出固定长度的特征向量。而R-CNN输入的是每个候选框，然后在进入CNN，因为SPP-Net只需要一次对整张图片进行特征提取，速度会大大提升。 最后一步也是和R-CNN一样，采用SVM算法进行特征向量分类识别。 用于目标检测 我们将SPP-net应用于物体检测。只在整张图像上抽取一次特征。然后在每个特征图的候选窗口上应用空间金字塔池化，形成这个窗口的一个固定长度表示。因为只应用一次卷积网络，这种方法快得多。SPP-net从特征图中直接抽取特征，而R-CNN则要从图像区域抽取。之前的一些工作中，可变性部件模型(Deformable Part Model, DPM)从HOG特征图的窗口中抽取图像，选择性搜索方法从SIFT编码后的特征图的窗口中抽取特征。Overfeat也是从卷积特征图中抽取特征，但需要预定义的窗口尺寸。作为对比，我们的特征抽取可以在任意尺寸的深度卷积特征图窗口上。 我们使用选择性搜索[20]的“fast”模式对每张图片产生2000个候选窗口。然后缩放图像以满足min(w;h) = s，并且从整张图像中抽取特征图。我们暂时使用ZF-5的SPP-net 模型（单一尺寸训练）。在每个候选窗口，我们使用一个4级空间金字塔（1×1, 2×2, 3×3, 6×6, 总共50块）。每个窗口将产生一个12800（256×50）维的表示。这些表示传递给网络的全连接层。然后我们针对每个分类训练一个二分线性SVM分类器。 将我们想要的proposal映射到特征图之上，从而进行SPP 。 原图中的proposal,经过多层卷积之后，位置还是相对于原图不变的。 对于映射关系，论文中给出了一个公式：假设(x’,y’)表示特征图上的坐标点，坐标点(x,y)表示原输入图片上的点，那么它们之间有如下转换关系，这种映射关心与网络结构有关： (x,y)=(S∗x’,S∗y’) 反过来，我们希望通过(x,y)坐标求解(x’,y’)，那么计算公式如下： Left、Top：x′=⌊x/S⌋+1 \\Right、Bottom： x ′ = ⌈ x / S ⌉ − 1其中S就是CNN中所有的strides的乘积，包含了池化、卷积的stride。 比如，对于下图的集中网络结构，S的计算如下： 论文中使用的是 ZF-5： S=2*2*2*2=16 \\Overfeat-5/7 : S =2*3*2 =12 完整流程如下：]]></content>
      <categories>
        <category>AI</category>
        <category>CV</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测一]]></title>
    <url>%2F2020%2F10%2F11%2F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%80%2F</url>
    <content type="text"><![CDATA[目标检测一非极大值抑制nmsnms目标检测算法会产生数量巨大的候选矩形框，这些矩形框有很多是指向同一目标，存在大量冗余。nms可以消除多余的框，找到最佳的物体检测位置。 非极大值抑制（Non-Maximum Suppression）的思想是搜索局部极大值，抑制非极大值元素 交并比 IoU(Intersection over Union)为交并比 。 经典nms 设定目标框的置信度阈值，常用的阈值是0.5左右 根据置信度降序排列候选框列表 选取置信度最高的框A添加到输出列表，并将其从候选框列表中删除 计算A与候选框列表中的所有框的IoU值，删除大于阈值的候选框 重复上述过程，直到候选框列表为空，返回输出列表 soft-NMS经典NMS对于重叠物体无法很好检测。 下图中红色边界框的置信度最高，绿色框的置信度较小，但和红色框的IoU较大，如果按NMS规则，那么此时绿色框的置信度则置为0。可是实际上，绿色框是后面那匹马的边界框，而红色框是前面那匹马的边界框，两者应该同时存在。 相对于经典NMS算法，Soft-NMS仅仅修改了一行代码。当选取了最大置信度的Bounding box之后，计算其余每个Bounding box与Bounding box的Iou值，经典NMS算法的做法是直接删除Iou大于阈值的Bounding box；而Soft-NMS则是使用一个基于Iou的衰减函数，降低Iou大于阈值Nt的Bounding box的置信度，IoU越大，衰减程度越大。 经典NMS soft-NMS-线性 soft-NMS-高斯 Locality-Aware NMS假设来自附近像素的几何图形往往高度相关，我们建议逐行合并几何图形，同时在同一行中合并几何图形时，我们将迭代地合并当前遇到的几何图形和最后合并的几何图形。这种改进的技术在最佳场景下以$O(n)$运行。即使最坏的情况也与经典NMS相同，只要位置假设成立，算法在实践中运行得足够快。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import numpy as npfrom shapely.geometry import Polygon# 传入的g为numpy数组，8个数为4个坐标的x,y值，顺序为：左上 左下 右下 右上def intersection(g, p): # 取g,p中的几何体信息组成多边形 g = Polygon(g[:8].reshape((4, 2))) p = Polygon(p[:8].reshape((4, 2))) # 判断g,p是否为有效的多边形几何体 if not g.is_valid or not p.is_valid: return 0 # 取两个几何体的交集和并集 inter = Polygon(g).intersection(Polygon(p)).area union = g.area + p.area - inter if union == 0: return 0 else: return inter / uniondef weighted_merge(g, p): # 取g,p两个几何体的加权（权重根据对应的检测得分计算得到） g[:8] = (g[8] * g[:8] + p[8] * p[:8]) / (g[8] + p[8]) # 合并后的几何体的得分为两个几何体得分的总和 g[8] = (g[8] + p[8]) return gdef standard_nms(S, thres): # 标准NMS order = np.argsort(S[:, 8])[::-1] # 反转后为从大到小 keep = [] while order.size &gt; 0: i = order[0] keep.append(i) ovr = np.array([intersection(S[i], S[t]) for t in order[1:]]) inds = np.where(ovr &lt;= thres)[0] order = order[inds + 1] return S[keep]def nms_locality(polys, thres=0.3): ''' locality aware nms of EAST :param polys: a N*9 numpy array. first 8 coordinates, then prob :return: boxes after nms ''' S = [] # 合并后的几何体集合 p = None # 合并后的几何体 for g in polys: if p is not None and intersection(g, p) &gt; thres: # 若两个几何体的相交面积大于指定的阈值，则进行合并 p = weighted_merge(g, p) else: # 反之，则保留当前的几何体 if p is not None: S.append(p) p = g if p is not None: S.append(p) if len(S) == 0: return np.array([]) return standard_nms(np.array(S), thres) softer-NMS以上的NMS算法，无论是经典NMS还是Soft-NMS算法，都是在一种假设前提下：置信度最高的Bounding box就是目标的候选位置最精确的物体位置。但是事实上，这个假设可能并不成立，或者说并不那么精确。针对这个问题，来自卡内基梅隆大学与旷视科技的研究人员在文中提出了一种新的非极大抑制算法Softer-NMS，显著改进了目标检测的定位精度。 论文的motivation来自于NMS时用到的score仅仅是分类置信度得分，不能反映Bounding box的定位精准度，既分类置信度和定位置信非正相关的 , 论文首先假设Bounding box是高斯分布，ground truth bounding box是狄拉克delta分布（即标准方差为0的高斯分布极限）。KL 散度用来衡量两个概率分布的非对称性度量，KL散度越接近0代表两个概率分布越相似。 论文提出的KL loss，即为最小化Bounding box regression loss，既Bounding box的高斯分布和ground truth的狄拉克delta分布的KL散度。直观上解释，KL Loss使得Bounding box预测呈高斯分布，且与ground truth相近。而将包围框预测的标准差看作置信度。 论文提出的Softer-NMS，基于soft-NMS，对预测标注方差范围内的候选框加权平均，使得高定位置信度的bounding box具有较高的分类置信度。 Softer-NMS网络结构，与R-CNN不同的是引入absolute value layer（图中AbsVal）,实现标注方差的预测: 预测的四个顶点坐标，分别对$IoU＞Nt$的预测加权平均计算，得到新的4个坐标点。第i个box的x1计算公式如下（j表示所有$IoU＞Nt$的box） : Selective Search1可以通过pip安装selectivesearch 首先通过简单的区域划分算法，将图片划分成很多小区域，再通过相似度和区域大小（小的区域先聚合，这样是防止大的区域不断的聚合小区域，导致层次关系不完全）不断的聚合相邻小区域，类似于聚类的思路。这样就能解决object层次问题。 step0：生成区域集R，具体参见论文《Efficient Graph-Based Image Segmentation》step1：计算区域集R里每个相邻区域的相似度S={s1,s2,…}step2：找出相似度最高的两个区域，将其合并为新集，添加进Rstep3：从S中移除所有与step2中有关的子集step4：计算新集与所有子集的相似度step5：跳至step2，直至S为空 为了保证能够划分的完全，对于相似度，作者提出了可以多样化的思路，不但使用多样的颜色空间（RGB，Lab，HSV等等），还有很多不同的相似度计算方法 通过上述的步骤我们能够得到很多很多的区域，但是显然不是每个区域作为目标的可能性都是相同的，因此我们需要衡量这个可能性，这样就可以根据我们的需要筛选区域建议个数啦。 这篇文章做法是，给予最先合并的图片块较大的权重，比如最后一块完整图像权重为1，倒数第二次合并的区域权重为2以此类推。但是当我们策略很多，多样性很多的时候呢，这个权重就会有太多的重合了，排序不好搞啊。文章做法是给他们乘以一个随机数，毕竟3分看运气嘛，然后对于相同的区域多次出现的也叠加下权重，毕竟多个方法都说你是目标，也是有理由的嘛。这样我就得到了所有区域的目标分数，也就可以根据自己的需要选择需要多少个区域了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 从https://github.com/AlpacaDB/selectivesearch下载示例代码，运行example.py# -*- coding: utf-8 -*-from __future__ import ( division, print_function,)import skimage.dataimport matplotlib.pyplot as pltimport matplotlib.patches as mpatchesimport selectivesearchdef main(): # loading astronaut image img = skimage.data.astronaut() # perform selective search img_lbl, regions = selectivesearch.selective_search( img, scale=500, sigma=0.9, min_size=10) candidates = set() for r in regions: # excluding same rectangle (with different segments) if r['rect'] in candidates: continue # excluding regions smaller than 2000 pixels if r['size'] &lt; 2000: continue # distorted rects x, y, w, h = r['rect'] if w / h &gt; 1.2 or h / w &gt; 1.2: continue candidates.add(r['rect']) # draw rectangles on the original image fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6)) ax.imshow(img) for x, y, w, h in candidates: print(x, y, w, h) rect = mpatches.Rectangle( (x, y), w, h, fill=False, edgecolor='red', linewidth=1) ax.add_patch(rect) plt.show()if __name__ == "__main__": main()]]></content>
      <categories>
        <category>AI</category>
        <category>CV</category>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极大似然与EM算法]]></title>
    <url>%2F2020%2F08%2F05%2F%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%B8%8EEM%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[极大似然估计参考： https://www.zhihu.com/question/24124998 极大似然是对概率模型参数学习优化目标的一种定义 。 就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值 。 对于离散型的随机变量： 如果是一个连续型的随机变量 ： 想对$L(\theta)$求最值，为了便于求导，两边取对数，有： 如果方程有唯一解，且是极大值点，那么我们就求得了极大似然估计值。 例子1：抛硬币 例子2：单参数 例子3：多参数 总体方差的极大似然估计值的分母是 而不是 ，因此他不是一个无偏估计量。但是可以说他是渐近无偏的 EM算法参考： https://blog.csdn.net/wsp_1138886114/article/details/81002550 参考： https://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html EM算法是用于求解极大似然估计的一种迭代逼近的算法 。 Jensen不等式、 设f是定义域为实数的函数，如果对于所有的实数x， $f^{‘’}(x)\geqslant 0$ 那么f是凸函数，如果$f^{‘’}(x)&gt; 0$ 那么f是严格凸函数。 jensen不等式： 如果f是凸函数，X是随机变量，那么 $E[f(x)]\geqslant f[E(x)]$，特别的，如果f是严格凸函数，那么当且仅当$p(x=E[x])=1$时（X为常量），取得 $E[f(x)]= f[E(x)]$ lazy Statistician规则设 y 是随机变量 x 的函数，$y=g(x)(g是连续函数)$，那么： (1) x 是离散随机变量，分布为$p(x=xk)=p_k,k∈N∗$,若$∑^∞{k=1} g(x) p_k$绝对收敛，则 E(y)=E|g(x)|=∑^∞_{k=1}g(x_k)p_k (2) x 是连续随机变量，分布概率为$f(x)$,若$∫^∞_{−∞}g(x)f(x)dx$ 绝对收敛，则 E(y)=E|g(x)|=∫^∞_{−∞}g(x)f(x)dxEM公式推导假设我们有一个样本集${x(1),…,x(m)}$，包含m个独立的样本。但每个样本i对应的类别z(i)是未知的，也即隐含变量。故我们需要估计概率模型$p(x,z)$的参数$θ$，但是由于里面包含隐含变量z，所以很难用最大似然求解。 思路是既然不能直接最大化$L(\theta)$，我们可以不断地建立$L(\theta)$的下界（E步），然后优化下界，得到新参数$\theta$（M步） （1）对每个样例的每个可能类别z求联合分布概率和，由于”和的对数“求导困难（ log(f1(x)+ f2(x)+ f3(x)+··· 复合函数求导），因此进行化简。 对于每一个样例i，让$Q_t$ 表示该样例隐含变量z的某种分布， $Q_t$满足的条件是$\sum_zQ_i(z)=1，Q_i(z)\geqslant 0$，如果z是连续的，那么$Q_t$是概率密度函数，将求和号换成积分号。 对于公式（3），由于$log(x)$是凹函数，且 是的期望，根据Jensen不等式，对于凹函数有： 这个过程可以看作对$L(\theta)$求下界，固定$\theta$，那么$L(\theta)$的值就取决于$Q_i(z^{(i)})$和$p(x^{(i)},z^{(i)};\theta)$ 。我们可以通过调整这两个概率使下界不断上升，以逼近$L(θ)$的真实值，那么什么时候算是调整好了呢？当不等式变成等式时，说明我们调整后的概率都能够等价于$L(θ)$了。按照这个思路，我们要找到等式成立的条件。根据Jensen不等式，要想让等式成立，需要让随机变量变成常数值，这里得到 \frac {p(x^{(i)},z^{(i)};θ)}{Q_i(z^{(i)})}=CC为常数，不依赖于$z^{(i)}$，由于$\sum_zQ_i(z)=1$，分子分母同时求和（认为每个比值都是C，这样分子分母同时求和结果不变），于是得到$\sum_z p(x^{(i)},z^{(i)};\theta)=C$​，则 之前说$L(\theta)$的值取决于$Q_i(z^{(i)})$和$p(x^{(i)},z^{(i)};\theta)$，但我们为了取到等号，让两者的比值等于常数，也就是说$Q_i(z^{(i)})$和$p(x^{(i)},z^{(i)};\theta)$其实是同比例变化的。 至此，我们推出了在固定参数$θ$后，使下界拉升的$Q(z)$的计算公式就是后验概率，解决了$Q(z)$如何选择的问题。这一步就是E步，建立$L(θ)$的下界。接下来的M步，就是在给定$Q(z)$后，调整$θ$，去极大化$L(θ)$的下界J（在固定$Q(z)$后，下界还可以调整的更大）。那么一般的EM算法的步骤如下： 在 E-step：固定$\theta$，找到对于当前参数 $θ$使不等式成立的 $Q$分布，使得下界$J(Z,Q)$不断上升，直到与$L(θ)$在$θ$点重合。 在 M-step：固定$Q(z)$，对似然函数下界进行极大似然估计，找到$J(Z,θ)$的极大值，得到新的参数 形式化表示为： E-step $Q_i(z^{(i)})=p(z^{(i)}∣x^{(i)};θ) $ M-step $θ=\arg \max\theta{∑^n{i=1}∑_{z^{(i)}}Qi(z^{(i)})log\frac {p(x^{(i)}),z^{(i)};θ)}{Qi(z^{(i)})}} $ 由于$L(\theta)$会单调增加。因此EM算法收敛。 证明：收敛证明 直线式迭代优化每一步都会向最优值前进一步，而且前进路线是平行于坐标轴的，因为每一步只优化一个变量。这犹如在x-y坐标系中找一个曲线的极值，然而曲线函数不能直接求导，因此梯度下降方法不适用。 但固定一个变量后，另外一个可以通过求导得到，因此可以使用坐标上升法，一次固定一个变量，对另外的求极值，最后逐步逼近极值。对应到EM上， E步：固定θ，优化Q；M步：固定Q，优化θ；交替将极值推向最大。 EM算法实例 ● 假设现在有两枚硬币1和2,随机抛掷后正面朝上概率分别为$P_1、P_2$。为了估计这两个概率，每次取一枚硬币，连掷5下，记录下结果，如下 表一（实验数据） 表二（测试数据） 硬币 结果 统计 硬币 结果 统计 1 正正反正反 3正-2反 UnKnow 正正反正反 3正-2反 2 反反正正反 2正-3反 UnKnow 反反正正反 2正-3反 1 正反反反反 1正-4反 UnKnow 正反反反反 1正-4反 2 正反反正正 3正-2反 UnKnow 正反反正正 3正-2反 1 反正正反反 2正-3反 UnKnow 反正正反反 2正-3反 表一：可以很容易地估计出P1和P2，如下：P1 = （3+1+2）/ 15 = 0.4P2= （2+3）/10 = 0.5 ● 现在我们抹去每轮投掷时使用的硬币标记，如上右表（表二（测试数据））。 目标没变，还是估计P1和P2: 此时多了一个隐变量z，可以把它认为是一个5维的向量（z1,z2,z3,z4,z5)，代表每次投掷时所使用的硬币，比如z1，就代表第一轮投掷时使用的硬币是1还是2。但是，这个变量z不知道，就无法去估计P1和P2。 我们可以先随机初始化一个P1和P2，用它来估计z，然后基于z，还是按照最大似然概率法则去估计新的P1和P2当与我们初始化的P1和P2一样时，说明是P1和P2很有可能就是真实的值。这里面包含了两个交互的最大似然估计。（参数$\theta$在这里就是需要求解的P1、P2） 计算过程当假设P1 = 0.2，P2 = 0.8时： （看看第一轮抛掷最可能是哪个硬币。） 如果是硬币1，得出3正2反的概率为：0.2×0.2×0.2×0.8×0.8= 0.00512如果是硬币2，得出3正2反的概率为：0.8×0.8×0.8×0.2×0.2=0.03087依次求出其他4轮中的相应概率。（如：表三） 按照最大似然法则：（表三） 轮数 若是硬币1 若是硬币2 第1轮中最有可能的是硬币2 1 0.00512 0.03087 第2轮中最有可能的是硬币1 2 0.02048 0.01323 第3轮中最有可能的是硬币1 3 0.08192 0.00567 第4轮中最有可能的是硬币2 4 0.00512 0.02048 第5轮中最有可能的是硬币1 5 0.02048 0.01323 我们就把上面的值作为z的估计值。 然后按照最大似然概率法则来估计新的P1和P2。（由表三，查到 表二的正反数据计算P值） P1 = （2+1+2）/15 = 0.33 P2=（3+3）/10 = 0.6 将算的的P1P2反复迭代： 设想我们知道每轮抛掷时的硬币就是如标示的那样，那么，P1和P2的最大似然估计就是0.4和0.5 （下文中将这两个值称为P1和P2的真实值）。那么对比下我们初始化的P1和P2和新估计出的P1和P2： 初始化P1 估计出P1 真实的P1 初始化P2 估计出P2 真实的P2 0.2 0.33 0.4 0.8 0.6 0.5 优化新估计出的 P1和P2 一定会更接近真实的 P1和P2迭代不一定会收敛到真实的P1和P2。取决于P1和P2的初始化值。 用期望来简化运算 再次利用表三：我们可以算出每轮抛掷中使用硬币1或者使用硬币2的概率。 比如第1轮，使用硬币1的概率是：0.00512/(0.00512+0.03087)=0.14使用硬币2的概率是：1-0.14=0.86 我们按照期望最大似然概率的法则来估计新的P1和P2：以P1估计为例，（表二）第1轮的3正2反相当于0.14*3=0.42正0.14*2=0.28反依次算出其他四轮，表四如下：new_P1=4.22/(4.22+7.98)=0.35 轮数 正面 反面 1 0.42 0.28 2 1.22 1.83 3 0.94 3.76 4 0.42 0.28 5 1.22 1.83 总计 4.22 7.98 可以看到，改变了z值的估计方法后，新估计出的P1要更加接近0.4。原因就是我们使用了所有抛掷的数据，而不是之前只使用了部分的数据。我们根据E步中求出的z的概率分布，依据最大似然概率法则去估计P1和P2，被称作M步。]]></content>
      <categories>
        <category>AI</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP三]]></title>
    <url>%2F2020%2F08%2F04%2FNLP%E4%B8%89%2F</url>
    <content type="text"><![CDATA[马尔可夫链每个状态的转移只依赖于之前的n个状态。最简单的马尔可夫过程是一阶过程，即每一个状态的转移只依赖于之前的那一个状态。 明天的概率分布为 (1,0)*\begin{pmatrix} 0.9 & 0.1 \\ 0.5 & 0.5 \end{pmatrix}=(0.9,0.1)后天的概率分布为继续乘上转移矩阵，最后概率趋于稳定，得到稳态分布。 我们为上面的一阶马尔可夫过程定义了以下三个部分： 状态：晴天、阴天 初始向量：系统在时间为0的时候状态的分布概率，如（1，0） 状态转移矩阵：每种状态转移的概率 所有能被这样描述的系统都是一个马尔可夫过程。 隐马尔可夫模型（HMM）隐马尔可夫模型（Hidden Markov Model）是一种统计模型，用来描述一个含有隐含未知参数的马尔可夫过程。难点是从可观测的参数中确定该过程的隐含参数，然后利用参数做进一步分析。 用掷骰子举例，假设有三种骰子，分别为6面、4面、8面，选中每个骰子的概率都为1/3。 隐藏的马尔可夫链随机生成的状态序列，称为状态序列；每个状态生成一个观测，而由此产生的观测随机序列，称为观测序列。序列的每个位置又可以看作是一个时刻。 基本假设 齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于前一时刻的状态，与其他时刻的状态及观测无关。 观测独立性假设，即假设任意时刻的观测只依赖与该时刻的马尔科夫链的状态，与其他观测及状态无关。 隐马尔可夫链三大问题隐马尔可夫模型由三个概率确定： 初始概率分布，即初始的隐含状态的概率分布，记为$π$； 状态转移概率分布，即隐含状态间的转移概率分布, 记为$A$； 观测概率分布，即由隐含状态生成观测状态的概率分布, 记为$B$。 以上的三个概率分布可以说就是隐马尔可夫模型的参数，而根据这三个概率，能够确定一个隐马尔可夫模型 $λ=(A,B,π)$。 而隐马尔科夫链的三个基本问题为： 概率计算问题。即给定模型$λ=(A,B,π)$和观测序列$O$，计算在模型$λ$下观测序列出现的最大概率$P(O|λ)$； 解码问题。给定模型$λ=(A,B,π)$和观测序列$O$，计算最有可能产生这个观测序列的隐含序列$X$, 即使得概率$P(X|O,λ)$最大的隐含序列$X$。 学习问题。即给定观测序列$O$，估计模型的参数$λ$, 使得在该参数下观测序列出现的概率最大，即$P(O|λ)$最大； 也即： 1、给定一个模型，如何计算某个特定的输出序列的概率 2、给定一个模型和某个模型的输出序列，如何找到最可能产生这种输出的状态序列 3、给定足够量的观测数据，如何估计隐马尔可夫模型的参数 假设一个隐马尔可夫过程的例子，则$(A,B,π)$如下图所示： 则三个问题为： 已知整个模型，观测到连续三天做的事情是：散步、购物、清理。那么根据模型，计算产生这些行为的概率是多少。 已知整个模型，同样是这三件事，猜测这三天的天气如何。 最复杂的问题，在只知道这三天做了这三件事的情况下，建立整个模型，给出$(A,B,π)$ 隐马尔可夫链解法 问题一：Forward Algorithm，向前算法；或者Backward Algorithm，向后算法 问题二：Viterbi Algorithm，维特比算法 问题三：Baum-Welch Algorithm，鲍姆-韦尔奇算法 问题一参考： 前向算法、后向算法 遍历算法已知三天做的事情是：散步、购物、清理。三天的可能天气组合为$2^3=8$，遍历每种可能，求出概率。 当状态和观测节点较少时，遍历法更有效，但随着节点数增多，计算复杂度急剧增加。 前向算法 看成时间序列，按照t=1、t=2···的顺序计算。 先计算第一天散步的概率，包括$P(Walk_1,Rainy_1)和P(Walk_1,Sunny_1)$ 计算第二天购物的概率：包括$P(Walk_1,Shop_2,Rainy_2)和P(walk_1,Shop_2,Sunny_2)$ 分别为： P(Walk_1,Shop_2,Rainy_2)=P(Walk_1,Rainy_1)P(Rainy_2|Rainy_1)P(Shop_2|Rainy_2)+ \\P(Walk_1,Sunny_1)P(Rainy_2|Sunny_1)P(Shop_2|Rainy_2) \\ P(walk_1,Shop_2,Sunny_2)=P(Walk_1,Rainy_1)P(Sunny_2|Rainy_1)P(Shop_2|Sunny_2)+ \\P(Walk_1,Sunny_1)P(Sunny_2|Sunny_1)P(Shop_2|Sunny_2) 计算第三天清理的概率：包括$P(Walk_1,Shop_2,Clean_3,Rainy_3)和P(walk_1,Shop_2,Clean_3,Sunny_3)$ 后向算法 计算所有后向概率$β_t$，最后通过后向概率求出观测序列概率 定义最后时刻T所有状态的后向概率为1，即$ β_3(S)=1、 β_3(R)=1 $ $a_{R\rightarrow R}$表示前一天下雨的情况下，后一天也下雨的概率，$b_R(O_3=C)$表示下雨的情况下清理的概率，则第二天的后向概率： β_2(R)=a_{R\rightarrow R}·b_R(O_3=C)·β_3(R)+a_{R\rightarrow S}·b_S(O_3=C)·β_3(S) \\β_2(S)=a_{S\rightarrow R}·b_R(O_3=C)·β_3(R)+a_{S\rightarrow S}·b_S(O_3=C)·β_3(S)前后向算法代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081from numpy import *import numpy as npimport matplotlib as pltimport math#隐马尔科链模型前向算法def hmm_forward(A, PI, B, O): M = shape(PI)[0] #观测序列大小 N = shape(A)[1] #状态序列大小 T = M alpha = mat(zeros((M, N))) P = 0.0 for i in range(N): alpha[0, i] = PI[i, 0] * B[i, 0] for t in range(T - 1): for i in range(N): temp_value = 0.0; for j in range(N): temp_value += alpha[t, j] * A[j, i] index = 0 if(O[t + 1, 0] == 0): index = 0 else: index = 1 alpha[t + 1, i] = temp_value * B[i, index] for i in range(N): P += alpha[T - 1, i] return P,alpha#隐马尔科链模型后向算法def hmm_backword(A, PI, B, O): T,N = shape(A) beta = mat(zeros((T, N))) P = 0.0 beta[T - 1, :] = 1 t = T - 2 while t &gt;= 0: for i in range(N): temp_value = 0.0 for j in range(N): index = 0 if(O[t + 1, 0] == 0): index = 0 else: index = 1 temp_value += A[i, j] * B[j, index] * beta[t + 1, j] beta[t, i] = temp_value t -= 1 for i in range(N): index = 0 if(O[0, 0] == 0): index = 0 else: index = 1 P += PI[i, 0] * B[i, index] * beta[0, i] return P,betaif __name__ == "__main__": A = mat([[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]]) B = mat([[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]]) PI = mat([[0.2], [0.4], [0.4]]) #红，白，红 O = mat([[0], [1], [0]]) P,alpha = hmm_forward(A, PI, B, O) print(P) print("--------------------------------------") P,beta = hmm_backword(A, PI, B, O) print(P) 问题二viterbi算法参考： https://www.zhihu.com/question/20136144 参考： https://blog.csdn.net/hudashi/article/details/87875259 隐马尔科夫的预测问题就是要求图中的一条路径，使得该路径对应的概率值最大。 对应上图来讲，假设每个时刻x可能取的值为3，如果直接求的话，有3^N的组合数，底数3为篱笆网络宽度，指数N为篱笆网络的长度，计算量非常大。维特比利用动态规划的思想来求解概率最大路径（可理解为求图最短路径），使得复杂度正比于序列长度，复杂度为O(N⋅D⋅D), N为长度，D为宽度，从而很好地解决了问题的求解。 1、如果概率最大的路径经过篱笆网络的某点，则从开始点到该点的子路径也一定是从开始到该点路径中概率最大的。 2、假定第i时刻有k个状态，从开始到i时刻的k个状态有k条最短路径，而最终的最短路径必然经过其中的一条。 3、根据上述性质，在计算第i+1状态的最短路径时，只需要考虑从开始到当前的k个状态值的最短路径和当前状态值到第i+1状态值的最短路径即可，如求t=3时的最短路径，等于求t=2时的所有状态结点x2i的最短路径加上t=2到t=3的各节点的最短路径。 算法流程 定义t时刻状态为i的所有单个路径 (i1, i2, …, it) 中最大概率值（最短路径）为 其中，$i_t$表示最短路径，得到变量的递推公式： 其中i = 1, 2, …, N; t = 1, 2, … , T-1，定义在时刻t状态为i的所有单个路径 (i1, i2, …, it, i) 中概率最大的路径的第t－1个结点为： 初始化参数 开始递推 最后的终止状态（T状态）计算： 最优路径的回溯，对t＝T-1, T－2，…, 1 则最优路径为： 例子 计算t=1时刻Walk的概率 δ_1(R) = P(Rainy,Walk) = π_R*b_R(O_1=W)=0.6×0.1=0.06\\ δ_1(S) = P(Sunny,Walk) = π_S*b_S(O_1=W)=0.4×0.6=0.24​ $\psi_1(R)=0、\psi_1(S)=0$ 计算t=2时刻Shop发生的概率 δ_2(R) =Max[δ_1(R)*a_{R\rightarrow R}, δ_1(S)*a_{S \rightarrow R}]*b_R(O_2=Shop)\\ =0.24*0.4*0.4=0.0384\\ δ_2(S) =Max[δ_1(R)*a_{R\rightarrow S}, δ_1(S)*a_{S \rightarrow S}]*b_S(O_2=Shop)\\ =0.24*0.6*0.3=0.001392\\​ $\psi_2(R)=Rainy、\psi_2(S)=Rainy$ 计算t=3时刻Clean的概率 δ_3(R) =Max[δ_2(R)*a_{R\rightarrow R}, δ_2(S)*a_{S \rightarrow R}]*b_R(O_3=Clean)\\ =0.0384*0.7*0.5=0.01344\\ δ_3(S) =Max[δ_2(R)*a_{R\rightarrow S}, δ_2(S)*a_{S \rightarrow S}]*b_S(O_3=Clean)\\ =0.0384*0.4*0.1=0.0432\\​ $\psi_3(R)=Rainy、\psi_3(S)=Rainy$ $i^_T=Sunny，i^_2=\psi_3(Sunny)=Rainy，i^*_1=\psi_2(Rainy)=Rainy$ $I^*=(Rainy，Rainy,Sunny)$ 问题三先导：EM算法极大似然与EM算法 Baum-Welch算法由于只知道观测值，所以算法没有全局最优解，只能找到局部最优解。 参考： https://blog.csdn.net/u014688145/article/details/53046765]]></content>
      <categories>
        <category>AI</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP二]]></title>
    <url>%2F2020%2F08%2F03%2FNLP%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[image caption with X Image Captioning方面的工作可以总结为“Image Captioning with X”，其中的 X 可以是 Visual Attention, Visual Attributes, Entity Recognition, Dense Caption 和 Reinforcement Learning等模块。 Visual Attention注意力包括软注意力(soft attention)和强注意力 软注意力的关键点在于，这种注意力更关注区域或者通道，而且软注意力是确定性的注意力，学习完成后直接可以通过网络生成，最关键的地方是软注意力是可微的，这是一个非常重要的地方。可以微分的注意力就可以通过神经网络算出梯度并且前向传播和后向反馈来学习得到注意力的权重。 强注意力与软注意力不同点在于，首先强注意力是更加关注点，也就是图像中的每个点都有可能延伸出注意力，同时强注意力是一个随机的预测过程，更强调动态变化。当然，最关键是强注意力是一个不可微的注意力，训练过程往往是通过增强学习(reinforcement learning)来完成的。 attention是学出一个权重分布，再拿这个权重分布施加在原来的特征之上。简单来说： 这个加权可以是保留所有分量均做加权（即soft attention）；也可以是在分布中以某种采样策略选取部分分量（即hard attention）。 这个加权可以作用在原图上，也就是RAM和DRAM；也可以作用在特征图上，如后续的好多文章（例如image caption)。 这个加权可以作用在空间尺度上，给不同空间区域加权；也可以作用在channel尺度上，给不同通道特征加权；甚至特征图上每个元素加权。 这个加权还可以作用在不同时刻历史特征上，如Machine Translation。 Reinforcement Learning强化学习（Reinforcement Learning，简称RL）是机器学习的一个重要分支。在强化学习中，包含两种基本的元素：状态与动作，在某个状态下执行某种动作，这便是一种策略，学习器要做的就是通过不断地探索学习，从而获得一个好的策略。例如：在围棋中，一种落棋的局面就是一种状态，若能知道每种局面下的最优落子动作，那就攻无不克/百战不殆了~ 若将状态看作为属性，动作看作为标记，易知：监督学习和强化学习都是在试图寻找一个映射，从已知属性/状态推断出标记/动作，这样强化学习中的策略相当于监督学习中的分类/回归器。但在实际问题中，强化学习并没有监督学习那样的标记信息，通常都是在尝试动作后才能获得结果，因此强化学习是通过反馈的结果信息不断调整之前的策略，从而算法能够学习到：在什么样的状态下选择什么样的动作可以获得最好的结果。 强化学习和监督学习最大的区别是它没有监督学习已经准备好的训练数据输出值。强化学习只有奖励值，但是这个奖励值和监督学习的输出值不一样，它不是事先给出的，而是延后给出的。同时，强化学习的每一步与时间顺序前后关系紧密。而监督学习的训练数据之间一般都是独立的，没有这种前后的依赖关系。 强化学习和非监督学习的区别。也还是在奖励值这个地方。非监督学习是没有输出值也没有奖励值的，它只有数据特征。同时和监督学习一样，数据之间也都是独立的，没有强化学习这样的前后依赖关系。 基本概念强化学习任务通常使用马尔可夫决策过程（Markov Decision Process，简称MDP）来描述，具体而言：机器处在一个环境中，每个状态为机器对当前环境的感知；机器只能通过动作来影响环境，当机器执行一个动作后，会使得环境按某种概率转移到另一个状态；同时，环境会根据潜在的奖赏函数反馈给机器一个奖赏。综合而言，强化学习主要包含四个要素：状态、动作、转移概率以及奖赏函数。 状态（X）：机器对环境的感知，所有可能的状态称为状态空间；动作（A）：机器所采取的动作，所有能采取的动作构成动作空间；转移概率（P）：当执行某个动作后，当前状态会以某种概率转移到另一个状态；奖赏函数（R）：在状态转移的同时，环境给反馈给机器一个奖赏。 因此，强化学习的主要任务就是通过在环境中不断地尝试，根据尝试获得的反馈信息调整策略，最终生成一个较好的策略π，机器根据这个策略便能知道在什么状态下应该执行什么动作。常见的策略表示方法有以下两种： 确定性策略：π（x）=a，即在状态x下执行a动作；随机性策略：P=π（x,a），即在状态x下执行a动作的概率。 一个策略的优劣取决于长期执行这一策略后的累积奖赏，换句话说：可以使用累积奖赏来评估策略的好坏，最优策略则表示在初始状态下一直执行该策略后，最后的累积奖赏值最高。长期累积奖赏通常使用下述两种计算方法： K摇臂赌博机首先我们考虑强化学习最简单的情形：仅考虑一步操作，即在状态x下只需执行一次动作a便能观察到奖赏结果。易知：欲最大化单步奖赏，我们需要知道每个动作带来的期望奖赏值，这样便能选择奖赏值最大的动作来执行。若每个动作的奖赏值为确定值，则只需要将每个动作尝试一遍即可，但大多数情形下，一个动作的奖赏值来源于一个概率分布，因此需要进行多次的尝试。 单步强化学习实质上是K-摇臂赌博机（K-armed bandit）的原型，一般我们尝试动作的次数是有限的，那如何利用有限的次数进行有效地探索呢？这里有两种基本的想法： 仅探索法：将尝试的机会平均分给每一个动作，即轮流执行，最终将每个动作的平均奖赏作为期望奖赏的近似值。 仅利用法：将尝试的机会分给当前平均奖赏值最大的动作，隐含着让一部分人先富起来的思想。 可以看出：上述两种方法是相互矛盾的，仅探索法能较好地估算每个动作的期望奖赏，但是没能根据当前的反馈结果调整尝试策略；仅利用法在每次尝试之后都更新尝试策略，符合强化学习的思维，但容易找不到最优动作。因此需要在这两者之间进行折中。 折中1： ε-贪心 ε-贪心法基于一个概率来对探索和利用进行折中，具体而言：在每次尝试时，以ε的概率进行探索，即以均匀概率随机选择一个动作；以1-ε的概率进行利用，即选择当前最优的动作。ε-贪心法只需记录每个动作的当前平均奖赏值与被选中的次数，便可以增量式更新。 折中2： Softmax Softmax算法则基于当前每个动作的平均奖赏值来对探索和利用进行折中，Softmax函数将一组值转化为一组概率，值越大对应的概率也越高，因此当前平均奖赏值越高的动作被选中的几率也越大。Softmax函数如下所示： 有模型学习若学习任务中的四个要素都已知，即状态空间、动作空间、转移概率以及奖赏函数都已经给出，这样的情形称为“有模型学习”。假设状态空间和动作空间均为有限，即均为离散值，这样我们不用通过尝试便可以对某个策略进行评估。 策略评估前面提到：在模型已知的前提下，我们可以对任意策略的进行评估（后续会给出演算过程）。一般常使用以下两种值函数来评估某个策略的优劣： 状态值函数（V）：V（x），即从状态x出发，使用π策略所带来的累积奖赏； 状态-动作值函数（Q）：Q（x,a），即从状态x出发，执行动作a后再使用π策略所带来的累积奖赏。 根据累积奖赏的定义，我们可以引入T步累积奖赏与r折扣累积奖赏： 折扣累计奖励： $\gamma$是奖励衰减因子，在[0，1]之间。如果为0，则是贪婪法，即价值只由当前延时奖励决定，如果是1，则所有的后续状态奖励和当前奖励一视同仁。大多数时候，我们会取一个0到1之间的数字，即当前延时奖励的权重比后续奖励的权重大。 含义是虽然当前动作会给一个延时奖励$r_t$，即使当前奖励很高，但到了$t+1、t+2$等时刻，后续的延时奖励不一定也高。比如下象棋，我们可以某个动作可以吃掉对方的车，这个延时奖励是很高，但是接着后面我们输棋了。此时吃车的动作奖励值高但是价值并不高。 由于MDP具有马尔可夫性，即现在决定未来，将来和过去无关，我们很容易找到值函数的递归关系： 关于上面的推导： π（x，a）指的是在x状态下执行a动作的概率 执行a动作后达到的状态不是唯一的，也是一个概率，所以$P^a_{x\rightarrow x^{‘}}$指的是执行a动作后到达x状态的概率 以上的公式可以理解为，T步的累计奖励分为第一步的奖励和后T-1步的累积奖励 后T-1步的奖励为$V^π_{T-1}(x^{‘})$，权重为$\frac{T-1}{T}$ 第一步的奖励为$R^a_{x\rightarrow x^{‘}}$ 最后需要在外面考虑执行a动作的概率和执行a动作后到达$x^{‘}$状态的概率 类似地，对于r折扣累积奖赏可以得到： 易知：当模型已知时，策略的评估问题转化为一种动态规划问题，即以填表格的形式自底向上，先求解每个状态的单步累积奖赏，再求解每个状态的两步累积奖赏，一直迭代逐步求解出每个状态的T步累积奖赏。算法流程如下所示： 对于状态-动作值函数，只需通过简单的转化便可得到： 策略改进理想的策略应能使得每个状态的累积奖赏之和最大，简单来理解就是：不管处于什么状态，只要通过该策略执行动作，总能得到较好的结果。因此对于给定的某个策略，我们需要对其进行改进，从而得到最优的值函数 最优Bellman等式改进策略的方式为：将策略选择的动作改为当前最优的动作，而不是像之前那样对每种可能的动作进行求和。易知：选择当前最优动作相当于将所有的概率都赋给累积奖赏值最大的动作，因此每次改进都会使得值函数单调递增。 策略迭代： 初始策略，策略评估，然后策略改进……不断迭代 将策略评估与策略改进结合起来，我们便得到了生成最优策略的方法：先给定一个随机策略，现对该策略进行评估，然后再改进，接着再评估/改进一直到策略收敛、不再发生改变。这便是策略迭代算法，算法流程如下所示： 可以看出：策略迭代法在每次改进策略后都要对策略进行重新评估，因此比较耗时。 值迭代：策略改进与值函数的改进是一致的，因此可以将策略改进视为值函数的改善 若从最优化值函数的角度出发，即先迭代得到最优的值函数，再来计算如何改变策略，这便是值迭代算法，算法流程如下所示： 免模型学习蒙特卡罗强化学习在现实的强化学习任务中，环境的转移函数与奖赏函数往往很难得知，因此我们需要考虑在不依赖于环境参数的条件下建立强化学习模型，这便是免模型学习。蒙特卡罗强化学习便是其中的一种经典方法。 由于模型参数未知，状态值函数不能像之前那样进行全概率展开，从而运用动态规划法求解。一种直接的方法便是通过采样来对策略进行评估/估算其值函数，蒙特卡罗强化学习正是基于采样来估计状态-动作值函数：对采样轨迹中的每一对状态-动作，记录其后的奖赏值之和，作为该状态-动作的一次累积奖赏，通过多次采样后，使用累积奖赏的平均作为状态-动作值的估计，并引入ε-贪心策略保证采样的多样性。 在上面的算法流程中，被评估和被改进的都是同一个策略，因此称为同策略蒙特卡罗强化学习算法。引入ε-贪心仅是为了便于采样评估，而在使用策略时并不需要ε-贪心，那能否仅在评估时使用ε-贪心策略，而在改进时使用原始策略呢？这便是异策略蒙特卡罗强化学习算法。 参考： 周志华《Machine Learning》强化学习 井字棋实例来自： https://www.cnblogs.com/pinard/p/9385570.html 代码：github 首先看第一个要素环境的状态$S$。这是一个九宫格，每个格子有三种状态，即没有棋子(取值0)，有第一个选手的棋子（取值1），有第二个选手的棋子（取值-1）。那么这个模型的状态一共有$3^9=1968339=19683$个 接着我们看个体的动作$A$，这里只有9个格子，每次也只能下一步，所以最多只有9个动作选项。实际上由于已经有棋子的格子是不能再下的，所以动作选项会更少。实际可以选择动作的就是那些取值为0的格子。 第三个是环境的奖励$R$，这个一般是我们自己设计。由于我们的目的是赢棋，所以如果某个动作导致的改变到的状态可以使我们赢棋，结束游戏，那么奖励最高，反之则奖励最低。其余的双方下棋动作都有奖励，但奖励较少。特别的，对于先下的棋手，不会导致结束的动作奖励要比后下的棋手少。]]></content>
      <categories>
        <category>AI</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NLP一]]></title>
    <url>%2F2020%2F08%2F02%2FNLP%E4%B8%80%2F</url>
    <content type="text"><![CDATA[NLP 正则表达式验证工具：http://regexr.com/ 练习地址： https://alf.nu/RegexGolf 1234567891011import re # 将正则表达式编译成Pattern对象pattern = re.compile(r'hello.*\!') # 使用Pattern匹配文本，获得匹配结果，无法匹配时将返回Nonematch = pattern.match('hello, hanxiaoyang! How are you?') if match: # 使用Match获得分组信息 print match.group() jiebajieba一般用来完成中文分词 jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator 123456789101112131415161718192021import jiebaseg_list = jieba.cut("我在学习自然语言处理", cut_all=True)print seg_listprint("Full Mode: " + "/ ".join(seg_list)) # 全模式seg_list = jieba.cut("我在学习自然语言处理", cut_all=False)print("Default Mode: " + "/ ".join(seg_list)) # 精确模式seg_list = jieba.cut("他毕业于上海交通大学，在百度深度学习研究院进行研究") # 默认是精确模式print(", ".join(seg_list))seg_list = jieba.cut_for_search("小明硕士毕业于中国科学院计算所，后在哈佛大学深造") # 搜索引擎模式print(", ".join(seg_list))'''Full Mode: 我/ 在/ 学习/ 自然/ 自然语言/ 语言/ 处理Default Mode: 我/ 在/ 学习/ 自然语言/ 处理他, 毕业, 于, 上海交通大学, ，, 在, 百度, 深度, 学习, 研究院, 进行, 研究小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 哈佛, 大学, 哈佛大学, 深造''' jieba.lcut以及jieba.lcut_for_search直接返回 list 12345678910result_lcut = jieba.lcut("小明硕士毕业于中国科学院计算所，后在哈佛大学深造")print result_lcutprint " ".join(result_lcut)print " ".join(jieba.lcut_for_search("小明硕士毕业于中国科学院计算所，后在哈佛大学深造"))'''[u'\u5c0f\u660e', u'\u7855\u58eb', u'\u6bd5\u4e1a', u'\u4e8e', u'\u4e2d\u56fd\u79d1\u5b66\u9662', u'\u8ba1\u7b97\u6240', u'\uff0c', u'\u540e', u'\u5728', u'\u54c8\u4f5b\u5927\u5b66', u'\u6df1\u9020']小明 硕士 毕业 于 中国科学院 计算所 ， 后 在 哈佛大学 深造小明 硕士 毕业 于 中国 科学 学院 科学院 中国科学院 计算 计算所 ， 后 在 哈佛 大学 哈佛大学 深造''' 添加用户自定义字典很多时候我们需要针对自己的场景进行分词，会有一些领域内的专有词汇。 1.可以用jieba.load_userdict(file_name)加载用户字典 2.少量的词汇可以自己用下面方法手动添加： 用 add_word(word, freq=None, tag=None) 和 del_word(word) 在程序中动态修改词典 用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。 12345678print('/'.join(jieba.cut('如果放到旧字典中将出错。', HMM=False)))# 如果/放到/旧/字典/中将/出错/。jieba.suggest_freq(('中', '将'), True)# 494print('/'.join(jieba.cut('如果放到旧字典中将出错。', HMM=False)))# 如果/放到/旧/字典/中/将/出错/。 关键词提取基于 TF-IDF 算法的关键词抽取import jieba.analyse jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=()) sentence 为待提取的文本 topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20 withWeight 为是否一并返回关键词权重值，默认值为 False allowPOS 仅包括指定词性的词，默认值为空，即不筛选 12345678910import jieba.analyse as analyselines = open('NBA.txt').read()print " ".join(analyse.extract_tags(lines, topK=20, withWeight=False, allowPOS=()))韦少 杜兰特 全明星 全明星赛 MVP 威少 正赛 科尔 投篮 勇士 球员 斯布鲁克 更衣柜 张卫平 三连庄 NBA 西部 指导 雷霆 明星队lines = open(u'西游记.txt').read()print " ".join(analyse.extract_tags(lines, topK=20, withWeight=False, allowPOS=()))行者 八戒 师父 三藏 唐僧 大圣 沙僧 妖精 菩萨 和尚 那怪 那里 长老 呆子 徒弟 怎么 不知 老孙 国王 一个 基于 TextRank 算法的关键词抽取 jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=(‘ns’, ‘n’, ‘vn’, ‘v’)) 直接使用，接口相同，注意默认过滤词性。 jieba.analyse.TextRank() 新建自定义 TextRank 实例 算法论文： TextRank: Bringing Order into Texts 基本思想: 将待抽取关键词的文本进行分词 以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图 计算图中节点的PageRank，注意是无向带权图 词性标注 jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。jieba.posseg.dt 为默认词性标注分词器。 标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。 具体的词性对照表参见计算所汉语词性标记集 123456789import jieba.posseg as psegwords = pseg.cut("我爱自然语言处理")for word, flag in words: print('%s %s' % (word, flag)) 我 r爱 v自然语言 l处理 v 并行分词原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升 基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows 12jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数jieba.disable_parallel() # 关闭并行分词模式 Word2VecWord2vec，把词映射为实数域向量的技术也叫词嵌入（word embedding）,不使用onehot编码 两个生成词汇向量的算法 两套效率中等的训练算法 Skip-gram由于onthot编码的向量相互正交，无法通过内积进行相似度计算，因此将onthot编码的词向量转换为d维的向量。 方法是用监督学习（窗口内的背景词作为监督信息）进行训练，最后只取隐层信息（fake task），也就是权重矩阵作为映射后的向量表达。为了将onthot编码映射到d维（假设d=300），那么想到的方法是矩阵运算，由于一个单词的onthot编码大小是n维（n为单词数），为了映射到300维，需要一个n*300大小的矩阵。 对于输入的一个词（onehot）和权重矩阵相乘，取其对应的列（lookup）,得到稠密的向量表示。第一个权重矩阵为中心词矩阵，第二个为上下文矩阵，一个词有两种向量表达（可能作为中心词，也可能作为上下文）。矩阵随机初始化 训练样本是（input word, output word ) 这样的单词对，如（dirve, car）,这种单词对从窗口里面取 这一个红框就代表一个样本，这三个红框其实是用三个样本训练了三次 和所有单词做内积（近似为相似度），通过监督学习进行训练 https://blog.csdn.net/weixin_41843918/article/details/90312339 n-gram如果有一个由 m 个词组成的序列（或者说一个句子），我们希望算得概率 ，根据链式规则，可得 这个概率显然并不好算，不妨利用马尔科夫链的假设，即当前这个词仅仅跟前面几个有限的词相关，因此也就不必追溯到最开始的那个词，这样便可以大幅缩减上述算式的长度。即 这个马尔科夫链的假设为什么好用？我想可能是在现实情况中，大家通过真实情况将n=1，2，3，….这些值都试过之后，得到的真实的效果和时间空间的开销权衡之后，发现能够使用 下面给出一元模型，二元模型，三元模型的定义： 当 n=1, 一个一元模型（unigram model)即为 ： 当 n=2, 一个二元模型（bigram model)即为 ： 当 n=3, 一个三元模型（trigram model)即为 然后下面的思路就很简单了，在给定的训练语料中，利用贝叶斯定理，将上述的条件概率值（因为一个句子出现的概率都转变为右边条件概率值相乘了）都统计计算出来即可。下面会给出具体例子讲解。这里先给出公式： 对第一个进行解释，后面同理,如下： 下面给出具体的例子。 下面例子来自于：自然语言处理中的N-Gram模型详解 - 白马负金羁 - CSDN博客和《北京大学 常宝宝 以及 The University of Melbourne “Web Search and Text Analysis” 课程的幻灯片素材》 假设现在有一个语料库，我们统计了下面的一些词出现的数量 下面的这些概率值作为已知条件： p(want|&lt; s&gt;) = 0.25​ 下面这个表给出的是基于Bigram模型进行计数之结果 例如，其中第一行，第二列 表示给定前一个词是 $i$时，当前词为$want$的情况一共出现了827次。据此，我们便可以算得相应的频率分布表如下。 比如说，我们就以表中的$p(eat|i)=0.0036$这个概率值讲解，从表一得出$i$一共出现了2533次，而其后出现$eat$的次数一共有9次，$p(eat|i)=p(eat,i)/p(i)=count(i,eat)/count(i)=9/2533 = 0.0036$ 下面我们通过基于这个语料库来判断s1= &lt; s&gt; i want english food&lt; /s&gt; ​与​s2 = &lt; s&gt; want i english food&lt; /s>​哪个句子更合理： 首先判断p(s1) P(s1)=P(i|)P(want|i)P(english|want)P(food|english)P(|food) =\\0.25×0.33×0.0011×0.5×0.68=0.000031再求p(s2)？ P(s2)=P(want|)P(i|want)P(english|want)P(food|english)P(|food) =\\0.25*0.0022*0.0011*0.5*0.68 = 0.00000002057通过比较我们可以明显发现$0.00000002057&lt;0.000031$,也就是说s1= i want english food更像人话。 再深层次的分析，我们可以看到这两个句子的概率的不同，主要是由于顺序i want还是want i的问题，根据我们的直觉和常用搭配语法，i want要比want i出现的几率要大很多。所以两者的差异，第一个概率大，第二个概率小，也就能说的通了。 Beam SearchBeam search（集束）和Greedy search（贪心）解码常用的算法。 在机器翻译中，beam search算法在测试的时候用的，因为在训练过程中，每一个decoder的输出是有与之对应的正确答案做参照，也就不需要beam search去加大输出的准确率。 以中翻英作为例子： 12我 爱 学习，学习 使 我 快乐I love learning, learning makes me happy 记中文序列为$X$，首先使用seq2seq中的encoder对中文序列进行编码，得到语义向量$C$ 之后decoder对语义向量$C$进行解码，翻译成目标语言。解码之前需要设置beam size，为k个最有可能的结果。此处设置为3. 来看解码器的第一个输出$y_1$，在给定语义向量$C$的情况下，首先选择英语词汇表中最有可能k个单词，也就是依次选择条件概率$P(y_1∣C)$前3大对应的单词，比如这里概率最大的前三个单词依次是：$I，learning，happy$ 接着生成第二个输出$y_2$，在这个时候我们得到了那些东西呢，首先我们得到了编码阶段的语义向量$C$，还有第一个输出$y_1$。此时有个问题，$y_1$有三个，怎么作为这一时刻的输入呢（解码阶段需要将前一时刻的输出作为当前时刻的输入），答案就是都试下，具体做法是： 确定$I$为第一时刻的输出，将其作为第二时刻的输入，得到在已知$(C, I)$的条件下，各个单词作为该时刻输出的条件概率$P(y_2|C,I)$，有6个组合，每个组合的概率为$P(I|C)P(y_2|C, I)$。 确定$leanring$为第一时刻的输出，将其作为第二时刻的输入，得到该条件下，词汇表中各个单词作为该时刻输出的条件概率$P(y_2|C, learning)$，这里同样有6种组合； 确定$happy$为第一时刻的输出，将其作为第二时刻的输入，得到该条件下各个单词作为输出的条件概率$P(y_2|C, happy)$，得到6种组合，概率的计算方式和前面一样。 这样就得到了18个组合，每一种组合对应一个概率值$P(y_1|C)P(y_2|C, y_1)$，接着在这18个组合中选择概率值top3的那三种组合，假设得到$Ilove,Ihappy,leanring make$。接下来要做的重复这个过程，逐步生成单词，直到遇到结束标识符停止。最后得到概率最大的那个生成序列。其概率为： P(Y|C)=P(y_1|C)P(y_2|C,y_1),...,P(y_6|C,y_1,y_2,y_3,y_4,y_5)以上就是Beam search算法的思想，当beam size=1时，就变成了贪心算法。]]></content>
      <categories>
        <category>AI</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>AI，NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数、概率论]]></title>
    <url>%2F2020%2F04%2F08%2F%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E3%80%81%E6%A6%82%E7%8E%87%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[线性代数特征值、特征向量 对角矩阵 A= \begin{bmatrix} \lambda_{1}\\ &\lambda_{2}\\ &&\ddots \\ &&& \lambda_{n} \end{bmatrix} 矩阵相似 若矩阵$A$和矩阵$B$都是n阶矩阵，如果存在可逆矩阵$P$，使得 $P^{-1}AP=B$，则称$A$、$B$相似，记作$A\sim B$ 矩阵相似对角化 如果一个n阶矩阵$A$有n个线性无关的特征向量，那么矩阵$A$与由其特征值所组成的对角矩阵（$Λ$）相似，即： $A\simΛ$ 对$A$的特征分解： 有一个NxN的矩阵$A$ $A$有N个线性无关的特征向量（$A\simΛ$） 由矩阵相似定义，则$P^{-1}AP=Λ$ 两边同时左乘$P$，右乘$P^{-1}$，得到$A=PΛP^{-1}$ 如果 $\upsilon$ 是$A$的特征向量，那么任何缩放后的向量 $s\upsilon\ (s∈R，s\neq0 ) $也是 $A$ 的 特征向量。此外，$s\upsilon$和 $\upsilon$ 有相同的特征值。基于这个原因，通常我们只考虑单位特征向量。 假设矩阵$A$有 n 个线性无关的特征向量 ${\upsilon^{(1)},…,\upsilon^{(n)}}$，对应着特征值 ${λ1,…,λn}$。我们将特征向量连接成一个矩阵，使得每一列是一个特征向量：$V = [\upsilon^{(1)},…,\upsilon^{(n)}]$类似地，我们也可以将特征值连接成一个向量 $λ =[λ1,…,λn]^⊤$。 因此$A$的特征分解（eigendecomposition）可以记作 A = Vdiag(λ)V^{-1}我们将实对称矩阵分解成实特征向量和实特征值： A=QΛQ^{T}其中$Q$是$A$的特征向量组成的正交矩阵，$Λ$是对角矩阵，特征值$Λ{i,i}$对应的特征向量是矩阵$Q$的第$i$列，记作$Q{:,i}$，由于$Q$是正交矩阵，可以将$A$看作沿方向$v^{i}$延展$λ_{i}$倍的空间。 虽然任意一个实对称矩阵$A$都有特征分解，但是特征分解可能并不唯一。如果两个或多个特征向量拥有相同的特征值，那么在由这些特征向量产生的生成子空间中，任意一组正交向量都是该特征值对应的特征向量。因此，我们可以等价地从这 些特征向量中构成$Q$作为替代。按照惯例，我们通常按降序排列$Λ$的元素。在该 约定下，特征分解唯一当且仅当所有的特征值都是唯一的。 矩阵的特征分解给了我们很多关于矩阵的有用信息。矩阵是奇异的当且仅当含 有零特征值。 所有特征值都是正数的矩阵被称为正定（positive deﬁnite）；所有特征值都是非 负数的矩阵被称为半正定（positive semideﬁnite）。同样地，所有特征值都是负数的 矩阵被称为负定（negative deﬁnite）；所有特征值都是非正数的矩阵被称为 半负定 （negative semideﬁnite）。 半正定矩阵受到关注是因为它们保证 $∀x,x^{T}Ax≥0$。此外， 正定矩阵还保证$x^{T}Ax=0\Rightarrow x=0$。 矩阵的秩、奇异值、数据降维 奇异值分解与低秩近似 奇异值分解矩阵除了特征分解还有另一种分解方法，被称为奇异值分解（singular value decomposition, SVD），将矩阵分 解为奇异向量（singular vector）和奇异值（singular value）。通过奇异值分解，我们会得到一些与特征分解相同类型的信息。然而，奇异值分解有更广泛的应用。每 个实数矩阵都有一个奇异值分解，但不一定都有特征分解。例如，非方阵的矩阵没有特征分解，这时我们只能使用奇异值分解。 奇异值分解将矩阵$A$分解成三个矩阵的乘积： A=UDV^{T}假设$A$是一个 m×n 的矩阵，那么$U$是一个 m×m 的矩阵，$D$是一个 m×n 的矩阵，$V$是一个 n×n 矩阵。 这些矩阵中的每一个经定义后都拥有特殊的结构。矩阵$U$和$V$都定义为正交 矩阵，而矩阵$D$定义为对角矩阵。注意，矩阵$D$不一定是方阵。 对角矩阵$D$对角线上的元素被称为矩阵$A$的奇异值（singular value）。矩阵$U$的列向量被称为左奇异向量（left singular vector），矩阵$V$的列向量被称右奇异向量（right singular vector）。 事实上，我们可以用与$A$相关的特征分解去解释$A$的奇异值分解。$A$的左奇异向量（leftsingularvector）是$AA^{T}$的特征向量。$A$的右奇异向量（rightsingular vector）是$A^{T}A$的特征向量。$A$的非零奇异值是$A^{T}A$特征值的平方根，同时也是$AA^{T}$特征值的平方根。 SVD有用的一个性质可能是拓展矩阵求逆到非方矩阵上。 迹运算迹运算返回的是矩阵对角元素的和： Tr(A)=\sum_{i}A_{i,i·}迹运算有如下性质： Tr(A)=Tr(A^{T})循环置换（将最后一个移到最前面）： Tr(ABC)=Tr(CAB)=Tr(BCA)对于标量a： a=Tr(a)PCA http://blog.codinglabs.org/articles/pca-tutorial.html code1234567891011121314def pca(dataMat, topNfeat=9999999): # topNfeat：output top N features meanVals = np.mean(dataMat, axis=0) # to compute the mean value meanRemoved = dataMat - meanVals # to remove the mean value covMat = np.cov(meanRemoved, rowvar=0) # to compute the covariance matrix # if rowvar = True -&gt; row store dimension , col store Observation value eigVals, eigVects = np.linalg.eig(np.mat(covMat)) # to compute the eigenvalues and eigenvectors eigValInd = np.argsort(eigVals) # to sort from the smallest to the largest eigValInd = eigValInd[:-(topNfeat + 1):-1] # to get the nth largest eigenvalues and eigenvectors redEigVects = eigVects[:, eigValInd] lowDDataMat = meanRemoved * redEigVects # to transform into low dimensions reconMat = (lowDDataMat * redEigVects.T) + meanVals cumCont = sum(eigVals[eigValInd]) / sum(eigVals) # to compute cumulative contribution return lowDDataMat, reconMat, cumCont 概率论方差、协方差 协方差 协方差的绝对值如果很大则意味着变量值变化很大并且它们同时距离各自的均值很远。如果协方差是正的，那么两个变量都倾向于同时取得相对较大的值。如果协方差是负的，那么其中一个变量倾向于取得相对较大的值的同时，另一个变量倾向于 取得相对较小的值，反之亦然。其他的衡量指标如相关系数（correlation）将每个变量的贡献归一化，为了只衡量变量的相关性而不受各个变量尺度大小的影响。 协方差和相关性是有联系的，但实际上是不同的概念。它们是有联系的，因为 两个变量如果相互独立那么它们的协方差为零，如果两个变量的协方差不为零那么 它们一定是相关的。然而，独立性又是和协方差完全不同的性质。两个变量如果协 方差为零，它们之间一定没有线性关系。独立性比零协方差的要求更强，因为独立 性还排除了非线性的关系。两个变量相互依赖但具有零协方差是可能的。例如，假 设我们首先从区间 [−1,1] 上的均匀分布中采样出一个实数 $x$。然后我们对一个随机变量 $s$ 进行采样。$s$ 以 $\frac{1}{2}$ 的概率值为 1，否则为-1。我们可以通过令 $y = sx$ 来生成 一个随机变量 $y$。显然，$x$ 和 $y$ 不是相互独立的，因为 $x$ 完全决定了 $y$ 的尺度。然 而，$Cov(x,y)=0$。 协方差矩阵 随机向量 $x∈R^{n}$ 的协方差矩阵（covariance matrix）是一个 n×n 的矩阵，并 且满足 Cov(x)_{i,j}=Cov(x_{i},x_{j})协方差矩阵的对角元是方差： Cov(x_{i},x_{j})=Var(x_{i}) 分布Beinoulli分布 Multinoulli分布Multinoulli 分布（multinoulli distribution）或者范畴分布（categorical distribution）是指在具有 $k$ 个不同状态的单个离散型随机变量上的分布，其中 $k$ 是一 个有限值。Multinoulli 分布由向量 $p∈ [0,1]^{k−1}$ 参数化，其中每一个分量 $p_i$ 表示 第 $i$ 个状态的概率。后的第 $k$ 个状态的概率可以通过 $1−1^⊤p$ 给出。注意我们必 须限制 $1^⊤p≤ 1$。Multinoulli 分布经常用来表示对象分类的分布，所以我们很少假设状态 1 具有数值 1 之类的。因此，我们通常不需要去计算 Multinoulli 分布的随机 变量的期望和方差 高斯分布 N(x;µ,σ^2)=\frac{1}{\sqrt{2πσ^2}}exp(-\frac{1}{2σ^2}(x-µ^2))\\ µ ∈R \ , σ ∈ (0,∞)。$µ$ 为中心峰值坐标，也是期望，标准差是σ Dirac分布 p(x)=\delta (x-\mu)Dirac delta 函数被定义成在除了在0取无穷，0以外的所有点的值都为 0，但是积分为 1。 高斯混合模型GMMGMM是一种业界广泛使用的聚类算法，该方法使用了高斯分布作为参数模型，并使用了期望最大（Expectation Maximization，简称EM）算法进行训练，训练过程通过模型来计算数据的期望值。通过更新参数μ和σ来让期望值最大化。 p(x)=\sum_{i=1}^{K}\phi_i\frac{1}{\sqrt{2πσ_i^2}}exp(-\frac{1}{2σ_i^2}(x-µ_i^2))\\首先分布概率是K个高斯分布的和，每个高斯分布有属于自己的$\mu$和$\sigma$参数，以及对应的权重参数，权重值必须为正数，所有权重的和必须等于1，以确保公式给出数值是合理的概率密度值 。 函数logistic sigmoid \sigma(x)=\frac{1}{1+exp(-x)}sigmoid函数通常用来产生Beinoulli分布中的参数$\phi$，因为范围是(0,1) softplus \zeta(x)=log(1+exp(x))softplus可以用来产生正态分布的$\beta$和$\sigma$参数，因为范围是$(0,∞)$ 性质 逻辑回归与最大似然 频率学派、贝叶斯 贝叶斯贝叶斯公式 P(x|y)=\frac{P(x)P(y|x)}{P(y)} P(A_i|B)=\frac{P(B|A_i)P(A_i)}{\sum_jP(B|A_j)P(A_j)}Pr(A)是A的先验概率或边缘概率。之所以称为”先验”是因为它不考虑任何B方面的因素。 Pr(A|B)是已知B发生后A的条件概率，也由于得自B的取值而被称作A的后验概率。 Pr(B|A)是已知A发生后B的条件概率，也由于得自A的取值而被称作B的后验概率。 Pr(B)是B的先验概率或边缘概率，也作标准化常量（normalized constant）。 意义123456789例如：一座别墅在过去的 20 年里一共发生过 2 次被盗，别墅的主人有一条狗，狗平均每周晚上叫 3 次，在盗贼入侵时狗叫的概率被估计为 0.9，问题是：在狗叫的时候发生入侵的概率是多少？我们假设 A 事件为狗在晚上叫，B 为盗贼入侵，则以天为单位统计，P(A) = 3/7，P(B) = 2/(20*365) = 2/7300，P(A|B) = 0.9，按照公式很容易得出结果：P(B|A) = 0.9*(2/7300) / (3/7) = 0.00058另一个例子，现分别有 A、B 两个容器，在容器 A 里分别有 7 个红球和 3 个白球，在容器 B 里有 1 个红球和 9 个白球，现已知从这两个容器里任意抽出了一个红球，问这个球来自容器 A 的概率是多少?假设已经抽出红球为事件 B，选中容器 A 为事件 A，则有：P(B) = 8/20，P(A) = 1/2，P(B|A) = 7/10，按照公式，则有：P(A|B) = (7/10)*(1/2) / (8/20) = 0.875贝叶斯公式为利用搜集到的信息对原有判断进行修正提供了有效手段。在采样之前，经济主体对各种假设有一个判断（先验概率），关于先验概率的分布，通常可根据经济主体的经验判断确定（当无任何信息时，一般假设各先验概率相同），较复杂精确的可利用包括最大熵技术或边际分布密度以及相互信息原理等方法来确定先验概率分布 信息论信息论是应用数学的一个分支，主要研究的是对一个信号包含信息的多少进行量化。它初被发明是用来研究在一个含有噪声的信道上用离散的字母表来发送消息，例如通过无线电传输来通信。在这种情况下，信息论告诉我们如何对消息设计最优编码以及计算消息的期望长度，这些消息是使用多种不同编码机制、从特定的概率分布上采样得到的。在机器学习中，我们也可以把信息论应用于连续型变量， 此时某些消息长度的解释不再适用。信息论是电子工程和计算机科学中许多领域的基础。我们主要使用信息论的一些关键思想来描述概率分布或者量化概率分布之间的相似性。 量化信息的基本想法 非常可能发生的事件信息量要比较少，并且极端情况下，确保能够发生的事件应该没有信息量。 较不可能发生的事件具有更高的信息量。 独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量， 应该是投掷一次硬币正面朝上的信息量的两倍 定义一个事件 x = $x$ 的自信息（self-information）为： I(x)=-logP(x)$I(x)$ 单 位是奈特（nats）。一奈特是以 $\frac{1}{e}$ 的概率观测到一个事件时获得的信息量。其他的材料中使用底数为 2 的对数，单位是比特（bit）或者香农（shannons）；通过比特度量的信息只是通过奈特度量信息的常数倍。 当 x 是连续的，我们使用类似的关于信息的定义，但有些来源于离散形式的性质就丢失了。例如，一个具有单位密度的事件信息量仍然为 0，但是不能保证它一定 发生。 自信息只处理单个的输出。我们可以用香农熵（Shannon entropy）来对整个概 率分布中的不确定性总量进行量化： H(x)=E_{x\sim P}[I(x)]=-E_{x\sim P}[log(P(x))]一个分布的香农熵是指遵循这个分布的事件所产生的期望信息总量。它给出了对依据概率分布 $P$ 生成的符号进行编码所需的比特数在平均意义上的下界 (当对数底数不是 2 时，单位将有所不同)。那些接近确定性的分布 (输出几 乎可以确定) 具有较低的熵；那些接近均匀分布的概率分布具有较高的熵。下图给出了一个说明。当x是连续的，香农熵被称为微分熵（diﬀerential entropy）。 KL散度如果我们对于同一个随机变量 t 有两个单独的概率分布 $P(x)$ 和 $Q(x)$，我们可以使用KL 散度（Kullback-Leibler (KL) divergence）来衡量这两个分布的差异 D_{KL}(P||Q)=E_{x\sim P}[log\frac{P(x)}{Q(x)}]=E_{x\sim P}[logP(x)-logQ(x)]在离散型变量的情况下，KL 散度衡量的是，当我们使用一种被设计成能够使得概率分布$Q$产生的消息的长度最小的编码，发送包含由概率分布$P$产生的符号 的消息时，所需要的额外信息量 (如果我们使用底数为 2 的对数时，信息量用比特衡量，但在机器学习中，我们通常用奈特和自然对数。) KL 散度有很多有用的性质，最重要的是它是非负的。KL 散度为 0 当且仅当$P$和$Q$在离散型变量的情况下是相同的分布，或者在连续型变量的情况下是 ‘‘几乎处处’’ 相同的。因为 KL 散度是非负的并且衡量的是两个分布之间的差异，它经常被用作分布之间的某种距离。然而，它并不是真的距离因为它不是对称的：对于某 些$P$和$Q$，$D{KL}(P||Q)\neq D{KL}(Q||P)$。这种非对称性意味着选择$D{KL}(P||Q)$ 还是$D{KL}(Q||P)$ 影响很大 一个和 KL 散度密切联系的量是交叉熵（cross-entropy）$H(P,Q)=H(P)+ D_{KL}(P||Q)$，它和 KL 散度很像但是缺少左边一项： H(P,Q)=-E_{x\sim P}logQ(x)针对 $Q$ 最小化交叉熵等价于最小化 KL 散度，因为 $Q$ 并不参与被省略的那一项。 当我们计算这些量时，经常会遇到 $0log0$ 这个表达式。按照惯例，在信息论中， 我们将这个表达式处理为 $lim_{x\rightarrow0}xlogx=0$]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GAN]]></title>
    <url>%2F2020%2F03%2F09%2FGAN%2F</url>
    <content type="text"><![CDATA[GAN 判别器的目标函数： 最大化真实样本的期望（输出为Real），最小化从人为定义的分布中随机采样的向量（输出为Fake） 生成器目标函数： 最大化从人为定义的分布中随机采样的向量，去欺骗判别器 训练算法 KL散度、JS散度KL散度：衡量两个概率分布匹配程度的指标，当P1=P2时，KL散度为0 KL散度具有非负性，根据吉布斯不等式： KL散度不具有对称性，即 KL(P1||P2) ≠ KL(P2||P1) 因此在试图去拟合两种分布，使KL散度最小时，采用KL(p||q)，和KL(q||p)会得到两种不同的结果 JS散度： 极大似然与最小化KL散度 判别器D 生成器G最大化判别器损失，等价于计算合成数据分布和真实数据分布的JS散度 最小化生成器损失，等价于最小化JS散度（也就是优化生成模型） cGAN DCGAN WGAN Wasserstein距离 Wasserstein损失 权重截断 WGAN缺陷 WGAN-GP SN-GANSN-GAN： 每层权重除以该层矩阵谱范数即可满足利普希茨连续 Self-Attention GAN U-Net Patch GAN Cycle GAN]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RNN]]></title>
    <url>%2F2020%2F03%2F09%2FRNN%2F</url>
    <content type="text"><![CDATA[与CNN区别 CNN输入、输出相互独立 RNN可以更好地处理有时序关系的任务 RNN通过循环结构引入“记忆”概念（输出不仅依赖于输入，还依赖于记忆，将同一个结构循环利用） 基本结构 深度RNN 双向RNN BPTT算法 每一个时刻t的损失，取输出的y与真实值的交叉熵 总损失为各个时刻t的总损失 由于h3与h2相关，具有时序关系，所以需要展开对h2求偏导，根据链式法则，得到偏导： 传统RNN问题 对权重求偏导，对于累乘项来说，当t比较大时， 如果0&lt;W&lt;1,梯度趋于0 如果W&gt;1,梯度趋于无穷 LSTM LSTM与RNN区别 RNN记忆单元ht是累乘形式，复合函数的嵌套。 LSTM是累加形式 由于RNN是通过tanh非线性变换，所以经过较长时间后，之前的记忆会被覆盖 而LSTM是线性相加，而遗忘门ft通常接近1，所以之前的记忆会一定程度保存，解决了梯度消失问题 为了解决梯度爆炸问题，可以设置较小的learning rate GRU门控循环单元 Clockwise RNNClockwise RNN: 普通 RNN 都是隐层从前一个时间步连接到当前时间 步。而 CW-RNN 把隐层分成很多组，每组有不同的循环周期，有的周 期是 1（和普通 RNN 一样），有的周期更长（例如从前两个时间步连 接到当前时间步，不同周期的 cell 之间也有一些连接。这样一来，距离 较远的某个依赖关系就可以通过周期较长的 cell 少数几次循环访问到， 从而网络层数不太深，更容易学到。 Attention 人们在进行观察图像的时候，大多是根据需求将注意力集中到图像的特定部分。而且人类会根据之前观察的图像学习到未来要观察图像注意力应该集中的位置。 评价准则 更高的召回率可能导致准确率下降，二者围成的面积称为平均准确率。 R-CNN 用Selective Search方法产生目标候选 由于卷积时全连接层对输入尺寸的要求，先进性规整，然后利用CNN提取特征 传入SVM进行分类 （1）CNN需要大量的训练样本（对样本质量的要求松）； （2）SVM用少量的样本就可以训练（对样本质量的要求严）。 SPP-NET 传统CNN要求输入图片尺寸一致，SPP-net在全连接层之前加入一个空间金字塔池化层 Fast-RCNN 将图片的规整转化为对特征图的规整 将单独的SVM分类任务转化为CNN中的Softmax分类任务，并且将误差反向传播，进行全局的优化 Faster RCNN没有使用ss提取方法，而是使用RPN方法,RPN插入到最后一个卷积层后，用于直接产生候选区域，不需要额外算法，RPN之后，使用ROI Poling和后续的分类器、回归器 Faster-RCNN RoI Pooling层利用proposals从feature maps中提取proposal feature送入后续全连接和softmax网络作classification（即分类proposal到底是什么object） Conv layers。作为一种CNN网络目标检测方法，Faster RCNN首先使用一组基础的conv+relu+pooling层提取image的feature maps。该feature maps被共享用于后续RPN层和全连接层。 Region Proposal Networks。RPN网络用于生成region proposals。该层通过softmax判断anchors属于positive或者negative，再利用bounding box regression修正anchors获得精确的proposals。 Roi Pooling。该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。 Classification。利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。 RPN RFCN 共有kk = 9个颜色，每个颜色的立体块（WH(C+1)）表示的是不同位置存在目标的概率值（第一块黄色表示的是左上角位置，最后一块淡蓝色表示的是右下角位置）。共有k^2(C+1)个feature map。每个feature map，z(i,j,c)是第i+k(j-1)个立体块上的第c个map（1&lt;= i,j &lt;=3）。(i,j)决定了9种位置的某一种位置，假设为左上角位置（i=j=1），c决定了哪一类，假设为person类。在z(i,j,c)这个feature map上的某一个像素的位置是（x,y），像素值是value，则value表示的是原图对应的(x,y)这个位置上可能是人（c=‘person’）且是人的左上部位（i=j=1）的概率值 YOLO 把输入图像划分为S*S个网格（S=7）。位于目标中心的网格负责检测该目标 (1) 每个网格预测B个边界框和这个边界框是物体的概率（Objectness）；具体 的，每个边界框会预测出5个值：x,y,w,h和置信度Pr(Object)*IOU(truth&amp;pred) (2) 每个网格预测C个条件概率Pr（Classi|Object） 在测试阶段，预测每个检测框的分数： SSD 在Yolo中，每个单元预测多个边界框，但是其都是相对这个单元本身（正方块），但是真实目标的形状是多变的，Yolo需要在训练过程中自适应目标的形状。而SSD借鉴了Faster R-CNN中anchor的理念，每个单元设置尺度或者长宽比不同的先验框，预测的边界框（bounding boxes）是以这些先验框为基准的，在一定程度上减少训练难度。 对于每个单元的每个先验框，其都输出一套独立的检测值，对应一个边界框，主要分为两个部分。第一部分是各个类别的置信度或者评分，SSD将背景也当做了一个特殊的类别，如果检测目标共有 c个类别，SSD其实需要预测 c+1 个置信度值，其中第一个置信度指的是不含目标或者属于背景的评分。 第二部分就是边界框的location，包含4个值 (cx、cy、w、h)，分别表示边界框的中心坐标以及宽高。 Retina Net由于One Stage方法背景较多，模型大量聚焦在背景中，虽然有些背景很容易分类，但由于数量巨大，导致总和的loss对检测器产生影响。 所以Retina Net通过Focal Loss使得越接近背景的样本权重越小，从而使loss主要来源于更复杂的样本，而不是简单的背景样本]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch实践]]></title>
    <url>%2F2020%2F03%2F05%2FPyTorch%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[PyTorch实践数据集处理官方数据集从PyTorch开源项目：vision或者text中加载数据集，对应的包是torchvision、torchtext 12345678910111213#torchvisionimport torchvisionmnist = torchvision.datasets.MNIST(root='./',download="True")#torchtextimport torchtextWORD = torchtext.data.Field(init_token="&lt;bos&gt;",eos_token="&lt;eos&gt;")UD_TAG = torchtext.data.Field(init_token="&lt;bos&gt;",eos_token="&lt;eos&gt;")train,val,text = torchtext.datasets.UDPOS.splits(field=(('word',WORD),('udtag',UD_TAG),(None,None)))print(train.examples[0].word)print(train.examples[0].udtag) 构建自定义数据集1234567import torch.utils.data as Datax = torch.tensor([1,2,3])y = torch.tensor([0,0,1])#小于2都是0，大于2为1dataset = Data.TensorDataset(x,y) 细粒度构建自定义数据集继承torch.utils.data.Dataset ，然后重载函数len，getitem来构建 1234567891011121314import torch.utils.data as Dataclass Mydataset(Data.Dataset): def __init__(self): #读取文件 pass def __getitem__(self): #获取数据 #预处理 #返回数据对（x,y） pass def __len__(self): #返回数据集大小 pass 12345678910111213141516171819202122232425262728293031import torch.utils.data as Dataperson_1 = ['tall','rich','handsome','1']person_2 = ['n_tall','rich','handsome','1']person_3 = ['n_tall','n_rich','handsome','1']person_4 = ['n_tall','n_rich','n_handsome','0']person = [person_1,person_2,person_3,person_4]class Person(Data.Dataset): def __init__(self,person): self.data = person def __getitem__(self,index): item = self.data[index] x = item[:3] y = item[-1] return x,y def __len__(self): return(len(self.data)) p = Person(person)for index, (x,y) in enumerate(p): print(f"&#123;index&#125; : x:&#123;x&#125;,y:&#123;y&#125;") """0 : x:['tall', 'rich', 'handsome'],y:11 : x:['n_tall', 'rich', 'handsome'],y:12 : x:['n_tall', 'n_rich', 'handsome'],y:13 : x:['n_tall', 'n_rich', 'n_handsome'],y:0""" 加载数据集使用torch.utils.data.Dataloader加载数据集 12345tensor_person_data_loader = Data.DataLoader(dataset = person_dataset, batch_size = batch_size, shuffle = True, sampler = sampler, #怎么抽样 collate_fn = my_collate_fn) #抽样的样本怎么处理 加载自定义数据集： 1234567891011person_loader = Data.Dataloader(dataset = p, batch_size = 2)for index,data in enumerate(person_loader): x,y = data print(f"&#123;index&#125; : x:&#123;x&#125;,y:&#123;y&#125;") """0 : x:[('tall', 'n_tall'), ('rich', 'rich'), ('handsome', 'handsome')],y:('1', '1')1 : x:[('n_tall', 'n_tall'), ('n_rich', 'n_rich'), ('handsome', 'n_handsome')],y:('1', '0')""" 预处理数据集通过_getitem_方法12345678910111213141516171819202122232425262728293031323334353637word2id = &#123;'tall':1,'rich':1,'handsome':1,'n_tall':0,'n_rich':0,'n_handsome':0,'1':1,'0':0&#125;class TensorPerson(Data.Dataset): def __init__(self,person): self.data = person def __getitem__(self,index): item = self.data[index] new_item = [] for feature in item: new_item.append(word2id[feature]) x = new_item[:3] y = new_item[-1] return x,y def __len__(self): return(len(self.data)) p = TensorPerson(person)person_loader = Data.DataLoader(dataset = p, batch_size = 2)for index, data in enumerate(person_loader): x,y = data print(f"&#123;index&#125; : x:&#123;x&#125;,y:&#123;y&#125;") """0 : x:[tensor([1, 0]), tensor([1, 1]), tensor([1, 1])],y:tensor([1, 1])1 : x:[tensor([0, 0]), tensor([0, 0]), tensor([1, 0])],y:tensor([1, 0])""" 通过collate_fn123456789101112131415161718192021222324252627282930313233#定义抽样样本处理方法：def my_collate_fn(batch_data): print("----------") x_batch = [] y_batch = [] for example in batch_data: x,y = example x_batch.append(x) y_batch.append(y) x_batch = torch.tensor(x_batch,dtype = torch.float32) y_batch = torch.tensor(y_batch,dtype = torch.float32) print("----------") return x_batch,y_batchperson_loader = Data.DataLoader(dataset = p, batch_size = 2, collate_fn = my_collate_fn)for index, data in enumerate(person_loader): x,y = data print(f"&#123;index&#125; : x:&#123;x&#125;,y:&#123;y&#125;") """--------------------0 : x:tensor([[1., 1., 1.], [0., 1., 1.]]),y:tensor([1., 1.])--------------------1 : x:tensor([[0., 0., 1.], [0., 0., 0.]]),y:tensor([1., 0.])""" 模型TorchVision支持一些经典模型 Alexnet VGG ResNet SqueezeNet DenseNet Inception v3 TorchText没有统一模型 经典模型以及可视化123456789import torchimport torchvision.modelsimport hiddenlayer as hlfrom torchviz import make_dotresnet = torchvision.models.resnet18()# hl.build_graph(resnet,torch.randn([1,3,224,224]))# 由于版本问题，使用hiddenlayer的可视化可能找不到get_trace_graph方法，从而报错make_dot(resnet(torch.randn([1,3,224,224]))).view() 可以使用torchviz的方法进行可视化，会在目录下生成一个pdf文件 构建自己的神经网络结构sample1234567891011121314my_net = torch.nn.Sequential( torch.nn.Linear(1,10), torch.nn.ReLU(inplace=True), torch.nn.Linear(10,1))my_net"""Sequential( (0): Linear(in_features=1, out_features=10, bias=True) (1): ReLU(inplace=True) (2): Linear(in_features=10, out_features=1, bias=True))""" 构建多层网络12345678hun_layer = [torch.nn.Linear(10,10) for _ in range(100)]"""[Linear(in_features=10, out_features=10, bias=True), Linear(in_features=10, out_features=10, bias=True), `````````````````````````` Linear(in_features=10, out_features=10, bias=True)]""" 深度自定义123456789101112131415161718192021222324import torch.nn as nnclass MyNET(nn.Module): def __init__(self): super(MyNET,self).__init__() pass def forward(self,x): passclass SingleDogCls(nn.Module): def __init__(self,n_feature,n_hidden,n_output): super(SingleDogCls,self).__init__() self.hidden = nn.Linear(n_feature,n_hidden) self.relu = nn.ReLU() self.predict = nn.Linear(n_hidden,n_output) def forward(self,x): x = self.hidden(x) x = self.relu(x) x = self.predict(x) return xw = SingleDogCls(n_feature=3, n_hidden=10, n_output=1)make_dot(w(torch.randn([10,3]))).view() 使用torchviz产生的可视化图不如hiddenlayer的简洁： 1234567891011121314151617181920212223for index,data in enumerate(person_loader): print(f"迭代次数&#123;index&#125;") print(f"data:&#123;data&#125;") input_x,ground_truth = data predict = w(input_x) print(predict,ground_truth)"""--------------------迭代次数0data:(tensor([[1., 1., 1.], [0., 1., 1.]]), tensor([1., 1.]))tensor([[-0.2159], [-0.2262]], grad_fn=&lt;AddmmBackward&gt;) tensor([1., 1.])--------------------迭代次数1data:(tensor([[0., 0., 1.], [0., 0., 0.]]), tensor([1., 0.]))tensor([[-0.0682], [-0.2633]], grad_fn=&lt;AddmmBackward&gt;) tensor([1., 0.])""" 定义损失官方定义的损失函数在两个地方 torch.nn torch.nn.functional torch.nn下面的loss函数，是作为模型的一部分存在，实际上是torch.nn.functional下loss函数的封装，实际上它还是调用了torch.nn.functional下面的函数 123456789a = torch.tensor(2.)b = torch.tensor(5.)print(F.l1_loss(a,b))print(F.mse_loss(a,b))"""tensor(3.)tensor(9.)""" 损失函数torch.nn.functional: binary_cross_entropy binary_cross_entropy_with_logits poisson_nll_loss cross_entropy cosine_embedding_loss ctc_loss hinge_embedding_loss kl_div l1_loss mse_loss margin_ranking_loss multilabel_margin_loss multilabel_soft_margin_loss multi_margin_loss nll_loss smooth_l1_loss soft_margin_loss triplet_margin_loss 如果要定义自己的损失函数，可以： 继承torch.nn.module实现loss（当成模型，计算图中的方块） 继承torch.autograd.function实现loss（当成函数，计算图中的椭圆） 实际区别在于谁去进行反向传播，官方实现中，loss是一个module 继承torch.nn.module实现loss12345678910class MyLoss(nn.Module): def __init__(self): super(MyLoss,self).__init__() def forward(self,x,y): return x*100-y loss = MyLoss()loss(a,b)# tensor(195.) 继承torch.autograd.funcion实现loss适合损失函数非常难求导时 123456789101112131415from torch.autograd import Functionclass MyLossFunc(torch.autograd.Function): def forward(self,a,b): return 2*(a-b) def backward(self,grad_output): print("----------") return grad_output*2,grad_output*2 # a_grad, b_grad a = torch.tensor(1.,requires_grad=True)b = torch.tensor(2.,requires_grad=True)f_loss = MyLossFunc()c = f_loss(a,b)# tensor(-2., grad_fn=&lt;MyLossFunc&gt;) 实现优化算法pytorch集成了常见的优化算法： torch.optim.Adadelta torch.optim.Adagrad torch.optim.Adam torch.optim.Adamax torch.optim.SparseAdam torch.optim.LBFGS torch.optim..RMSprop torch.optim.Rprop torch.optim.SGD 123from torch.optim import Optimizeroptimizer = torch.optim.SGD(w.parameters(),lr=0.05,mometum=0.9) 如果自定义优化算法： 1234class MyOptimizer(Optimizer): def step(self,closure=None): #每一步是怎么优化的 pass 调整学习率pytorch官方，提供了torch.optim.lr_scheduler类来基于动态调整学习率 torch.optim.lr.scheduler.LambdaLR torch.optim.lr.scheduler.StepLR torch.optim.lr.scheduler.MultiStepLR torch.optim.lr.scheduler.ExponentialLR torch.optim.lr.scheduler.CosineAnnealingLR torch.optim.lr.scheduler.ReduceLROnPlateau 12345from torch.optim.lr_scheduler import StepLRscheduler = StepLR(optimizer,step_size=30,gamma=0.1)# 每隔30次迭代就乘gamma,在迭代固定的次数之后以一定的比例降低学习率 迭代训练123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import torchimport torch.utils.data as Dataimport torch.nn as nnfrom torch.optim import Optimizerfrom torch.optim.lr_scheduler import StepLRperson_1 = ['tall','rich','handsome','1']person_2 = ['n_tall','rich','handsome','1']person_3 = ['n_tall','n_rich','handsome','1']person_4 = ['n_tall','n_rich','n_handsome','0']person = [person_1,person_2,person_3,person_4]word2id = &#123;'tall':1,'rich':1,'handsome':1,'n_tall':0,'n_rich':0,'n_handsome':0,'1':1,'0':0&#125;# 将数据表进行封装class ManDataset(Data.Dataset): def __init__(self,person): self.data = person; def __getitem__(self,index): item = self.data[index] new_item = [] for feature in item: new_item.append(word2id[feature]) x = new_item[:3] y = new_item[-1] return x,y def __len__(self): return(len(self.data))# 对数据进行预处理def my_collate_fn(batch_data): x_batch = [] y_batch = [] for example in batch_data: x,y = example x_batch.append(x) y_batch.append(y) x_batch = torch.tensor(x_batch,dtype = torch.float32) y_batch = torch.tensor(y_batch,dtype = torch.float32) return x_batch,y_batch# 创建数据集实例person_dataset = ManDataset(person)# 创建加载器，加载数据集batch_size = 1person_data_loader = Data.DataLoader( dataset=person_dataset, batch_size=batch_size, collate_fn=my_collate_fn)# 实现模型class SingleDog(nn.Module): def __init__(self,n_feature,n_hidden,n_output): super(SingleDog,self).__init__() self.hidden = nn.Linear(n_feature,n_hidden) self.relu = nn.ReLU() self.predict = nn.Linear(n_hidden,n_output) def forward(self,x): x = self.hidden(x) x = self.relu(x) x = self.predict(x) return x# 创建模型实例will_u_be_single = SingleDog(n_feature=3,n_hidden=10,n_output=1)#########will_u_be_single.cuda()########## 创建loss函数single_loss = nn.L1Loss()# 创建优化器optimizer = torch.optim.SGD(will_u_be_single.parameters(),lr=0.1,momentum=0.9)# 根据epoch，自动更新优化器参数scheduled_optimizer = StepLR(optimizer,step_size=10,gamma=0.1)# 开始迭代训练total_epoch = 100for epoch in range(total_epoch): for index,data in enumerate(person_data_loader): input_x,ground_truth = data ########## input_x = input_x.cuda() ground_truth = ground_truth.cuda() ########## predict = will_u_be_single(input_x) loss = single_loss(predict.squeeze(),ground_truth) optimizer.zero_grad() loss.backward() optimizer.step() scheduled_optimizer.step() print(f"Epoch &#123;epoch&#125;,loss: &#123;loss.item()&#125;, current lr:&#123;scheduled_optimizer.get_lr()&#125;") 测试： 1will_u_be_single(torch.tensor([1.,1.,0.])) 加速计算12345678910torch.cuda.is_available()#########will_u_be_single.cuda()###################input_x = input_x.cuda()ground_truth = ground_truth.cuda()########## 储存和加载模型储存整个模型： torch.save(will_u_be_single,&quot;./will_u_be_single.pkl&quot;) 加载整个模型： model_from_file = torch.load(&quot;./will_u_be_single.pkl&quot;) 储存参数： torch.save(will_u_be_single.state_dict(),&quot;./will_u_be_single_2.pkl&quot;) 加载参数 12model_parameter = torch.load("./will_u_be_single_2.pkl")will_u_be_single.load_state_dict(model_parameter)]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch基础]]></title>
    <url>%2F2020%2F03%2F05%2FPyTorch%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[PyTorch基础pytorchPyTorch是一个python库，它主要提供了两个高级功能： GPU加速的张量计算 构建在反向自动求导系统上的深度神经网络 数据类型数据类型： torch.float32, torch.float64, torch.float16, torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64 创建Tensor方法：ones, zeros, eye, arange, linspace, rand, randn, normal, uniform, randperm 定义数据1234567891011121314151617181920212223242526272829303132333435363738394041424344x = torch.tensor(666)# tensor(666)x = torch.tensor([1,2,3,4,5,6])# tensor([1,2,3,4,5,6])x = torch.ones(2,3)"""tensor([[1., 1., 1.], [1., 1., 1.]])"""x = torch.empty(5,3)"""tensor([[1.4178e-36, 0.0000e+00, 4.4842e-44], [0.0000e+00, nan, 0.0000e+00], [1.0979e-05, 4.2008e-05, 2.1296e+23], [1.0386e+21, 4.4160e-05, 1.0742e-05], [2.6963e+23, 4.2421e-08, 3.4548e-09]])"""x = torch.rand(5,3)"""tensor([[0.3077, 0.0347, 0.3033], [0.9099, 0.2716, 0.4310], [0.8286, 0.3317, 0.0536], [0.9529, 0.4905, 0.1403], [0.6899, 0.8349, 0.4015]])"""x = torch.zeros(5,3,dtype=torch.long)"""tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])"""# 基于现有的tensor，创建一个新tensor，# 从而可以利用原有的tensor的dtype，device，size之类的属性信息y = x.new_ones(5,3) #tensor new_* 方法，利用原来tensor的dtype，devicez = torch.randn_like(x, dtype=torch.float) # 利用原来的tensor的大小，但是重新定义了dtype 定义操作 凡是用Tensor进行各种运算的，都是Function 基本运算，加减乘除，求幂求余 函数 功能 abs/sqrt/div/exp/fmod/log/pow 绝对值/平方根/除法/指数/求余/求幂 cos/sin/asin/atan2 ··· 三角函数 ceil/round/floor/trunc 上取整/四舍五入/下取整/只保留整数 clamp(input, min, max) 超过min和max截断 mean/sum/mode 均值/和/众数 norm/dist 范数/距离 std/var 标准差/方差 cumsum/cumprod 累加/累乘 布尔运算，大于小于，最大最小 函数 功能 gt/lt/ge/le/eq/ne 大于/小于/大于等于/小于等于/等于/不等 topk 最大的k个数 sort 排序 max/min 比较两个tensor最大最小值 线性运算，矩阵乘法，求模，求行列式 函数 功能 trace 对角线元素之和（矩阵的迹） diag 对角线元素 triu/tril 矩阵的上三角/下三角，可指定偏移 mm/bmm 矩阵乘法，batch的矩阵乘法 addmm/addbmm/addmv/addr/badbmm 矩阵运算 t 转置 dot/cross 内积/外积 inverse 求逆矩阵 svd 奇异值分解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 创建一个 2x4 的tensorm = torch.Tensor([[2, 5, 3, 7], [4, 2, 1, 9]])# 返回 m 中元素的数量print(m.numel())# 返回 第1列的全部元素print(m[:, 1])# 返回 第0行的全部元素print(m[0, :])# Create tensor of numbers from 1 to 5# 注意这里结果是1到4，没有5v = torch.arange(1, 5)# tensor([1, 2, 3, 4])# Scalar product 点积m @ v# tensor([49., 47.])# Calculated by 1*2 + 2*5 + 3*3 + 4*7m[[0], :] @ v# tensor([49.])# 转置，由 2x4 变为 4x2print(m.t())# 使用 transpose 也可以达到相同的效果print(m.transpose(0, 1))"""tensor([[2., 4.], [5., 2.], [3., 1.], [7., 9.]])tensor([[2., 4.], [5., 2.], [3., 1.], [7., 9.]])"""# returns a 1D tensor of steps equally spaced points between start=3, end=8 and steps=20torch.linspace(3, 8, 20)"""tensor([3.0000, 3.2632, 3.5263, 3.7895, 4.0526, 4.3158, 4.5789, 4.8421, 5.1053, 5.3684, 5.6316, 5.8947, 6.1579, 6.4211, 6.6842, 6.9474, 7.2105, 7.4737, 7.7368, 8.0000])"""# 创建两个 1x4 的tensora = torch.Tensor([[1, 2, 3, 4]])b = torch.Tensor([[5, 6, 7, 8]])# 在 0 方向拼接 （即在 Y 方各上拼接）, 会得到 2x4 的矩阵print( torch.cat((a,b), 0))"""tensor([[1., 2., 3., 4.], [5., 6., 7., 8.]])"""# 在 1 方向拼接 （即在 X 方各上拼接）, 会得到 1x8 的矩阵print( torch.cat((a,b), 1))"""tensor([[1., 2., 3., 4., 5., 6., 7., 8.]])""" 张量 反向传播 PyTorch里并没有显式的Graph定义，计算步骤，存在Tensor的grad_fn里，沿着Tensor的grad_fn往后走，就是反向传播 计算图 对于上述过程，公式如下： \begin{cases} x_i = 1\\ y_i = x_i+2\\ z_i = 3y_i^2\\ out = \frac{1}{4}\sum_i z_i\\ \end{cases}所以： \frac{\partial out}{\partial z_i} = \frac{1}{4}\\ \frac{\partial z_i}{\partial y_i} = 6y_i\\ \frac{\partial y_i}{\partial x_i} = 1所以： \frac{\partial out}{\partial x_i} = \frac{1}{4}*6y_i=\frac{3}{2}(x_i+2)\\ \frac{\partial out}{\partial x_i} \vert_{x_i=1}=\frac{2}{9}=4.5]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow学习]]></title>
    <url>%2F2020%2F02%2F05%2Ftensorflow%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Tensorflowhello world123456789import tensorflow.compat.v1 as tftf.disable_v2_behavior()vec_1 = tf.constant([1, 2, 3, 4])vec_2 = tf.constant([1, 2, 3, 4])v_add = tf.add(vec_1,vec_2)with tf.Session() as sess: print(sess.run(v_add)) 12345678910111213import tensorflow.compat.v1 as tftf.disable_v2_behavior()vec_1 = tf.constant([1, 2, 3, 4])vec_2 = tf.constant([1, 2, 3, 4])sess = tf.InteractiveSession()v_add = tf.add(vec_1,vec_2)print(v_add.eval())sess.close() 张量所有的数据都通过张量的形式来表示 TensorFlow的张量和Numpy的数组不同，他计算的结果不是一个具体的数字，而是一个张量的结构。从上面结果来看，一个张量主要保存了三个属性，名字（name），维度（shape）和类型（type） 123456789#_*_coding:utf-8_*_import tensorflow as tf # tf.constant 是一个计算，这个计算的结果为一个张量，保存在变量a中a = tf.constant([1.0, 2.0], name='a')b = tf.constant([2.0, 3.0], name='b') result = a + b# print(result) # Tensor("add:0", shape=(2,), dtype=float32) 张量的第一个属性名字不仅是一个张量的唯一标识符，它同样也给出了这个张量是如何计算的，TensorFlow的计算都可以通过计算图的模型来建立，而计算图上的每一个节点代表一个计算，计算的结果就保存在张量之中。所以张量和计算图上节点所代表的计算结果是对应的。所以张量的命名就可以通过“node : src_output”的形式来给出。其中node为节点的名称，src_output 表示当前张量来自节点的第几个输出。比如上面的“add:0” 就说明了result这个张量是计算节点“add” 输出的第一个结果（编号从0 开始）。 张量的第二个属性是张量的维度。这个属性描述了一个张量的维度信息，比如上面样例中 shape = (2, ) 说明了张量 result 是一个一维数组，这个数组的长度为2。维度是张量一个很重要的属性，围绕张量的维度TensorFlow也给出了很多有用的运算。 张量的第三个属性就是类型（type），每一个张量会有一个唯一的类型。TensorFlow 会对参与运算的所有张量进行类型的检查，当发现类型不匹配的时候会报错 常量、随机数、变量大规模常量张量对象最好定义成 t_large = tf.Varible(large_array,trainable = False) 可训练标志位为False 12345678910111213t_1 = tf.constant(4)zero_t = tf.zeros([2,3],tf.int32)tf.zeros_like(t_2)tf.ones_like(t_2)range_t = tf.linspace(2.0,5.0,5)#We get:[2. 2.75 3.5 4.25 5.]tf.range(start,limit,delta)#start 默认0，delta 默认1range_t = tf.range(10)#Result:[0 1 2 3 4 5 6 7 8 9] 123456#随机数t_random = tf.random_normal([2,3],mean=2.0,stddev=4,seed = 12)#要想得到同样的随机数，seed需要设置相同，均值默认0，标准差默认1tf.random_crop(t_random,[2,5],seed=12)#将给定的张量随机剪裁为指定的大小 123456789rand_t = tf.random_uniform([50,50]，0，10，seed=0)t_a = tf.Variable(rand_t)#随机均匀分布，min 0 max 10weight2 = tf.Variable(weights.initialized_value(),name='w2')#用原有变量定义saver = tf.train.Saver()#保存变量 占位符定义过程，执行时再赋具体值 1tf.placeholder(dtype,shape=None,name=None) 常用函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687(1)tf.argmax(input, axis=None, name=None, dimension=None)此函数是对矩阵按行或列计算最大值参数 input：输入Tensor axis：0表示按列，1表示按行 name：名称 dimension：和axis功能一样，默认axis取值优先。新加的字段返回：Tensor 行或列的最大值下标向量 (2)tf.equal(a, b)此函数比较等维度的a, b矩阵相应位置的元素是否相等，相等返回True,否则为False返回：同维度的矩阵，元素值为True或False (3)tf.cast(x, dtype, name=None)将x的数据格式转化成dtype.例如，原来x的数据格式是bool，那么将其转化成float以后，就能够将其转化成0和1的序列。反之也可以 (4)tf.reduce_max(input_tensor, reduction_indices=None,keep_dims=False, name=None) 功能：求某维度的最大值 (5)tf.reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None)功能：求某维度的均值参数1--input_tensor:待求值的tensor。参数2--reduction_indices:在哪一维上求解。0表示按列，1表示按行参数（3）（4）可忽略例：x = [ 1, 2 3, 4]x = tf.constant([[1,2],[3,4]], &quot;float&quot;)tf.reduce_mean(x) = 2.5tf.reduce_mean(x, 0) = [2, 3]tf.reduce_mean(x, 1) = [1.5, 3.5] (6)tf.truncated_normal(shape, mean=0.0, stddev=1.0,dtype=tf.float32, seed=None, name=None)从截断的正态分布中输出随机值 shape: 输出的张量的维度尺寸。 mean: 正态分布的均值。 stddev: 正态分布的标准差。 dtype: 输出的类型。 seed: 一个整数，当设置之后，每次生成的随机数都一样。 name: 操作的名字。 (7）tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)从标准正态分布中输出随机值 (8) tf.nn.conv2d(input, filter, strides, padding,use_cudnn_on_gpu=None, data_format=None, name=None)在给定的4D input与 filter下计算2D卷积 1，输入shape为 [batch, height, width, in_channels]: batch为图片数量，in_channels为图片通道数 2，第二个参数filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，有一个地方需要注意，第三维in_channels，就是参数input的第四维 3，第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4 4，第四个参数padding：string类型的量，只能是&quot;SAME&quot;,&quot;VALID&quot;其中之一，这个值决定了不同的卷积方式（后面会介绍） 5，第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true 结果返回一个Tensor，这个输出，就是我们常说的feature map，shape仍然是[batch, height, width, channels]这种形式。 (9)tf.nn.max_pool(value, ksize, strides, padding, name=None)参数是四个，和卷积很类似：第一个参数value：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch, height, width, channels]这样的shape第二个参数ksize：池化窗口的大小，取一个四维向量，一般是[1, height, width, 1]，因为我们不想在batch和channels上做池化，所以这两个维度设为了1第三个参数strides：和卷积类似，窗口在每一个维度上滑动的步长，一般也是[1, stride,stride, 1]第四个参数padding：和卷积类似，可以取&apos;VALID&apos; 或者&apos;SAME&apos; 返回一个Tensor，类型不变，shape仍然是[batch, height, width, channels]这种形式 (10) tf.reshape(tensor, shape, name=None)函数的作用是将tensor变换为参数shape的形式。其中shape为一个列表形式，特殊的一点是列表中可以存在-1。-1代表的含义是不用我们自己指定这一维的大小，函数会自动计算，但列表中只能存在一个-1。（当然如果存在多个-1，就是一个存在多解的方程了） (11)tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None,name=None)为了减少过拟合，随机扔掉一些神经元，这些神经元不参与权重的更新和运算参数： x : 输入tensor keep_prob : float类型，每个元素被保留下来的概率 noise_shape : 一个1维的int32张量，代表了随机产生“保留/丢弃”标志的shape。 seed : 整形变量，随机数种子。 name : 名字，没啥用。 feed_dict字符串拼接123456789Str1 = tf.placeholder(tf.string)Str2 = tf.placeholder(tf.string)Str3 = tf.placeholder(tf.string)Str = tf.string_join([Str1, Str2, Str3], separator=" ") with tf.Session() as sess: output = sess.run(Str, feed_dict=&#123;Str1: 'I', Str2: 'like', Str3: 'TensorFlow !'&#125;) print(output.decode()) 浮点数乘积1234567Num1 = tf.placeholder(tf.float32)Num2 = tf.placeholder(tf.float32)Result = tf.multiply(Num1, Num2)with tf.Session() as sess: print(sess.run(Result, feed_dict=&#123;Num1:[5.],Num2:[6.]&#125;)) tensorboard12345678910import tensorflow.compat.v1 as tftf.disable_v2_behavior()A = tf.random_uniform([2,3] , 2 , 10 , dtype = tf.int32 ,name = "A")B = tf.eye(3 , dtype = tf.int32 , name = "B")C = tf.matmul(A , B , name = "ans")with tf.Session() as sess: write = tf.summary.FileWriter('logs' , sess.graph) sess.run(C) logs上级目录下打开shell，命令： tensorboard --logdir &quot;logs&quot;，新版tensorflow将 = 换成了双引号 更改命名空间： 1234567891011121314import tensorflow.compat.v1 as tftf.disable_v2_behavior()with tf.name_scope("A"): A = tf.random_uniform([2,3] , 2 , 10 , dtype = tf.int32 ,name = "A")with tf.name_scope("B"): B = tf.eye(3 , dtype = tf.int32 , name = "B")C = tf.matmul(A , B , name = "ans")with tf.Session() as sess: write = tf.summary.FileWriter('logs' , sess.graph) sess.run(C)]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase]]></title>
    <url>%2F2020%2F01%2F01%2FHBase%2F</url>
    <content type="text"><![CDATA[HBase安装hbase下载wget https://archive.apache.org/dist/hbase/2.0.0-alpha4/hbase-2.0.0-alpha4-bin.tar.gz 安装后解压到/opt/hbase文件夹 配置环境变量修改~/.bashrc文件，添加以下代码 12export HBASE_HOME=/opt/hbase export PATH=$PATH:$HBASE_HOME/bin 立即生效，source ~/.bashrc 修改配置文件修改以下内容，/opt/hbase/conf/hbase-env.sh 12export HBASE_MANAGES_ZK=true export JAVA_HOME=/opt/jdk 使用hbase自带的zookeeper，java路径为/opt/jdk 修改以下内容，/opt/hbase/conf/hbase-site.xml 1234567891011121314151617181920&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://Master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;Master:2181,Slave1:2181,Slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/hadoop/zookeeper&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 设置储存位置为hdfs://Master:9000/hbase 使用完全分布式模式，指定zookeeper集群的地址列表，指定zookeeper本地快照位置 修改以下内容：/opt/hbase/conf/regionservers 123MasterSlave1Slave2 HMaster闪退1、时间同步造成HMaster闪退，可能是由于节点的时间未同步，使用ntpdate 123456yum install -y ntpdate#设置时区cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeyes | cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime#同步时间ntpdate us.pool.ntp.org 配置后检查各个节点的date，看时间是否同步 2、zookeeper未连接使用hbase自带的zookeeper的话，要保证之前安装的zookeeper不会抢占2181端口，如果已有进程抢占2181端口，使用kill命令杀死进程。 保证各个节点防火墙已关闭，使2181端口能够正常访问 1service iptables stop 启动hbase先启动Hadoop，start -all.sh ，之后启动hbase，使用shell HBase Shellcreate alter删除menber中的member_id列族 list put12345678910111213put 'member','scutshuxue','info:age','24' put 'member','scutshuxue','info:birthday','1987-06-17' put 'member','scutshuxue','info:company','alibaba' put 'member','scutshuxue','address:contry','china' put 'member','scutshuxue','address:province','zhejiang' put 'member','scutshuxue','address:city','hangzhou' put 'member','xiaofeng','info:birthday','1987-4-17' put 'member','xiaofeng','info:favorite','movie' put 'member','xiaofeng','info:company','alibaba' put 'member','xiaofeng','address:contry','china' put 'member','xiaofeng','address:province','guangdong' put 'member','xiaofeng','address:city','jieyang' put 'member','xiaofeng','address:town','xianqiao' get12get 'member','scutshuxue','info' get 'member','scutshuxue','info:age' count Java APIwindows下安装hadoop下载hadoop_2.8.2 解压到合适位置后，添加环境变量 由于是在windows上安装，使用编译好的windows版本二进制文件进行替换，下载地址： https://github.com/steveloughran/winutils 由于没有2.8.2版本，所以使用2.8.3版本替换bin文件夹下全部内容 修改配置文件后，格式化hdfs，到sbin目录下启动hadoop 可以通过http://localhost:8088/ 、 http://localhost:50070/ 查看hadoop相关信息 windows下安装hbase官网下载安装包，版本选择的是 HBase 2.0.0-alpha4，下载地址：http://archive.apache.org/dist/hbase/ 修改环境变量等配置文件，在运行时报错 原因是缺少jar包导致，在网上下载 jline-2.12.1.jar，替换掉hadoop目录里的两个低版本的 jline-0.9.94.jar，并复制一份添加到yarn/lib中去 运行 java项目创建Java项目，导入本机hbase\lib下的所有jar包 创建HBaseUtils类、Run类 建立连接 12345678 HBaseUtils() throws IOException &#123; conf = HBaseConfiguration.create(); conf.set("hbase.rootdir", "hdfs://Master:9000/hbase"); conf.set("hbase.zookeeper.quorum", "Master,Slave1,Slave2"); config.set("hbase.zookeeper.property.clientPort", "2181");// zookeeper端口connection = ConnectionFactory.createConnection(config);admin = conn.getAdmin(); &#125; 创建表 12345678910111213public void createTable(String tableName, String[] family) throws Exception &#123; HTableDescriptor desc =new HTableDescriptor(tableName); for(int i=0;i&lt;family.length;i++)&#123; desc.addFamily(new HColumnDescriptor(family[i])); &#125; if(admin.tableExists(tableName))&#123; System.out.println("Already Exits"); &#125;else&#123; admin.createTable(desc); System.out.println("Create Success"); &#125;&#125; 插入数据 12345678910public void insertRecord(String tableName, String row, String col, String values) throws IOException &#123; createConn(); Table table = conn.getTable(TableName.valueOf(tableName)); Put put = new Put(row.getBytes()); String[] cols = col.split(":"); put.addColumn(cols[0].getBytes(), cols[1].getBytes(), values.getBytes()); table.put(put); table.close(); closeConn();&#125; 删除数据 1234567public void deleteRow(String tName, String row) throws IOException &#123; createConn(); Table table = conn.getTable(TableName.valueOf(tName)); Delete del = new Delete(row.getBytes()); table.delete(del); table.close();&#125; 遍历表 12345678910111213141516171819202122public ResultScanner getResultScann(String tableName) throws Exception &#123; Scan scan=new Scan(); ResultScanner rs =null; HTable htable=new HTable(conf, tableName); try&#123; rs=htable.getScanner(scan); for(Result r: rs)&#123; for(KeyValue kv:r.list())&#123; System.out.println(Bytes.toString(kv.getRow())); System.out.println(Bytes.toString(kv.getFamily())); System.out.println(Bytes.toString(kv.getQualifier())); System.out.println(Bytes.toString(kv.getValue())); System.out.println(kv.getTimestamp()); &#125; &#125; &#125;finally&#123; rs.close(); &#125; return rs; &#125; 结果 在虚拟机中查看结果，可以看到通过java api成功创建了menber表 如果在虚拟机中使用hbase shell时出现错误 Can&#39;t get master address from ZooKeeper; znode data == null 只需重新启动hbase]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Exp</tag>
        <tag>云计算</tag>
        <tag>Hadoop</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapReduce]]></title>
    <url>%2F2020%2F01%2F01%2FMapReduce%2F</url>
    <content type="text"><![CDATA[MapReduce的编程方法与实践MapReduce框架 MapReduce将复杂的，运行大规模集群上的并行计算过程高度地抽象两个函数：Map和Reduce MapReduce采用“分而治之”策略，将一个分布式文件系统中的大规模数据集，分成许多独立的分片。这些分片可以被多个Map任务并行处理。 MapReduce设计的一个理念就是“计算向数据靠拢”，而不是“数据向计算靠拢”，原因是，移动数据需要大量的网络传输开销 MapReduce框架采用了Master/Slave架构，包括一个Master和若干个Slave，Master上运行JobTracker，Slave运行TaskTracker Hadoop框架是用JAVA来写的，但是,MapReduce应用程序则不一定要用Java来写。 Mapper1234567891011121314151617public static class WordCountMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;&#123; private final static IntWritable plugOne = new IntWritable(1); private Text word = new Text(); @Override public void map(Object key, Text value, Context context ) throws IOException, InterruptedException &#123; //使用默认的分隔符，空格、制表符、回车、换行 StringTokenizer st = new StringTokenizer(value.toString().toLowerCase().replaceAll(&quot;[\\pP‘’“”]&quot;, &quot;&quot;)); while (st.hasMoreTokens()) &#123; word.set(st.nextToken()); context.write(word, plugOne); &#125; &#125;&#125; 在map阶段，key/value键值对作为输入，产生另外一系列key/value键值对作为中间输出写入本地磁盘。mapreduce框架自动将这些中间数据按照key值进行聚集，key值相同的数据将一起被reduce处理。 建立test1.txt和test2.txt test1.txt 12I am JackI am the king of the world test2.txt 12I am RoseI am looking for Jack 则map阶段得到的结果为 test1.txt 12345678910&lt;I,1&gt;&lt;am,1&gt;&lt;Jack,1&gt;&lt;I,1&gt;&lt;am,1&gt;&lt;the,1&gt;&lt;king,1&gt;&lt;of,1&gt;&lt;the,1&gt;&lt;world,1&gt; Reduce1234567891011121314151617public static class WordCountReducer extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; &#123; private IntWritable result = new IntWritable(); @Override public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context ) throws IOException, InterruptedException &#123; int reduceSum = 0; for (IntWritable val : values) &#123; reduceSum += val.get(); &#125; result.set(reduceSum); context.write(key, result); &#125;&#125; reduce阶段以key及对应的value列表作为输入，经过合并key相同的value值后，产生另外一系列key/value对作为最终输出写入hdfs map处理完后，得到的KV对会分组保存，key值相同的分为一组，然后传递一个组会调用一次reduce，在词频统计中，同一个单词会分为一组，value的值为1，所以reduceSum += val.get() 统计了每一个单词的个数。 结果： Sort由于只需要出现次数最多的100个单词，所以采用TreeMap结构 建立新的sortjob，继承mapper和reducer mapper 12345678910111213public void map(final Object key, final Text value, final Context context) throws IOException, InterruptedException &#123; final String line = value.toString(); final String[] keyValueStrings = line.split(&quot;\t&quot;); final int count = Integer.parseInt(keyValueStrings[1]); final String word = keyValueStrings[0]; map1.put(count, word); if (map1.size() &gt; K) &#123; map1.remove(map1.firstKey()); &#125; &#125; reducer 1234567891011121314public void reduce(final Text key, final Iterable&lt;IntWritable&gt; values, final Context context) throws IOException, InterruptedException &#123; final String word = key.toString(); int count = 0; for (final IntWritable val : values) &#123; count = val.get(); &#125; map1.put(count, word); if (map1.size() &gt; K) &#123; map1.remove(map1.firstKey()); &#125; &#125; 上传ebooks在hdfs根目录建立文件夹ebooks 使用scp将200本英文书上传到虚拟机： hadoop fs -put /ebooks / 将文件上传到hdfs目录下 可以看到文件上传成功 运行编辑run.sh 编译后的结果： 第一次运行时，在运行过程中会被强制kill掉进程，返回码为137 原因是内存分配不足造成，需要修改配置文件 yarn-site.xml ，添加以下内容 1234567891011121314151617&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;22528&lt;/value&gt; &lt;discription&gt;每个节点可用内存,单位MB&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;1500&lt;/value&gt; &lt;discription&gt;单个任务可申请最少内存，默认1024MB&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;16384&lt;/value&gt; &lt;discription&gt;单个任务可申请最大内存，默认8192MB&lt;/discription&gt; &lt;/property&gt; mapred-site.xml ，添加以下内容 12345678910111213141516171819202122232425&lt;property&gt; &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt; &lt;value&gt;1500&lt;/value&gt; &lt;description&gt;每个Map任务的物理内存限制&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt; &lt;value&gt;3000&lt;/value&gt; &lt;description&gt;每个Reduce任务的物理内存限制&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt; &lt;value&gt;-Xmx1200m&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.java.opts&lt;/name&gt; &lt;value&gt;-Xmx2600m&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; result]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Exp</tag>
        <tag>云计算</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hdfs使用方法]]></title>
    <url>%2F2020%2F01%2F01%2Fhdfs%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[HDFS使用方法一、使用命令操作HDFS查看文件、发送文件hadoop fs -ls / 查看hdfs根目录文件 hadoop fs -put ./test/file1 / 将test目录下的file1发送到hdfs根目录 创建目录hadoop fs -mkdir -p /test/user/ -p为递归创建，可以创建多级目录 下载文件、删除文件hadoop fs -get sourcepath savepath 将hdfs test 文件夹下的user文件夹 下载到本地的test文件夹下 hadoop fs -rm -r /test/user/del 删除 test/user 下的del文件，-r循环删除文件夹下的所有文件 查找文件hadoop fs -find / -name xxx 从根目录开始查找名为xxx的文件位置 二、使用Java接口操作HDFS添加环境变量123修改 .bashrc，添加export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jarsource .bashrc 编写Java代码实现 put 、 delete、get三个方法 参考老师的PPT 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.io.IOException;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class hadoop_try&#123; public static Boolean put(String src , String dst , Configuration conf)&#123; Path dstPath = new Path(dst) ; try&#123; FileSystem hdfs = dstPath.getFileSystem(conf) ; hdfs.copyFromLocalFile(false, new Path(src), dstPath) ; &#125; catch(IOException ie)&#123; ie.printStackTrace() ; return false ; &#125; return true ; &#125; public static Boolean get(String src , String dst , Configuration conf)&#123; Path dstPath = new Path(dst) ; try&#123; FileSystem dhfs = dstPath.getFileSystem(conf) ; dhfs.copyToLocalFile(false, new Path(src), dstPath) ; &#125; catch(IOException ie)&#123; ie.printStackTrace() ; return false ; &#125; return true ; &#125; public static Boolean Delete(final String path , Configuration conf)&#123; Path dstPath = new Path(path) ; try&#123; FileSystem dhfs = dstPath.getFileSystem(conf) ; if(dhfs.exists(dstPath))&#123; dhfs.delete(dstPath, true) ; &#125; else&#123; return false ; &#125; &#125; catch(IOException ie )&#123; ie.printStackTrace() ; return false ; &#125; return true ; &#125; public static void main(String[] args) &#123; String dst = "hdfs://Master:9000/test/user" ; String src = "/root/test/tryfile"; Boolean status = false ; Configuration conf = new Configuration() ; status = put( src , dst , conf) ; System.out.println("put status="+status) ; src = "hdfs://Master:9000/test/user/tryfile"; dst = "/root/" ; status = get( src , dst , conf) ; System.out.println("get status="+status) ; dst = "hdfs://Master:9000/test/user/tryfile"; status = Delete( dst , conf) ; System.out.println("del status="+status) ; &#125;&#125; 编译、打包、运行123编译 ： hadoop com.sun.tools.javac.Main hadoop_try.java打包 ： jar cf hadoop_try.jar hadoop_try*.class运行 ： hadoop jar hadoop_try.jar hadoop_try 通过get方法，将hdfs上 /test/user/tryfile 下载到了 root文件夹下 ， 验证：]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Exp</tag>
        <tag>云计算</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop安装配置]]></title>
    <url>%2F2019%2F11%2F05%2FHadoop%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Hadoop平台安装与配置一、创建三台虚拟机1、 为创建好的虚拟机配置网络使用命令 vi /etc/sysconfig/network-scripts/ifcfg-eth0 重启服务，并验证配置好的网络 2、 使用模板创建另外两台虚拟机使用实验一中创建的CentOS 6虚拟机，并使用OVF模板创建另外两台虚拟机 二、配置网络1、 生成MAC地址由于直接使用OVF模板创建了虚拟机，所以需要为两台模板虚拟机生成MAC地址 2、 修改MAC地址使用命令 vi /etc/sysconfig/network-scripts/ifcfg-eth0 删除旧网卡规则映射 使用命令 rm /etc/udev/rules.d/70-persistent-net.rules 删除后重启机器 3、 修改ip、子网掩码、网关使用命令 ifconfig 、 netstat -rn 查看ip、子网掩码、网关地址 修改ip、子网掩码、网关，在网卡配置中增加 IPADDR、NETMASK、GATEWAY 4、重启服务，关闭防火墙12service network restartservice iptables stop 5、 测试网络三个虚拟机ip: 123CentOS 6 : 192.168.112.129CentOS 6 - 1 : 192.168.112.130CentOS 6 - 2 : 192.168.112.131 测试网络： 三、修改hosts1、分别修改虚拟机hosts文件使用命令 vi /etc/hosts 四、配置SSH免登录1、ssh-keygen使用命令 ssh-kengen 2、配置两两间的免登录12ssh-copy-id -i .ssh/id_rsa.pub root@Slave1 ssh-copy-id -i .ssh/id_rsa.pub root@Slave2 五、安装Hadoop平台1、安装java 2、将下载的java安装包传入虚拟机 3、解压12tar -zxvf jdk-8u231-linux-x64.tar.gz mv ./jdk1.8.0_231 /opt/jdk 4、添加环境变量vi /etc/profile 12export JAVA_HOME=/opt/jdkCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 5、安装Hadoop网址： https://archive.apache.org/dist/hadoop/core/hadoop-2.8.2/ 解压后添加环境变量，修改 .bashrc 添加 12export HADOOP_HOME=/opt/hadoop export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin 修改 hadoop-env.sh 和 yarn-env.sh 1export JAVA_HOME=/opt/jdk 修改 slaves ，添加Slave1、Slave2 修改 core-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://Master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 修改 hdfs-site.xml ， 设置副本数、心跳间隔 12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.http.address&lt;/name&gt; &lt;value&gt;Master:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.heartbeat.interval&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/tmp/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/tmp/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 mapred-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 yarn-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 格式化文件系统 hdfs namenode -format 启动Hadoop start-all.sh 查看jps]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Exp</tag>
        <tag>云计算</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Next主题baidu验证]]></title>
    <url>%2F2019%2F10%2F11%2Fhexo_baidu_verify%2F</url>
    <content type="text"><![CDATA[baidu验证验证未收录百度搜索 site:yourgithub.github.io , 验证未收录 百度搜索平台进入百度搜索平台，点击链接提交，填写github地址 记录content值验证站点，选择html标签验证，记录content值 添加代码在themes/next下的配置文件最后添加代码 baidu_site_verification: 5xxxxxxQ 重新生成提交，无需修改head文件 刷新github页面，查看网站源代码，当可以找到正确的验证标签时，进行验证。 验证通过 等待通过，通过后进行推送 推送主动推送最为快速的提交方式，推荐您将站点当天新产出链接立即通过此方式推送给百度，以保证新链接可以及时被百度收录。 自动推送最为便捷的提交方式，请将自动推送的JS代码部署在站点的每一个页面源代码中，部署代码的页面在每次被浏览时，链接会被自动推送给百度。可以与主动推送配合使用。 sitemap您可以定期将网站链接放到sitemap中，然后将sitemap提交给百度。百度会周期性的抓取检查您提交的sitemap，对其中的链接进行处理，但收录速度慢于主动推送。 手动提交一次性提交链接给百度，可以使用此种方式。 主动推送&gt;自动推送&gt;sitemap主动推送安装hexo-baidu-url-submit插件git bash 命令 npm install hexo-baidu-url-submit --save 添加baidu-url-submit的配置项站点配置文件中添加： #设置百度主动推送baidu_url_submit: count: 200 #比如200，代表提交最新的200个链接 host: www.lansheng.net.cn # 在百度站长平台中注册的域名，这个改为你自己的域名 token: your_token # 请注意这是您的秘钥， 所以请不要把博客源代码发布在公众仓库里! path: baidu_urls.txt # 文本文档的地址， 新链接会保存在此文本文档里，这个默认 同时注意修改站点配置文件中的url值 加入新的deploy配置项两个type前都要加‘ - ’，表明层次 deploy: - type: gitrepo: coding: git@git.coding.net:你的coding用户名/你的coding用户名.coding.me.git #coding地址 github: git@github.com:你的github用户名/你的github用户名.github.io.git # Github地址branch: master - type: baidu_url_submitter 验证配置是否成功hexo d部署后查看反馈： 自动推送设置baidu_push将主题配置文件中的baidu_push置为 true 自动推送代码位于 themes\next\layout\_third-party\baidu-push.swig Sitemap安装baidu 、Google插件git bash命令 npm install hexo-generator-sitemap --save npm install hexo-generator-baidu-sitemap --save 修改配置文件修改站点配置文件，添加 # 自动生成sitemapsitemap:path: sitemap.xmlbaidusitemap:path: baidusitemap.xml 编译hexo clean &amp;&amp; hexo g 更换站点地图文件url将地图文件中的yoursite.com更换成自己的url 在站长管理中提交地图]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>baidu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F10%2F11%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[汽车牌照提取]]></title>
    <url>%2F2019%2F06%2F05%2F%E6%B1%BD%E8%BD%A6%E7%89%8C%E7%85%A7%E6%8F%90%E5%8F%96%2F</url>
    <content type="text"><![CDATA[​ 问题分析车牌特点样例车牌可以分为两类： （1） 小功率汽车使用的蓝底白字牌照； （2） 国外驻华机构使用黑底白字牌照 这些牌照的长度均为45cm，宽为15cm，共有字符7个。一般民用牌照第一个字符为汉字，且是各省市的简称；第二个字符为大写英文字母，如“E”；第三个字符是英文字母或阿拉伯数字，第四至第七个字符为阿拉伯数字。 实验流程实验流程包括：车牌定位、倾斜校正、字符分割、字符识别4个部分 (1) 原始图像：样例中所给的汽车图像； (2) 图像预处理：对原始图像进行二值化等预处理操作； (3) 车牌定位：定位出汽车牌照所在的矩形范围； (4) 倾斜校正：对定位后的车牌进行倾斜校正； (5) 字符分割：定位分割得到的车牌图像，得到单个的字符； (6) 图像预处理：重新定义分割后的字符图像大小，并转化为一维矩阵； (7) 字符识别：通过BP神经网络训练，得到最后的汽车牌照，包括英文字母和数字。 实验过程解决思路车牌定位1) 基于灰度边缘检测与形态学重构的方法。这种方法只要利用车牌区域局部对比度明显和有规律的纹理特征来定位，然后利用形态学方法将车牌区域与其它背景区域分离。 2) 基于直线检测的方法。这种方法主要Hough变换的方法来检测车牌周围边框直线，利用车牌形状特性来定位车牌。 3) 根据车牌的固有长宽比进行定位的方法。因为中外车牌的长宽比都是固定的3.1：1，在预处理完成后对二值化的图像进行膨胀腐蚀，计算联通区域长宽比确定车牌位置。 4) 基于彩色图像的车牌定位方法。现在的牌照有四种类型:第一种是最常见的小型汽车所用的蓝底白字牌照；第二种是大型汽车所用的黄底黑字牌照；第三种是军用或警用的白底黑字、红字牌照；第四种是国外驻华机构用的黑底白字、红字牌照。基于彩色图像的车牌定位方法主要利用车牌颜色与车身其他部位颜色具有明显不同的差异来分割与提取车牌。 5) 目前较为成熟的车牌区域定位算法有自适应边界搜索法、区域生长法、灰度图像数学形态学运算法、基于纹理或颜色的分割方法以及模糊聚类法等。 字符分割1) 投影分析常采用的是水平投影法。即沿水平方向计算每一列属于车牌字符的象素数目，在字符的间隙处取得局部最小值，分割位置应在其附近。先根据车牌水平投影的统计特征呈现出明显“波峰——波谷——波峰”，进行水平方向上的粗分割，若字符出现合并和粘连现象，再采用递归回归办法进行二次字符分割。 2) 投影法进行字符分割实现起较为简单，但在预处理效果不好的情况下，较难获得满足条件的列。若增加预处理，则使处理后的图像不可避免地损失一部分有用信息，还可能导致额外误差。基于连通域聚类分析切分车牌字符的方法按照属于同一个字符的像素构成一个连通域的原则，结合牌照字符的固定高度和间距比例关系等先验知识，较好地解决了汽车牌照在复杂背景条件下的字符切分问题，降低了对车牌定位准确度的要求，对不规范的车牌识别也具有一定的适用性。 字符识别1) 模板匹配法是最简单的一种字符识别方法。将待识别字符经分割归一化成模板字体的大小，将它输入字符识别模块进行匹配。根据实际字符和模板图像之间匹配方差最小的原则，判定车牌图像字符所属类别。这种方法对于标准、规范的字符识别效果较好。但在复杂环境下的车牌字符会与理想模板字符不完全一致，这导致了识别结果存在较大误差。 2) 模版匹配法简单、成熟，但其自适应不强。对于字符有断裂和粘连等情况容易造成误判。神经网络匹配法具有良好的容错性、自适应和学习能力，但样本的训练收敛速度慢，而大规模并行处理为此提供了解决途径。其中一种方法是采用并行识别的BP网络，让汉字、英文、阿拉伯数字，阿拉伯数字分别送到各自的网络识别。还有学者结合小波变化的优点，提出基于小波和BP神经网络的车牌字符识别新方法，采用小波变换提取字符特征，神经网络实现字符识别，加快了算法的执行，提高了识别率。 方法设计车牌定位1) 边缘检测方法 采用robert、prewitt、soble算子进行边缘检测，之后利用数学形态学的方法对边缘检测后得到的图像进行线性腐蚀、闭运算等操作得到初步定位的二值化车牌位置 2) 颜色提取方法 针对蓝底、黑底车牌，确定颜色提取的范围，进行颜色提取，提取后得到图像的逻辑矩阵，逻辑为真的部分为初步定位的二值化车牌位置 3) 根据行、列像素灰度值累积值确定行列起始、终止位置。 4) 将逻辑矩阵初步确定的车牌位置的外接矩形作为车牌最终定位位置 倾斜校正1) 理想情况下，将车牌左上角，右上角连线与水平方向的夹角作为倾角。 2) 将定位后的车牌等分为左右两部分，求出平均y值，作为倾角。 字符分割1) 水平投影法。沿水平方向计算每一列属于车牌字符的像素数目，在字符的间隙处取得局部最小值，分割位置应在其附近。先根据车牌水平投影的统计特征呈现出明显“波峰——波谷——波峰”，进行分割。 2) 首先计算列级灰度值，确定阈值范围，将满足阈值范围的列号设为逻辑真值1，用连续的两个0作为分割符，进行初步分割，对分割后的部分进行判断，取连续超过5个的逻辑真值列，作为分割后的字符位置。 字符识别1) 使用matlab自带的bp神经网络进行训练 小组分工描述小组成员的分工情况，每个人需要完成的任务 实现过程牌照定位边缘检测首先采用边缘检测的方法进行定位，利用robert算子，进行边缘提取，之后利用腐蚀，闭运算填充的方法，得到初步的结果，之后根据车牌的大小，通过做差，提取出车牌部分 123456789101112131415161718192021222324252627282930313233a = imread(&apos;pics/2.jpg&apos;);I = edge(rgb2gray(a),&apos;roberts&apos;,0.07,&apos;both&apos;); %采用robert算子进行边缘检测 figure , subplot(1,2,1);imshow(I) , title(&apos;边缘检测&apos;); se = [1;1;1];I1 = imerode(I,se);%figure , imshow(I1) , title(&apos;膨胀后&apos;); se=strel(&apos;rectangle&apos;,[25,25]); %矩形结构元素I2 = imclose(I1,se); %初步填充I3 = bwareaopen(I2,9000); %去除聚团灰度值小于9000的部分I4 = bwareaopen(I2,11000); subplot(1,2,2)imshow(I3-I4) , title(&apos;填充后&apos;); 但是这种方法对于样例4，得到的结果并不理想 因此改用颜色提取的方法 颜色提取根据蓝底和黑底车牌，确定不同的颜色范围，进行颜色提取。 以蓝底车牌为例： 123456789101112131415161718192021222324252627282930313233a = imread(&apos;pics/2.jpg&apos;); dd1 = (a(:,:,1)&lt;=40&amp;a(:,:,1)&gt;=10&amp;a(:,:,2)&lt;=85&amp;a(:,:,2)&gt;=55&amp;a(:,:,3&lt;=240&amp;a(:,:,3)&gt;=110); %由RGB颜色范围抠图 结果为逻辑矩阵（只包含0与1）figure , subplot(1,2,1),imshow(dd1) , title(&apos;颜色提取&apos;); se = strel(&apos;square&apos;,3); %线型结构元素 I1 = imdilate(imdilate(dd1,se),se); %膨胀图像 se=strel(&apos;rectangle&apos;,[20,20]); %矩形结构元素I2 = imclose(I1,se); %初步填充 I3 = bwareaopen(I2,2000); %去除聚团灰度值小于2000的部分 se=strel(&apos;rectangle&apos;,[100,100]); %矩形结构元素I = imclose(I3,se); %再次填充subplot(1,2,2)imshow(I) , title(&apos;填充后&apos;); 确定范围首先尝试通过行列的像素灰度值进行最终范围的确定，但得到的最终范围会损失一些有用信息，因此改用外接矩形的方法。 由于颜色提取后的车牌位置已经比较准确，所以将颜色提取后车牌位置的x,y轴极大极小值作为最终的范围 倾斜校正(1) 在理想情况下，由于车牌为矩形，可以通过车牌的左上角和右上角确定倾角。但在实际识别过程中，定位的车牌左上角以及右上角并不准确，导致倾角误差较大。 (2) 将定位后的车牌等分为左右两部分，求出平均y值，作为倾角。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137[y,x,]=size(I); minx = 0;maxx = x;for i = 1:y for j = 1:x if(I(i,j,1) == 1) if(minx == 0) minx = j; elseif(minx &gt; j) minx = j; end if(maxx == x) maxx = j; elseif(maxx &lt; j) maxx = j; end end endend miny = 0;maxy = y;sumofleft = 0;sumofright = 0;heightofleft = 0;heightofright = 0; for j = minx:int64((minx+maxx)/2) for i = 1:y if(I(i,j,1) == 1) sumofleft = sumofleft + 1; heightofleft = heightofleft + i; if(miny == 0) miny = i; elseif(miny &gt; i) miny = i; end if(maxy == y) maxy = i; elseif(maxy &lt; i) maxy = i; end end endend for j = int64((minx+maxx)/2):maxx for i = 1:y if(I(i,j,1) == 1) sumofright = sumofright + 1; heightofright = heightofright + i; if(miny &gt; i) miny = i; end if(maxy &lt; i) maxy = i; end end endend 旋转aveleft = heightofleft/sumofleft;averight = heightofright/sumofright;k = (aveleft - averight)/((maxx - minx)/2);DW = imrotate(DW,-atan(k)*180/pi); 字符分割(1) 首先计算列级灰度值，确定阈值范围，将满足阈值范围的列号设为逻辑真值1，用连续的两个0作为分割符，进行初步分割，对分割后的部分进行判断，取连续超过5个的逻辑真值列，作为分割后的字符位置。 先对定位后的图像进行再次抠图，得到更精确的逻辑矩阵，之后设立一维矩阵selectcol，如果列级灰度值的范围在（2，20），则将selectcol对应的列置为1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546a = DW;dd1 = (a(:,:,1)&lt;=200&amp;a(:,:,1)&gt;=100&amp;a(:,:,2)&lt;=220&amp;a(:,:,2)&gt;=100&amp;a(:,:,3)&lt;=220&amp;a(:,:,3)&gt;=100); %由RGB颜色范围抠图 结果为逻辑矩阵（只包含0与1）% figure , subplot(1,2,1),imshow(dd1);[y,x,]=size(dd1);sumofrow = 0;sumofcol = 0;selectrow = zeros(y,1);selectcol = zeros(1,x);row_min = 1;row_max = y;for i = 1:y sumofrow = 0; for j = 1:x if(dd1(i,j) == 1) sumofrow = sumofrow + 1; end end if(sumofrow &gt; 0 &amp;&amp; sumofrow &lt; 20) selectrow(i,1) = 1; endendfor i = 1:y if(selectrow(i,1) == 1) row_min = i; break; endendfor i = y:-1:1 if(selectrow(i,1) == 1) row_max = i; break; endendfor j = 1:x sumofcol = 0; for i = row_min:row_max if(dd1(i,j) == 1) sumofcol = sumofcol + 1; end if(sumofcol &gt; 2 &amp;&amp; sumofcol &lt; 20) selectcol(1,j) = 1; end endend 之所以要将范围下限设置为2，是为了排除一些干扰，由于下一步的分割要用连续的两个0作为分割符，但是对于图片五来说，第四个和第五个数字‘0’上方出现了车牌铆钉的干扰，如果不设置下界，则第四个和第五个数字被识别为连续的部分，不能进行分割。 分割以连续的两个0作为分割符，并且只取长度超过5的部分（这是为了排除包括车牌中点号在内的干扰） 12345678910111213141516171819202122232425262728293031323334353637383940414243[y,x,]=size(dd1);sum = 0;cur = 1;% figure;for i = 1:7 sum = 0; while(sum &lt; 5) while(cur &lt; x &amp;&amp; selectcol(1,cur) == 0) cur = cur + 1; end if(cur &gt; x-3) break; end tempstart = cur; while(~(selectcol(1,cur+1) == 0 &amp;&amp; selectcol(1,cur+2) == 0) &amp;&amp; cur &lt; x-3) sum = sum + 1; cur = cur + 1; end cur = cur + 1; end tempend = cur; z = dd1(1:y,tempstart:tempend,:);% se=strel(&apos;rectangle&apos;,[2,2]); %矩形结构元素% z = imclose(z,se); %再次填充 switch (i) case 1 pic1 = z; case 2 pic2 = z; case 3 pic3 = z; case 4 pic4 = z; case 5 pic5 = z; case 6 pic6 = z; case 7 pic7 = z; end subplot(1,7,i),imshow(z);end 字符识别建立模板库模板库中包含部分字母以及数字 预处理12345678910111213function inpt = pretreatment(I)% 训练样本前期处理if (ndims(I)==3) I1 = rgb2gray(I);else I1=I;endI1=imresize(I1,[50 25]);%将图片统一划为50*25大小I1=im2bw(I1,0.9);[m,n]=size(I1);inpt=zeros(1,m*n);% 将图像按列转换成一个行向量for j=1:n BP神经网络训练123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112close all;clear all;% 归一化训练样本I0=pretreatment(imread(&apos;pics/num0.png&apos;));I1=pretreatment(imread(&apos;pics/num1.png&apos;));I2=pretreatment(imread(&apos;pics/num2.png&apos;));I3=pretreatment(imread(&apos;pics/num3.png&apos;));I4=pretreatment(imread(&apos;pics/num4.png&apos;));I5=pretreatment(imread(&apos;pics/num5.png&apos;));I6=pretreatment(imread(&apos;pics/num6.png&apos;));I7=pretreatment(imread(&apos;pics/num7.png&apos;));I8=pretreatment(imread(&apos;pics/num8.png&apos;));I9=pretreatment(imread(&apos;pics/num9.png&apos;));I10=pretreatment(imread(&apos;pics/charA.png&apos;));I11=pretreatment(imread(&apos;pics/charB.png&apos;));I12=pretreatment(imread(&apos;pics/charC.png&apos;));I13=pretreatment(imread(&apos;pics/charD.png&apos;));I14=pretreatment(imread(&apos;pics/charK.png&apos;));I15=pretreatment(imread(&apos;pics/charM.png&apos;));I16=pretreatment(imread(&apos;pics/charP.png&apos;));I17=pretreatment(imread(&apos;pics/charQ.png&apos;));P=[I0&apos;,I1&apos;,I2&apos;,I3&apos;,I4&apos;,I5&apos;,I6&apos;,I7&apos;,I8&apos;,I9&apos;,I10&apos;,I11&apos;,I12&apos;,I13&apos;,I14&apos;,I15&apos;,I16&apos;,I17&apos;];T=eye(18,18); %输出样本% bp神经网络参数设置net=newff(minmax(P),[1250,300,18],&#123;&apos;logsig&apos;,&apos;logsig&apos;,&apos;logsig&apos;&#125;,&apos;trainrp&apos;);net.inputWeights&#123;1,1&#125;.initFcn =&apos;randnr&apos;;net.layerWeights&#123;2,1&#125;.initFcn =&apos;randnr&apos;;net.trainparam.epochs=5000;net.trainparam.show=50;%net.trainparam.lr=0.01;net.trainparam.goal=0.000000000001;net=init(net);[net,tr]=train(net,P,T); %训练样本% 测试path = &apos;pics/2.jpg&apos;;[PIN0,PIN1,PIN2,PIN3,PIN4,PIN5,PIN6]=blue_main(path);%字符分割及处理% 测试字符，得到识别数值PIN0=pretreatment(PIN0);PIN1=pretreatment(PIN1);PIN2=pretreatment(PIN2);PIN3=pretreatment(PIN3);PIN4=pretreatment(PIN4);PIN5=pretreatment(PIN5);PIN6=pretreatment(PIN6);P0=[PIN0&apos;,PIN1&apos;,PIN2&apos;,PIN3&apos;,PIN4&apos;,PIN5&apos;,PIN6&apos;];for i=2:7 T0= sim(net ,P0(:,i)); T1 = compet (T0) ; d = find(T1 == 1) - 1; if (d==10) str=&apos;A&apos;; elseif (d==11) str=&apos;B&apos;; elseif (d==12) str=&apos;C&apos;; elseif (d==13) str=&apos;D&apos;; elseif (d==14) str=&apos;K&apos;; elseif (d==15) str=&apos;M&apos;; elseif (d==16) str=&apos;P&apos;; elseif (d==17) str=&apos;Q&apos;; elseif (d==0) str=&apos;0&apos;; elseif (d==1) str=&apos;1&apos;; elseif (d==2) str=&apos;2&apos;; elseif (d==3) str=&apos;3&apos;; elseif (d==4) str=&apos;4&apos;; elseif (d==5) str=&apos;5&apos;; elseif (d==6) str=&apos;6&apos;; elseif (d==7) str=&apos;7&apos;; elseif (d==8) str=&apos;8&apos;; elseif (d==9) str=&apos;9&apos;; else str=num2str(d); end switch i case 2 str2=str; case 3 str3=str; case 4 str4=str; case 5 str5=str; case 6 str6=str; otherwise str7=str; endend% 识别出的结果以标题形式显示在图上S=strcat(&apos;鲁&apos;,str2,&apos; &apos;,str3,str4,str5,str6,str7); figure();imshow(imread(path)),title(S); 结果呈现]]></content>
      <categories>
        <category>数字图像处理</category>
      </categories>
      <tags>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库范式]]></title>
    <url>%2F2019%2F05%2F22%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[规范化过程 过程 影响 1NF ——-&gt; 2NF 消除非主属性对码的部分函数依赖 2NF ——-&gt; 3NF 消除非主属性对码的传递函数依赖 3NF ——-&gt; BCNF 消除主属性对码的部分、传递函数依赖 BCNF——&gt; 4NF 消除非平凡且非函数以来的多值依赖 4NF ——-&gt; 5NF 消除连接依赖 范式1NF定义符合1NF的关系中的每个属性都不可再分 不满足1NF 特点1NF是所有关系型数据库的最基本要求，在关系型数据库管理系统（RDBMS），例如SQL Server，Oracle，MySQL中创建数据表的时候，如果数据表的设计不符合这个最基本的要求，那么操作一定是不能成功的。也就是说，只要在RDBMS中已经存在的数据表，一定是符合1NF的。 修改后满足1NF的关系： 缺陷 学号 姓名 系名 系主任 课名 分数 101 Tom 经济 Jack 数据库 95 101 Tom 经济 Jack 英语 85 101 Tom 经济 Jack 语文 75 102 Jerry 经济 Jack 数据库 98 102 Jerry 经济 Jack 英语 55 102 Jerry 经济 Jack 音乐 75 103 Pikachu 法律 Rose 民法 85 103 Pikachu 法律 Rose 数据库 92 数据冗余每一名学生的学号、姓名、系名、系主任这些数据重复多次。每个系与对应的系主任的数据也重复多次 插入异常假如学校新建了一个系，但是暂时还没有招收任何学生（比如3月份就新建了，但要等到8月份才招生），那么是无法将系名与系主任的数据单独地添加到数据表中去的 删除异常假如将某个系中所有学生相关的记录都删除，那么所有系与系主任的数据也就随之消失了（一个系所有学生都没有了，并不表示这个系就没有了） 修改复杂假如李小明转系到法律系，那么为了保证数据库中数据的一致性，需要修改三条记录中系与系主任的数据 2NF改进2NF在1NF的基础之上，消除了非主属性对于码的部分函数依赖 概念函数依赖若在一张表中，在属性（或属性组）X的值确定的情况下，必定能确定属性Y的值，那么就可以说Y函数依赖于X，写作 X → Y。 在数据表中，不存在任意两条记录，它们在X属性（或属性组）上的值相同，而在Y属性上的值不同。这也就是“函数依赖”名字的由来，类似于函数关系 y = f(x)，在x的值确定的情况下，y的值一定是确定的。 例如，对于上图中的数据，找不到任何一条记录，它们的学号相同而对应的姓名不同。所以我们可以说姓名函数依赖于学号，写作 学号 → 姓名。但是反过来，因为可能出现同名的学生，所以有可能存在不同的两条学生记录，它们在姓名上的值相同，但对应的学号不同，所以我们不能说学号函数依赖于姓名。 表中其他的函数依赖关系还有如： 系名 → 系主任 学号 → 系主任 （学号，课名） → 分数 但以下函数依赖关系则不成立： 学号 → 课名 学号 → 分数 课名 → 系主任 （学号，课名） → 姓名 完全函数依赖在一张表中，若 X → Y，且对于 X 的任何一个真子集（假如属性组 X 包含超过一个属性的话），X ‘ → Y 不成立，那么我们称 Y 对于 X 完全函数依赖，记作$X-^F-&gt;Y$ 例如： 学号$-F-&gt;$姓名 （学号、课名）$-F-&gt;$分数 部分函数依赖假如 Y 函数依赖于 X，但同时 Y 并不完全函数依赖于 X，那么我们就称 Y 部分函数依赖于 X，记作 X $-P-&gt;$ Y 例如：（学号、课名）$-P-&gt;$ 姓名 传递函数依赖假如 Z 函数依赖于 Y，且 Y 函数依赖于 X （严格来说还有一个X 不包含于Y，且 Y 不函数依赖于Z的前提条件），那么我们就称 Z 传递函数依赖于 X ，记作 X $-T-&gt;$ Z 码设 K 为某表中的一个属性或属性组，若除 K 之外的所有属性都完全函数依赖于 K，那么我们称 K 为候选码，简称为码。在实际中我们通常可以理解为： 假如当 K 确定的情况下，该表除 K 之外的所有属性的值也就随之确定，那么 K 就是码。一张表中可以有超过一个码。（实际应用中为了方便，通常选择其中的一个码作为主码） 例如：（学号、课名）这个属性组就是码。该表中有且仅有这一个码。（假设所有课没有重名的情况） 主属性包含在任何一个码中的属性成为主属性 非主属性除了主属性之外的属性 判断是否为2NF根据2NF的定义，判断的依据实际上就是看数据表中是否存在非主属性对于码的部分函数依赖。 若存在，则数据表最高只符合1NF的要求，若不存在，则符合2NF的要求。判断的方法是： 第一步：找出数据表中所有的码。 第二步：根据第一步所得到的码，找出所有的主属性。 第三步：数据表中，除去所有的主属性，剩下的就都是非主属性了。 第四步：查看是否存在非主属性对码的部分函数依赖。 我们可以这么做： 第一步： 查看所有每一单个属性，当它的值确定了，是否剩下的所有属性值都能确定。 查看所有包含有两个属性的属性组，当它的值确定了，是否剩下的所有属性值都能确定。 …… 查看所有包含了六个属性，也就是所有属性的属性组，当它的值确定了，是否剩下的所有属性值都能确定。 看起来很麻烦是吧，但是这里有一个诀窍，就是假如A是码，那么所有包含了A的属性组， 如（A，B）、（A，C）、（A，B，C）等等，都不是码了（因为作为码的要求里有一个“完全函数依赖”） 关系如下： 第一步： 码只有一个，就是（学号、课名） 第二步： 主属性有两个：学号 与 课名 第三步： 非主属性有四个：姓名、系名、系主任、分数 第四步： 对于（学号，课名） → 姓名，有 学号 → 姓名，存在非主属性 姓名 对码（学号，课名）的部分函数依赖。对于（学号，课名） → 系名，有 学号 → 系名，存在非主属性 系名 对码（学号，课名）的部分函数依赖。对于（学号，课名） → 系主任，有 学号 → 系主任，存在非主属性 对码（学号，课名）的部分函数依赖。 所以上图只满足1NF而不满足2NF 模式分解为了符合2NF的要求，必须消除这些部分函数依赖，只有一个办法，就是将大数据表拆分成两个或者更多个更小的数据表，在拆分的过程中，要达到更高一级范式的要求，这个过程叫做”模式分解“。模式分解的方法不是唯一的，以下是其中一种方法：选课（学号，课名，分数）学生（学号，姓名，系名，系主任） 验证模式分解后是否满足2NF：对于选课表，其码是（学号，课名），主属性是学号和课名，非主属性是分数，学号确定，并不能唯一确定分数，课名确定，也不能唯一确定分数，所以不存在非主属性分数 对于码 （学号，课名）的部分函数依赖，所以此表符合2NF的要求。 对于学生表，其码是学号，主属性是学号，非主属性是姓名、系名和系主任，因为码只有一个属性，所以不可能存在非主属性对于码 的部分函数依赖，所以此表符合2NF的要求。 模式分解后： 学号 课名 分数 101 数据库 95 101 英语 85 101 语文 75 102 数据库 98 102 英语 55 102 音乐 75 103 民法 85 103 数据库 92 2NF_T2: 学号 姓名 系名 系主任 101 Tom 经济 Jack 102 Jerry 经济 Jack 103 Pikachu 法律 Rose 缺陷数据冗余学生的姓名、系名与系主任，不再像之前一样重复那么多次了 插入异常因为学生表的码是学号，不能为空，所以此操作不被允许 删除异常删除某个系中所有的学生记录，该系的信息仍然全部丢失 修改复杂李小明转系到法律系，只需要修改一次李小明对应的系的值即可 3NF改进3NF在2NF的基础之上，消除了非主属性对于码的传递函数依赖 判断是否为3NF对于选课表，主码为（学号，课名），主属性为学号和课名，非主属性只有一个，为分数，不可能存在传递函数依赖，所以选课表的设计，符合3NF的要求。 对于学生表，主码为学号，主属性为学号，非主属性为姓名、系名和系主任。因为 学号 → 系名，同时 系名 → 系主任，所以存在非主属性系主任对于码学号的传递函数依赖，所以学生表的设计，不符合3NF的要求。 模式分解分解为： 选课（学号，课名，分数）学生（学号，姓名，系名）系（系名，系主任） 对于选课表，符合3NF的要求 对于学生表，码为学号，主属性为学号，非主属性为系名，不可能存在非主属性对于码的传递函数依赖，所以符合3NF的要求 对于系表，码为系名，主属性为系名，非主属性为系主任，不可能存在非主属性对于码的传递函数依赖（至少要有三个属性才可能存在传递函数依赖关系），所以符合3NF的要求 关系如下： 3NF_T1: 学号 课名 分数 101 数据库 95 101 英语 85 101 语文 75 102 数据库 98 102 英语 55 102 音乐 75 103 民法 85 103 数据库 92 3NF_T2: 学号 姓名 系名 101 Tom 经济 102 Jerry 经济 103 Pikachu 法律 3NF_T3: 系名 系主任 经济 Jack 经济 Jack 法律 Rose 缺陷数据冗余进一步减少 插入异常插入一个尚无学生的新系的信息，因为系表与学生表目前是独立的两张表，所以不影响 删除异常删除某个系中所有的学生记录，该系的信息不会丢失 修改复杂进一步改善 BCNF改进在 3NF 的基础上消除主属性对于码的部分与传递函数依赖 若： 某公司有若干个仓库； 每个仓库只能有一名管理员，一名管理员只能在一个仓库中工作； 一个仓库中可以存放多种物品，一种物品也可以存放在不同的仓库中。每种物品在每个仓库中都有对应的数量。 那么关系模式 仓库（仓库名，管理员，物品名，数量） 属于哪一级范式？ 答： 已知函数依赖集：仓库名 → 管理员，管理员 → 仓库名，（仓库名，物品名）→ 数量码：（管理员，物品名），（仓库名，物品名）主属性：仓库名、管理员、物品名非主属性：数量∵ 不存在非主属性对码的部分函数依赖和传递函数依赖。∴ 此关系模式属于3NF 仓库名 管理员 物品名 数量 Shanghai Jack iphoneXXX 30 Shanghai Jack Ipadmini 50 Beijing Rose HuaweiP30 20 Beijing Rose Matebook14 100 插入异常对于上表，先新增加一个仓库，但尚未存放任何物品，是否可以为该仓库指派管理员？ ——不可以，因为物品名也是主属性，根据实体完整性的要求，主属性不能为空 删除异常某仓库被清空后，需要删除所有与这个仓库相关的物品存放记录，会带来什么问题？ ——仓库本身与管理员的信息也被随之删除了 修改复杂如果某仓库更换了管理员，会带来什么问题？ ——这个仓库有几条物品存放记录，就要修改多少次管理员信息 模式分解仓库（仓库名，管理员）库存（仓库名，物品名，数量） 仓库名 管理员 Shanghai Jack Beijing Rose 仓库名 物品名 数量 Shanghai iphoneXXX 30 Shanghai Ipadmini 50 Beijing HuaweiP30 20 Beijing Matebook14 100 数据冗余有改进 插入异常可以单独增加仓库 删除异常当删除某个仓库所有物品时，仓库信息得以保留 修改复杂当某个仓库更改管理员时，只需要修改一条数据]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Exp</tag>
        <tag>数据库</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语言SUM到栈式计算机STACK的机器语言的翻译]]></title>
    <url>%2F2019%2F05%2F11%2F%E8%AF%AD%E8%A8%80SUM%E5%88%B0%E6%A0%88%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%9C%BASTACK%E7%9A%84%E6%9C%BA%E5%99%A8%E8%AF%AD%E8%A8%80%E7%9A%84%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[实验内容sum.c是用c语言写的从sum语言到栈式计算机STACK的机器语言的编译器（省略了词法语法分析部分）。该程序的基本功能是先构造SUM语言的某句子的抽象语法树，然后将该语法树翻译成STACK的机器语言程序，并按顺序打印出该机器语言程序的指令。程序中有两段内容不完整（在程序中用TODO表示），请读懂并编译通过该程序，再将TODO的部分补充完整，并编译通过。 读懂程序sum.c并编译通过。（该程序可以使用gcc编译通过，其他编译环境请自行调试） 用你自己写的程序段替换程序中的TODO部分，使程序功能与实验内容的描述一致。 （此要求为额外要求，供学有余力的同学自行选择。）将程序的输入改为句子1+(2+3)的抽象语法树，尝试程序能否输出正确的结果。 实验参考 SUM语言简介：SUM语言是一种描述简单表达式的语言，该语言只有两种终结符num和+，其中num表示整型数，+表示加法。即该语言能表示整型的加法表达式。加法为左结合。 语言的文法为：E -&gt; num | E+E 栈式计算机STACK简介：这种机器有一个栈，能做的操作有两种，第一是向栈中压入一个整型数，第二是将栈顶的两个整型数弹出并做加法，然后将所得结果压入栈中。 因此，该计算机的机器语言只有两个指令，一为：PUSH n；（将整型数n压入栈中）；另一为：ADD；（无操作数，默认将栈顶的两个整型数弹出栈并相加，再将结果压入栈中）。 sum.c采用的翻译方法： SUM语言的句子先写成抽象语法树，然后对抽象语法树进行后续遍历，遍历到整型时就执行PUSH操作，遍历到+时就执行ADD操作。 SUM语言的句子翻译为STACK程序的例子： SUM语言的句子： 1+2+3 对应的抽象语法树: 12345 + / \ + 3 / \1 2 翻译成的STACK指令： ​ PUSH 1 ​ PUSH 2 ​ ADD ​ PUSH 3 ​ ADD 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define TODO() \ do&#123; \ printf ("\nAdd your code here: file \"%s\", line %d\n", \ __FILE__, __LINE__); \ &#125;while(0)///////////////////////////////////////////////// Data structures for the Sum language.enum Exp_Kind_t &#123; EXP_INT, EXP_SUM &#125;;struct Exp_t &#123; enum Exp_Kind_t kind;&#125;;struct Exp_Int &#123; enum Exp_Kind_t kind; int i;&#125;;struct Exp_Sum &#123; enum Exp_Kind_t kind; struct Exp_t *left; struct Exp_t *right;&#125;;// "constructors"struct Exp_t *Exp_Int_new(int i) &#123; struct Exp_Int *p = (struct Exp_Int *)malloc(sizeof(*p)); p-&gt;kind = EXP_INT; p-&gt;i = i; return (struct Exp_t *)p;&#125;struct Exp_t *Exp_Sum_new(struct Exp_t *left, struct Exp_t *right) &#123; struct Exp_Sum *p = (struct Exp_Sum *)malloc(sizeof(*p)); p-&gt;kind = EXP_SUM; p-&gt;left = left; p-&gt;right = right; return (struct Exp_t *)p;&#125;// "printer"void Exp_print(struct Exp_t *exp) &#123; switch ( exp-&gt;kind ) &#123; case EXP_INT: &#123; struct Exp_Int *p = (struct Exp_Int *)exp; printf("%d ", p-&gt;i); break; &#125; case EXP_SUM: &#123; struct Exp_Sum *p = (struct Exp_Sum *)exp; Exp_print(p-&gt;left); printf("+ "); Exp_print(p-&gt;right); break; &#125; default: break; &#125;&#125;//////////////////////////////////////////////// Data structures for the Stack language.enum Stack_Kind_t &#123; STACK_ADD, STACK_PUSH &#125;;struct Stack_t &#123; enum Stack_Kind_t kind;&#125;;struct Stack_Add &#123; enum Stack_Kind_t kind;&#125;;struct Stack_Push &#123; enum Stack_Kind_t kind; int i;&#125;;// "printer"void Stack_print(struct Stack_t *stack) &#123; switch ( stack-&gt;kind ) &#123; case STACK_ADD: &#123; struct Stack_Add *p = (struct Stack_Add *)stack; printf("STACK_ADD\r\n"); break; &#125; case STACK_PUSH: &#123; struct Stack_Push *p = (struct Stack_Push *)stack; printf("STACK_PUSH %d\r\n", p-&gt;i); break; &#125; default: break; &#125;&#125;// "constructors"struct Stack_t *Stack_Add_new() &#123; struct Stack_Add *p = (struct Stack_Add *)malloc(sizeof(*p)); p-&gt;kind = STACK_ADD; return (struct Stack_t *)p;&#125;struct Stack_t *Stack_Push_new(int i) &#123; struct Stack_Push *p = (struct Stack_Push *)malloc(sizeof(*p)); p-&gt;kind = STACK_PUSH; p-&gt;i = i; return (struct Stack_t *)p;&#125;/// instruction liststruct List_t &#123; struct Stack_t *instr; struct List_t *next;&#125;;struct List_t *List_new(struct Stack_t *instr, struct List_t *next) &#123; struct List_t *p = (struct List_t *)malloc(sizeof(*p)); p-&gt;instr = instr; p-&gt;next = next; return p;&#125;// "printer"void List_reverse_print(struct List_t *list) &#123; struct List_t *next = NULL; struct List_t *reverse = NULL; struct List_t *cur = list; while ( cur != NULL ) &#123; next = cur-&gt;next; cur-&gt;next = reverse; reverse = cur; cur = next; &#125; //print printf("\n"); cur = reverse; while ( cur != NULL ) &#123; Stack_print(cur-&gt;instr); cur = cur-&gt;next; &#125;&#125;//////////////////////////////////////////////////// a compiler from Sum to Stackstruct List_t *all = 0;void emit(struct Stack_t *instr) &#123; all = List_new(instr, all);&#125;// 从抽象语法树 --&gt; 中间语言void compile(struct Exp_t *exp) &#123; switch ( exp-&gt;kind ) &#123; case EXP_INT: &#123; struct Exp_Int *p = (struct Exp_Int *)exp; emit(Stack_Push_new(p-&gt;i)); break; &#125; case EXP_SUM: &#123; struct Exp_Sum *p = (struct Exp_Sum *)exp; compile(p-&gt;left); compile(p-&gt;right); emit(Stack_Add_new()); break; &#125; default: break; &#125;&#125;//////////////////////////////////////////////////// program entryint main() &#123; printf("Compile starting\n"); // build an expression tree: // + // / \ // + 4 // / \ // 2 3 struct Exp_t *exp = Exp_Sum_new(Exp_Sum_new(Exp_Int_new(2) , Exp_Int_new(3)) , Exp_Int_new(4)); // print out this tree: printf("the expression is:\n"); Exp_print(exp); // compile this tree to Stack machine instructions compile(exp); // print out the generated Stack instructons: List_reverse_print(all); printf("\nCompile finished\n"); return 0;&#125; List_reverse_print 和 compile的case EXP_SUM为填充部分 实验结果]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
        <tag>Exp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[验证Yacc的使用]]></title>
    <url>%2F2019%2F05%2F11%2F%E9%AA%8C%E8%AF%81Yacc%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[实验内容 输入为一个布尔表达式，以换行结束。输出为这个布尔表达式的真值（true或false）。 尝试二义文法和非二义文法两种不同的实现方式。布尔表达式二义文法为：S –&gt; S or S | S and S | not S | (S) | true | false，其中优先级or &lt; and &lt; not，or 和 and 左结合，not 右结合。 非二义文法请参照表达式非二义文法自己写出来。 实验过程cal.l12345678910111213141516171819202122232425262728%&#123;#include "cal.tab.h"int yywrap(void)&#123; return 1;&#125;%&#125;delim [ \t ]ws &#123;delim&#125;+digit [0-9]num &#123;digit&#125;+%%0 &#123;return FALSE;&#125;&#123;num&#125; &#123;return TRUE;&#125;"+" &#123;return PLUS;&#125;"-" &#123;return MINUS;&#125;"*" &#123;return TIMES;&#125;"/" &#123;return DIVIDE;&#125;"||" &#123;return OR;&#125;"&amp;&amp;" &#123;return AND;&#125;"!" &#123;return NOT;&#125;"(" &#123;return LPAREN;&#125;")" &#123;return RPAREN;&#125;&#123;ws&#125; &#123;;&#125;"\n" &#123;return ENTER;&#125;. &#123;printf("\nLEX:ERROR! c=%s\n", yytext);&#125; 二义文法二义文法12345678910S –&gt; S or S | S and S | not S | (S) | true | false表示为：expr1 : expr1 OR expr1 &#123;$$ = ($1) ? 1 : ($3);&#125; | expr1 AND expr1 &#123;$$ = ($1) ? ($3) : 0;&#125; | NOT expr1 &#123;$$ = ($2) ? 0 : 1;&#125; | TRUE &#123;$$ = 1;&#125; | FALSE &#123;$$ = 0;&#125; ; 优先级123456%token NUM LPAREN RPAREN ENTER PLUS MINUS TIMES DIVIDE AND OR NOT TRUE FALSE%left OR%left AND%right NOT%left PLUS MINUS%left TIMES DIVIDE cal.y123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657%&#123; #include &lt;ctype.h&gt; #include &lt;stdio.h&gt; int yylex(); int yyerror(char* s); #define YYSTYPE double /* 将Yacc栈定义为double类型 */ #define YYDEBUG 1 /* 允许debug模式 */%&#125;%token NUM LPAREN RPAREN ENTER PLUS MINUS TIMES DIVIDE AND OR NOT TRUE FALSE%left OR%left AND%right NOT%left PLUS MINUS%left TIMES DIVIDE%% /* 这样写prog可以让分析器每次读入一行进行分析，下一行重新分析expr */prog : prog expln | expln ;expln : expr ENTER &#123;if($$) printf("true\n");else printf("false\n");&#125; ; expr : expr PLUS term &#123;$$ = $1 + $3;&#125; | expr MINUS term &#123;$$ = $1 - $3;&#125; | term ; term : term TIMES factor &#123;$$ = $1 * $3;&#125; | term DIVIDE factor &#123;$$ = $1 / $3;&#125; | factor ; factor : LPAREN expr RPAREN &#123;$$ = $2;&#125; | MINUS factor &#123;$$ = - $2;&#125; | NUM &#123;$$ = $1;&#125; | expr1 ;expr1 : expr1 OR expr1 &#123;$$ = ($1) ? 1 : ($3);&#125; | expr1 AND expr1 &#123;$$ = ($1) ? ($3) : 0;&#125; | NOT expr1 &#123;$$ = ($2) ? 0 : 1;&#125; | TRUE &#123;$$ = 1;&#125; | FALSE &#123;$$ = 0;&#125; ; %%int main()&#123; // yydebug = 1; yyparse(); return 0;&#125; 非二义文法非二义文法12345678910111213141516E -&gt; E OR T | TT -&gt; T AND F | FF -&gt; NOT F | (F) | true | falseexpr1 : expr1 OR expr2 &#123;$$ = ($1) ? 1 : ($3);&#125; | expr2 ;expr2 : expr2 AND expr3 &#123;$$ = ($1) ? ($3) : 0;&#125; | expr3 ;expr3 : NOT expr3 &#123;$$ = ($2) ? 0 : 1;&#125; | TRUE &#123;$$ = 1;&#125; | FALSE &#123;$$ = 0;&#125; ; cal.y123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263%&#123; #include &lt;ctype.h&gt; #include &lt;stdio.h&gt; int yylex(); int yyerror(char* s); #define YYSTYPE double /* 将Yacc栈定义为double类型 */ #define YYDEBUG 1 /* 允许debug模式 */%&#125;%token NUM LPAREN RPAREN ENTER PLUS MINUS TIMES DIVIDE AND OR NOT TRUE FALSE%left OR%left AND%right NOT%left PLUS MINUS%left TIMES DIVIDE%% /* 这样写prog可以让分析器每次读入一行进行分析，下一行重新分析expr */prog : prog expln | expln ;expln : expr ENTER &#123;if($$) printf("true\n");else printf("false\n");&#125; ; expr : expr PLUS term &#123;$$ = $1 + $3;&#125; | expr MINUS term &#123;$$ = $1 - $3;&#125; | term ; term : term TIMES factor &#123;$$ = $1 * $3;&#125; | term DIVIDE factor &#123;$$ = $1 / $3;&#125; | factor ; factor : LPAREN expr RPAREN &#123;$$ = $2;&#125; | MINUS factor &#123;$$ = - $2;&#125; | NUM &#123;$$ = $1;&#125; | expr1 ;expr1 : expr1 OR expr2 &#123;$$ = ($1) ? 1 : ($3);&#125; | expr2 ;expr2 : expr2 AND expr3 &#123;$$ = ($1) ? ($3) : 0;&#125; | expr3 ;expr3 : NOT expr3 &#123;$$ = ($2) ? 0 : 1;&#125; | TRUE &#123;$$ = 1;&#125; | FALSE &#123;$$ = 0;&#125; ; %%int main()&#123; // yydebug = 1; yyparse(); return 0;&#125; makefile1234567891011121314151617181920cal3: cal.tab.o lex.yy.o gcc -o cal3 cal.tab.o lex.yy.o -lylex.yy.o: lex.yy.c cal.tab.h gcc -c lex.yy.ccal.tab.o: cal.tab.c gcc -c cal.tab.clex.yy.c: cal.l flex cal.lcal.tab.c: cal.y bison -dv cal.ycal.tab.h: cal.y echo "cal.tab.h was created at the same time as cal.tab.c."clean: rm -f cal3.exe lex.yy.o cal.tab.o lex.yy.c cal.tab.c cal.tab.h cal3.exe.stackdump cal.output 实验结果]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
        <tag>Exp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Lex设计词法分析器]]></title>
    <url>%2F2019%2F05%2F11%2F%E7%94%A8Lex%E8%AE%BE%E8%AE%A1%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[实验内容Exp2使用lex为下述文法语言写一个词法分析器。 &lt;程序&gt; -&gt; PROGRAM &lt;标识符&gt; ; &lt;分程序&gt;&lt;分程序&gt; -&gt; &lt;变量说明&gt; BEGIN &lt;语句表&gt; END.&lt;变量说明&gt; -&gt; VAR &lt;变量说明表&gt;;&lt;变量说明表&gt; -&gt;&lt;变量表&gt;: &lt;类型&gt; | &lt;变量表&gt;: &lt;类型&gt;; &lt;变量说明表&gt;&lt;类型&gt;- &gt; INTEGER | REAL&lt;变量表&gt; -&gt; &lt;变量&gt; | &lt;变量&gt;, &lt;变量表&gt;&lt;语句表&gt; -&gt; &lt;语句&gt; | &lt;语句&gt;; &lt;语句表&gt;&lt;语句&gt; -&gt; &lt;赋值语句&gt; | &lt;条件语句&gt; | | &lt;复合语句&gt;&lt;赋值语句&gt; -&gt; &lt;变量&gt; := &lt;算术表达式&gt;&lt;条件语句&gt; -&gt; IF &lt;关系表达式&gt; THEN &lt;语句&gt; ELSE &lt;语句&gt; -&gt; WHILE &lt;关系表达式&gt; DO &lt;语句&gt;&lt;复合语句&gt; -&gt; BEGIN &lt;语句表&gt; END&lt;算术表达式&gt; -&gt; &lt;项&gt; | &lt;算术表达式&gt; + &lt;项&gt; | &lt;算术表达式&gt; - &lt;项&gt;&lt;项&gt; -&gt; &lt;因式&gt; | &lt;项&gt; * &lt;因式&gt; | &lt;项&gt; / &lt;因式&gt;&lt;因式&gt; -&gt; &lt;变量&gt; | &lt;常数&gt; | (&lt;算术表达式&gt;)&lt;关系表达式&gt; -&gt; &lt;算术表达式&gt; &lt;关系符&gt; &lt;算术表达式&gt;&lt;变量&gt; -&gt; &lt;标识符&gt;&lt;标识符&gt; -&gt; &lt;标识符&gt;&lt;字母&gt; | &lt;标识符&gt;&lt;数字&gt; | &lt;字母&gt;&lt;常数&gt; -&gt; &lt;整数&gt; | &lt;浮点数&gt;&lt;整数&gt; -&gt; &lt;数字&gt; | &lt;数字&gt; &lt;整数&gt;&lt;浮点数&gt; -&gt; .&lt;整数&gt; | &lt;整数&gt;.&lt;整数&gt;&lt;关系符&gt; -&gt; &lt; | &lt;= | = | &gt; | &gt;=| &lt;&gt;&lt;字母&gt; -&gt; A | B | …| X | Y | Z | a | b | …| x | y | z&lt;数字&gt; -&gt; 0|1|2|…|9 Exp3 要求每次调用词法分析函数yylex时，只返回一个记号(token)； 为记号选择适当的属性值，并且每次词法分析函数返回记号前，都将记号的属性值存入全局变量yylval中。（yylval可以自己定义为全局变量）； 记号属性值的选择：标识符的属性为标识符的名字字符串（例如，标识符name1的属性为字符串”name1”），整数的属性为整数值，浮点数的属性为浮点数值。其他记号属性值可自己选择。关键字可以省略属性。 注意：由于属性值需要存入yylval中，并且记号属性值的类型比较多（可能为字符串、整数、浮点数等），因此yylval必须能同时存放各种类型的值（提示：将yylval设置为union类型）。 在cygwin下用flex和gcc工具将实验调试通过，并能通过例子parser0中testcases目录下的test1.p测试例的测试。 实验过程添加记号名12345678910#define PROGRAM 36#define BEGIN1 37#define VAR 38#define THEN 39#define INT 40#define FLOAT 41#define END 42#define REAL 43#define COMMA 44#define COLON 45 正规定义12345int &#123;digit&#125;+(E[+-]?&#123;digit&#125;+)?float &#123;digit&#125;*(\.&#123;digit&#125;+)(E[+-]?&#123;digit&#125;+)? allow ((\\\\)|(\\\")|(\\\')|(\\&#123;letter&#125;)|(\\&#123;digit&#125;))*str (&#123;allow&#125;|[^\"\'\n\\])*\"end END|END. 定义yylval12345union data&#123; int inum; float fnum; char c[20];&#125;yylval; 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203/* 把讨厌的注释去掉 */%&#123;#include &lt;stdio.h&gt; #define LT 1#define LE 2#define GT 3#define GE 4#define EQ 5#define NE 6#define WHILE 18#define DO 19#define ID 20//#define NUMBER 21#define RELOP 22#define NEWLINE 23#define ERRORCHAR 24#define LEFTBRACKET 25#define RIGHTBRACKET 26#define SEMICOLON 27#define ASSIGN 28#define ARITHMETIC 29#define NOTE 30#define IF 31#define ELSE 32#define LEFTBRACES 33#define RIGHTBRACES 34#define STRING 35#define STRERROR 46#define PROGRAM 36#define BEGIN1 37#define VAR 38#define THEN 39#define INT 40#define FLOAT 41#define END 42#define REAL 43#define COMMA 44#define COLON 45union data&#123; int inum; float fnum; char c[20];&#125;yylval;%&#125;underline [_] delim [ \t \n]ws &#123;delim&#125;+letter [A-Za-z]digit [0-9]id &#123;underline&#125;*&#123;letter&#125;(&#123;letter&#125;|&#123;digit&#125;)*int &#123;digit&#125;+(E[+-]?&#123;digit&#125;+)?float &#123;digit&#125;*(\.&#123;digit&#125;+)(E[+-]?&#123;digit&#125;+)? allow ((\\\\)|(\\\")|(\\\')|(\\&#123;letter&#125;)|(\\&#123;digit&#125;))*str (&#123;allow&#125;|[^\"\'\n\\])*\"end END|END./* 状态（或条件）定义可以定义在这里 * INITIAL是一个默认的状态，不需要定义 */%s COMMENT%s NOTE1%s QUOTE%%&lt;INITIAL&gt;"/*" &#123;BEGIN COMMENT;&#125;&lt;COMMENT&gt;"*/" &#123;BEGIN INITIAL;&#125;&lt;COMMENT&gt;.|\n &#123;;&#125;&lt;INITIAL&gt;"//" &#123;BEGIN NOTE1;&#125;&lt;NOTE1&gt;\n &#123;BEGIN INITIAL;&#125;&lt;NOTE1&gt;. &#123;;&#125;&lt;INITIAL&gt;"\"" &#123;BEGIN QUOTE;&#125;&lt;QUOTE&gt;"\"" &#123;BEGIN INITIAL;&#125;&lt;QUOTE&gt;"\n" &#123;BEGIN INITIAL;&#125;&lt;QUOTE&gt;&#123;str&#125; &#123;BEGIN INITIAL; return (STRING);&#125;&lt;QUOTE&gt;[^\"\n] &#123;;&#125;&lt;INITIAL&gt;&#123;ws&#125; &#123;;&#125;&lt;INITIAL&gt;PROGRAM &#123;return (PROGRAM);&#125;&lt;INITIAL&gt;BEGIN &#123;return (BEGIN1);&#125;&lt;INITIAL&gt;&#123;end&#125; &#123;return (END);&#125;&lt;INITIAL&gt;WHILE &#123;return (WHILE);&#125;&lt;INITIAL&gt;DO &#123;return (DO);&#125;&lt;INITIAL&gt;IF &#123;return (IF);&#125;&lt;INITIAL&gt;THEN &#123;return (THEN);&#125;&lt;INITIAL&gt;ELSE &#123;return (ELSE);&#125;&lt;INITIAL&gt;while &#123;return (WHILE);&#125;&lt;INITIAL&gt;do &#123;return (DO);&#125;&lt;INITIAL&gt;if &#123;return (IF);&#125;&lt;INITIAL&gt;else &#123;return (ELSE);&#125;&lt;INITIAL&gt;then &#123;return (THEN);&#125;&lt;INITIAL&gt;VAR &#123;return (VAR);&#125;&lt;INITIAL&gt;&#123;int&#125; &#123;sscanf(yytext,"%d",&amp;yylval.inum); return (INT);&#125;&lt;INITIAL&gt;&#123;float&#125; &#123;sscanf(yytext,"%f",&amp;yylval.fnum); return (FLOAT);&#125;&lt;INITIAL&gt;REAL &#123;return (REAL);&#125;&lt;INITIAL&gt;&#123;id&#125; &#123;sscanf(yytext,"%s",&amp;yylval.c); return (ID);&#125;&lt;INITIAL&gt;"&lt;" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"&lt;=" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"==" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"!=" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"&gt;" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"&gt;=" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"(" &#123;return (LEFTBRACKET);&#125;&lt;INITIAL&gt;")" &#123;return (RIGHTBRACKET);&#125;&lt;INITIAL&gt;"&#123;" &#123;return (LEFTBRACES);&#125;&lt;INITIAL&gt;"&#125;" &#123;return (RIGHTBRACES);&#125;&lt;INITIAL&gt;";" &#123;return (SEMICOLON);&#125;&lt;INITIAL&gt;"=" &#123;return (ASSIGN);&#125;&lt;INITIAL&gt;":=" &#123;return (ASSIGN);&#125;&lt;INITIAL&gt;":" &#123;return (COLON);&#125;&lt;INITIAL&gt;"+" &#123;return (ARITHMETIC);&#125;&lt;INITIAL&gt;"-" &#123;return (ARITHMETIC);&#125;&lt;INITIAL&gt;"*" &#123;return (ARITHMETIC);&#125;&lt;INITIAL&gt;"/" &#123;return (ARITHMETIC);&#125;&lt;INITIAL&gt;"," &#123;return (COMMA);&#125;&lt;INITIAL&gt;. &#123;return ERRORCHAR;&#125;%%int yywrap ()&#123; return 1;&#125;void writeout(int c)&#123; switch(c)&#123; case ERRORCHAR: fprintf(yyout, "(ERRORCHAR, \"%s\") ", yytext);break; case PROGRAM: fprintf(yyout, "(PROGRAM, \"%s\") ", yytext);break; case BEGIN1: fprintf(yyout, "(BEGIN, \"%s\") ", yytext);break; case END: fprintf(yyout, "(END, \"%s\") ", yytext);break; case IF: fprintf(yyout, "(IF, \"%s\") ", yytext);break; case THEN: fprintf(yyout, "(THEN, \"%s\") ", yytext);break; case ELSE: fprintf(yyout, "(ELSE, \"%s\") ", yytext);break; case VAR: fprintf(yyout, "(VAR, \"%s\") ", yytext);break; case INT: fprintf(yyout, "(INT, \"%s\") ", yytext);break; case FLOAT: fprintf(yyout, "(FLOAT, \"%s\") ", yytext);break; case REAL: fprintf(yyout, "(REAL, \"%s\") ", yytext);break; case COMMA: fprintf(yyout, "(COMMA, \"%s\") ", yytext);break; case COLON: fprintf(yyout, "(COLON, \"%s\") ", yytext);break; case RELOP: fprintf(yyout, "(RELOP, \"%s\") ", yytext);break; case WHILE: fprintf(yyout, "(WHILE, \"%s\") ", yytext);break; case DO: fprintf(yyout, "(DO, \"%s\") ", yytext);break; case ID: fprintf(yyout, "(ID, \"%s\") ", yytext);break; case LEFTBRACKET: fprintf(yyout, "(LEFTBRACKET, \"%s\") ", yytext);break; case RIGHTBRACKET: fprintf(yyout, "(RIGHTBRACKET, \"%s\") ", yytext);break; case LEFTBRACES: fprintf(yyout, "(LEFTBRACES, \"%s\") ", yytext);break; case RIGHTBRACES: fprintf(yyout, "(RIGHTBRACES, \"%s\") ", yytext);break; case SEMICOLON: fprintf(yyout, "(SEMICOLON, \"%s\") ", yytext);break; case ASSIGN: fprintf(yyout, "(ASSIGN, \"%s\") ", yytext);break; case ARITHMETIC: fprintf(yyout, "(ARITHMETIC, \"%s\") ", yytext);break; case NOTE: fprintf(yyout, "(NOTE, \"%s\") ", yytext);break; case NEWLINE: fprintf(yyout, "\n");break; case STRING: fprintf(yyout, "(STRING, \"%s\") ", yytext);break; default:break; &#125; return;&#125;int main (int argc, char ** argv)&#123; int c,j=0; if (argc&gt;=2)&#123; if ((yyin = fopen(argv[1], "r")) == NULL)&#123; printf("Can't open file %s\n", argv[1]); return 1; &#125; if (argc&gt;=3)&#123; yyout=fopen(argv[2], "w"); &#125; &#125; while (c = yylex())&#123; writeout(c); j++; if (j%5 == 0) writeout(NEWLINE); &#125; if(argc&gt;=2)&#123; fclose(yyin); if (argc&gt;=3) fclose(yyout); &#125; return 0;&#125; 实验结果测试样例 运行结果]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
        <tag>Exp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cygwin环境的熟悉和lex的使用1]]></title>
    <url>%2F2019%2F05%2F11%2FCygwin%E7%8E%AF%E5%A2%83%E7%9A%84%E7%86%9F%E6%82%89%E5%92%8Clex%E7%9A%84%E4%BD%BF%E7%94%A81%2F</url>
    <content type="text"><![CDATA[实验内容Exp1读懂exam1.l和exam2.l两个例子，使用cygwin下的flex工具将exam1.l和exam2.l编译并调试通过。并且修改exam2.l，在其基础上增加如下记号： 左右大小括号：{ } ( ) 将关系算符改写成C中的形式 分号、赋值号：; = 关键字：if else 双斜线表示的注释：// 算术运算符号：+ - * / 将标识符改为可含有下划线，并且可以以下划线开头 将注释内容忽略 Exp e1在实验1所改写的程序的基础上增加识别string记号。string是字符串，如果”出现在字符串中，则必须转义，写成\”形式；如果\出现在字符串中，也必须转义，写成\形式。 在cygwin下用flex和gcc工具将实验调试通过，并写出测试例测试正确性。同时该实验必须满足如下要求： string是字符串，它是以双引号括起的一串字符。 双引号内的字符有如下要求： 不能包含单独的”或者\，除非用\进行转义。例如字符串内的”写成\”，而\写成\。 字符串内可以出现转义字符。转义字符可简化表示为\c，其中c为任意字母或(反斜杠),”（双引号）,’（单引号）三个符号中的一个。 字符串内不可包含实体的换行。（可以包含\n，但是如果两个“”中的字符串出现在两行中，即包含了实体换行，则不应识别为字符串） 实验过程Exp1添加记号名12345678910111213#define NEWLINE 23#define ERRORCHAR 24#define LEFTBRACKET 25 //bracket 为小括号 ： （）#define RIGHTBRACKET 26#define SEMICOLON 27 //分号#define ASSIGN 28 //赋值#define ARITHMETIC 29 //算术#define NOTE 30 注释#define IF 31#define ELSE 32#define LEFTBRACES 33 //braces 为大括号 ： &#123; &#125;#define RIGHTBRACES 34 定义动作123456789101112131415161718&lt;INITIAL&gt;"&lt;" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"&lt;=" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"==" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"!=" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"&gt;" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"&gt;=" &#123;return (RELOP);&#125;&lt;INITIAL&gt;"(" &#123;return (LEFTBRACKET);&#125;&lt;INITIAL&gt;")" &#123;return (RIGHTBRACKET);&#125;&lt;INITIAL&gt;"&#123;" &#123;return (LEFTBRACES);&#125;&lt;INITIAL&gt;"&#125;" &#123;return (RIGHTBRACES);&#125;&lt;INITIAL&gt;";" &#123;return (SEMICOLON);&#125;&lt;INITIAL&gt;"=" &#123;return (ASSIGN);&#125;&lt;INITIAL&gt;"+" &#123;return (ARITHMETIC);&#125;&lt;INITIAL&gt;"-" &#123;return (ARITHMETIC);&#125;&lt;INITIAL&gt;"*" &#123;return (ARITHMETIC);&#125;&lt;INITIAL&gt;"/" &#123;return (ARITHMETIC);&#125;&lt;INITIAL&gt;. &#123;return ERRORCHAR;&#125; 更改writeout函数1234567891011121314151617181920212223void writeout(int c)&#123; switch(c)&#123; case ERRORCHAR: fprintf(yyout, "(ERRORCHAR, \"%s\") ", yytext);break; case RELOP: fprintf(yyout, "(RELOP, \"%s\") ", yytext);break; case WHILE: fprintf(yyout, "(WHILE, \"%s\") ", yytext);break; case DO: fprintf(yyout, "(DO, \"%s\") ", yytext);break; case NUMBER: fprintf(yyout, "(NUM, \"%s\") ", yytext);break; case ID: fprintf(yyout, "(ID, \"%s\") ", yytext);break; case LEFTBRACKET: fprintf(yyout, "(LEFTBRACKET, \"%s\") ", yytext);break; case RIGHTBRACKET: fprintf(yyout, "(RIGHTBRACKET, \"%s\") ", yytext);break; case LEFTBRACES: fprintf(yyout, "(LEFTBRACES, \"%s\") ", yytext);break; case RIGHTBRACES: fprintf(yyout, "(RIGHTBRACES, \"%s\") ", yytext);break; case SEMICOLON: fprintf(yyout, "(SEMICOLON, \"%s\") ", yytext);break; case ASSIGN: fprintf(yyout, "(ASSIGN, \"%s\") ", yytext);break; case ARITHMETIC: fprintf(yyout, "(ARITHMETIC, \"%s\") ", yytext);break; case NOTE: fprintf(yyout, "(NOTE, \"%s\") ", yytext);break; case IF: fprintf(yyout, "(IF, \"%s\") ", yytext);break; case ELSE: fprintf(yyout, "(ELSE, \"%s\") ", yytext);break; case NEWLINE: fprintf(yyout, "\n");break; default:break; &#125; return;&#125; Exp e1增加String记号12#define STRING 35#define STRERROR 36 进行正规定义12allow ((\\\\)|(\\\")|(\\\')|(\\&#123;letter&#125;)|(\\&#123;digit&#125;))*str (&#123;allow&#125;|[^\"\'\n\\])*\" 增加引用状态12345&lt;INITIAL&gt;"\"" &#123;BEGIN QUOTE;&#125;&lt;QUOTE&gt;"\"" &#123;BEGIN INITIAL;&#125;&lt;QUOTE&gt;"\n" &#123;BEGIN INITIAL;&#125;&lt;QUOTE&gt;&#123;str&#125; &#123;BEGIN INITIAL; return (STRING);&#125;&lt;QUOTE&gt;[^\"\n] &#123;;&#125; QUOTE状态以双引号开始，双引号结束，当匹配到除字符串str和单引号、回车之外的任意字符，返回ERRORCHAR 当QUOTE状态下，遇到回车则进入INITIAL状态 实验结果编译运行123flex exam2.lettergcc lex.yy.c -lfl./a.out test2.p 对于不满足string条件的STRERROR直接不输出 对于string6 , 在本分析器中当遇到第一个双引号时，进入QUOTE状态，之后string6”被识别为str类型，但虽然str以双引号结尾，但不将双引号作为字符串的一部分，（如果string6”被作为字符串的话，string6””应该被识别为str类型） 之后，QUOTE状态结束，遇到双引号又进入QUOTE状态，遇到回车，结束QUOTE状态 对于string2 ， string3: ​ allow ((\\\\)|(\\\&quot;)|(\\\&#39;)|(\\{letter})|(\\{digit}))* ​ “ \ ”、“ \” ”属于allow范围，因此包含在字符串内 对于string4: “\n \’ \0 \a”均属于allow范围，包含在字符串内 对于string5，string7，string，8，没有匹配到合适的str类型，因此匹配到的STRERROR类型不输出，最后不会有输出结果]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
        <tag>Exp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客搭建]]></title>
    <url>%2F2019%2F04%2F08%2F%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[新建仓库新建名为 yourgithubname.github.io 的仓库 Git Nodejs直接官网安装 Git 、Nodejs 配置SSH-KEYssh-keygen -t rsa -C &quot;邮件地址&quot; 连续三次回车，会生成key在用户文件目录下，找到.ssh\id_rsa.pub文件，记事本打开并复制里面的内容，打开你的 github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key： $ git config --global user.name &quot;liuxianan&quot;// 你的github用户名，非昵称$ git config --global user.email &quot;xxx@qq.com&quot;// 填写你的github注册邮箱 测试KEY$ ssh -T git@github.com 邮箱地址不用换 如果看到 Hi XX! You&#39;ve successfully authenticated, but GitHub does not provide shell access. 证明已经成功 Host key verification failed如果提示 Host key verification failed ， 输入 ssh-keyscan -H github.com &gt;&gt; ~/.ssh/known_hosts 之后重新测试 npm install hexo安装hexo]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字图像处理-图像合成]]></title>
    <url>%2F2019%2F03%2F28%2F%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E5%9B%BE%E5%83%8F%E5%90%88%E6%88%90%2F</url>
    <content type="text"><![CDATA[图像分割选择特定拓展名12345678img_path = &apos;pics/&apos;;ext = &#123;&apos;*.jpeg&apos;,&apos;*.jpg&apos;,&apos;*.png&apos;&#125;;img_list = [];for i = 1:numel(ext) img_list = [img_list ; dir(fullfile(img_path,ext&#123;i&#125;))];endimg_num = length(img_list); 转换为特定尺寸的灰度图像1234567891011if img_num &gt; 0 for j = 1 : img_num img_name = img_list(j).name; img = imread(strcat(img_path,img_name)); img = imresize(img,[640 480]); G = rgb2gray(img); strname = strsplit(img_name,&apos;.&apos;); name = strname&#123;1,1&#125;; imwrite(G , strcat(img_path, name , &apos;.gif&apos;)); endend 求素材图片的RGB平均值123456789101112131415161718192021SIZE = 5;img_RGB = zeros(img_num,SIZE,SIZE,3);average_rgb = zeros(img_num,3);if img_num &gt; 0 for j = 1:img_num img_name = img_list(j).name; img = imread(strcat(img_path,img_name)); img = imresize(img,[SIZE SIZE]); img_RGB(j,:,:,:) = img; R = img(:,:,1); G = img(:,:,2); B = img(:,:,3); average_rgb(j,1)=mean(mean(R)); average_rgb(j,2)=mean(mean(G)); average_rgb(j,3)=mean(mean(B)); endend 替换为素材图片123456789101112131415161718192021222324252627original_Img = (&apos;original.png&apos;);Image_size = size(original_Img);Image_RGB = zeros(Image_size(1),Image_size(2),3);Image_RGB = original_Img(:,:,:);for row = 1 : SIZE :Image_size(1)-SIZE for col = 1 : SIZE :Image_size(2)-SIZE rgb_mean = zeros(3); for k = 1:3 temp = original_Img(row:row+SIZE-1 ,col:col+SIZE-1,k); rgb_mean(k) = mean(mean(temp)); end deviation = zeros(1,img_num); for k = 1:img_num deviation(k) = abs(average_rgb(k,1) - rgb_mean(1)) + abs(average_rgb(k,2) - rgb_mean(2)) + abs(average_rgb(k,3) - rgb_mean(3)); 求目标区域与每一个素材图片的RGB误差 end [min_value,min_position] = min(deviation); %得到最小值下标 Image_RGB(row:row+SIZE-1 ,col:col+SIZE-1,:) = img_RGB(min_position,:,:,:); endendImage_RGB = uint8(Image_RGB);imwrite(Image_RGB,&apos;0.jpg&apos;); 实验结果素材图片 original pic After]]></content>
      <categories>
        <category>数字图像处理</category>
      </categories>
      <tags>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI-02深度学习概述]]></title>
    <url>%2F2019%2F03%2F04%2FAI-02%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[M-P神经元 为什么需要激活函数 激活函数举例 权重人工设置m-p神经元的权重由人工设置，无法学习 单层感知器首个可以学习的神经网络 逻辑实现 多层感知器异或 单层感知器，无法实现异或关系，无法找到一条线完美分开数据（0、1） 同或三层感知机实现同或关系 单隐层神经网络可视化urlhttp://playground.tensorflow.org/ 万有逼近定理 双隐层感知器 神经网络每一层作用 更深 or 更宽 误差反向传播在训练神经网络的过程中，各个神经元的权重是通过误差的反向传播确定的，更新权重时，权重沿着误差函数梯度下降方向改变，使误差下降最快。 对于整个神经网络最后的误差来说，每一个神经元对于误差做出的贡献不同，如果激活函数选择sigmoid函数的话，输出层和隐层神经元的责任如图，计算出每个神经元的责任就可以将结果带入权重的更新公式，来调整权重。由于整个计算过程是从输出层开始，反向计算，所以也叫做误差的反向传播。 梯度消失反向传播是误差沿着梯度方向反向传播，求偏导的过程中要计算激活函数的导数 如果激活函数选择sigmoid函数的话，那么函数的导数值最大仅为4分之1，在1/2处取得，但很多情况下，函数值会落入饱和区，即sigmoid函数上下平滑的部分，这些地方的导数值可能会很小很小。而且这仅为一层网络，如果是多层网络的话，这个偏导值就会非常小，误差在反向传播的过程中就会消失，最后的结果可能是只改变了输出层的权重，而前面的网络权重都没有更新。 逐层预训练 多层神经网络可能出现的两个问题，一是局部极小值，初始值选取不同，可能会导致网络收敛到局部极小值点，随着神经网络隐层的增多，局部极小值的数量会成倍增加。二就是梯度消失。 解决这两个问题的一个途径就是通过逐层预训练进行参数的初始化，如果参数的初始值选取得当，那么网络就会收敛到全局的极小值点，同时，由于梯度消失可能会导致前面几层网络权重无法更新，但是如果在开始的时候，就有一个较好的初始值，也可以使得网络训练出一个较好的结果。 自编码器 逐层预训练是想得到一个好的初始值，但是如果网络有多个隐层，并不是每个隐层都能看到输出，也就是没有监督信息。在没有监督信息的情况下进行预训练主要有两种方法，自编码器和受限玻尔兹曼机。 自编码器假设输出与输入相同，是一种 尽可能复现输入信号的神经网络。 堆叠自编码器就是将多个自编码器进行串联，首先训练所有的隐层，在隐层训练完之后，通过输出层得到的监督结果，重新对整个网络进行微调 受限玻尔兹曼机 受限玻尔兹曼机是一个两层神经网络，包括可见层和隐藏层，不同层全连接，层内无连接，是二分图。 他的过程是首先通过可见层的输入，得到一个输出，再将输出传入隐藏层，重新得到一个可见层，在正向和反向的传播过程中，同一路线的权重相同，但是偏置不同。目的是让得到的可见层与原来的一致，这样就可以将隐藏层作为输入的一个特征，从而得到初始化。 之所以叫受限玻尔兹曼机是因为应用了热力学中的玻尔兹曼分布。巧合的是根据玻尔兹曼分布，假设所有的节点都用0，1二进制来表示，推导出的条件概率结果正好是sigmoid函数。 深度信念网络DBN 自编码器与RBM对比 自编码器 RBM 自编码器编码和解码函数不同 RBM共享权重矩阵W，两个偏置向量 自编码器通过非线性变换学习特征，是确定的，特征值可以为任何实数 RBM基于概率分布定义，高层表示为底层特征的条件概率，输出只有两种状态 （未激活激活），用二进制0/1表示 自编码器直接对条件概率 建模，是判别式模型 RBM对联合概率密度建模， 是生成式模型 矩阵线性变换 求解特征值、特征向量 秩、奇异值与数据降维 方阵才有奇异矩阵和非奇异矩阵的概念 矩阵秩不为满秩则为奇异矩阵 矩阵行列式等于0，说明不满秩 设A为mn阶矩阵，q=min(m,n)，A\A的q个非负特征值的算术平方根叫作A的奇异值。 奇异值标识着矩阵的“本质信息”，只保留奇异值分解之后奇异值更高的矩阵即可基本还原原始数据 奇异值分解与低秩近似矩阵的低秩近似是一种稀疏表示形式,即利用一个秩较低的矩阵来近似表达原矩阵,不但能保留原矩阵的主要特征,而且可以降低数据的存储空间和计算复杂度 逻辑回归与最大似然逻辑回归是分类任务，但采用了回归的方法，以二分类为例，如果采用线性回归的方法就是希望用一条直线将正负样例分开，由于直线的局限性，所以企图引入Sigmoid函数，从而引入曲线 确定函数形式之后，希望确定一组参数W，从而找到能够完成分类任务的曲线，从而引入最大似然估计 最大似然概率描述的是在一定条件下某个事件发生的可能性，概率越大说明这件事情越可能会发生；而似然描述的是结果已知的情况下，该事件在不同条件下发生的可能性，似然函数的值越大说明该事件在对应的条件下发生的可能性越大 假如有一个罐子，里面有黑白两种颜色的球，数目多少不知，两种颜色的比例也不知。我 们想知道罐中白球和黑球的比例，但我们不能把罐中的球全部拿出来数。现在我们可以每次任意从已经摇匀的罐中拿一个球出来，记录球的颜色，然后把拿出来的球 再放回罐中。这个过程可以重复，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例最有可能是多少？ 因此在逻辑回归中，若想让预测出的结果全部正确的概率最大,根据最大似然估计，就是所有样本预测正确的概率相乘得到的P(总体正确)最大 频率学派与贝叶斯学派]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI_01人工智能概述]]></title>
    <url>%2F2019%2F03%2F04%2FAI-01%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[概述什么是人工智能人工智能(Artificial Intelligence)使一部机器像人一样进行感知、认知、决策、执行的人工程序或系统 标志性事件 人工智能发展阶段 人工智能三个层面计算智能能存能算 感知智能能听会说、能看会认 认知智能能理解、会思考 人工智能 &gt; 机器学习 &gt; 深度学习 逻辑演绎 vs 归纳总结 专家系统根据专家定义的知识和经验，进行推理和判断，从而模拟人类专家的决策过程来解决问题。 知识工程 vs 机器学习 计算机视觉人脸识别图像分类目标检测图像搜索图像分割视频监控语音技术语音识别语音合成声纹识别自然语言处理文本分类机器翻译知识图谱自动问答信息检索文本生成机器学习的定义最常用定义计算机系统能够利用经验提高自身的性能 可操作定义机器学习本质是一个基于经验数据的函数估计问题 统计学定义提取重要模式、趋势，并理解数据，即从数据中学习 机器学习-怎么学模型对要学习问题映射的假设（问题建模，确定假设空间） 模型分类数据标记 监督学习模型 无监督学习模型 数据分布参数模型 、 无参数模型 建模对象 判别模型 生成模型 策略从假设空间中学习/选择最优模型的准则（确定目标函数） 算法根据目标函数求解最优模型的具体计算方法（求解模型参数） 深度学习传统机器学习：人工设计特征 传统机器学习VS 深度学习 手动设计程序 手动设计特征 神经网络结构发展 深度学习的不能 连接主义 vs 符号主义 从对立到合作 连接主义+ 符号主义 算法模型分类根据有无监督，进行区分。对于有监督的情况，又可以分为分类和回归两类问题 定量输出称为回归，或者说是连续变量预测 定性输出称为分类，或者说是离散变量预测 无监督的情况下，有聚类和降维两种方法 线性分类器线性分类器就是用线性方程去拟合数据，在二维的情况下就是寻找一条直线，三维就是一个平面，更高维叫做超平面。寻找这个超平面的过程，其实就是求解所有权重参数的过程 学习过程 学习率学习率低的话，学习过程会比较缓慢，学习率较高的话，学习过程更快，但是会更加跳跃。如果学习率过高的话，可能越过了好的分界面，得到了比较差的结果，但是如果训练集还足够多，可以通过后续的学习，弥补这一步产生的不良影响，重新找到好的分界面，但是整个学习过程更加曲折。在某些情况下，学习率也不是一成不变的。 第一种情况，可以根据训练集的大小来调整学习率，如将学习率乘上1/N，N代表训练集的大小 第二种情况，可以在每次迭代的过程中调整学习率，基本的思路是，需要朝着最优值移动的距离越远，学习率就应该越大，距离越近，学习率就应该更小。用自适应的方法来调整学习率。但是在实际中，可能并不知道和最优值之间的距离，所以可以在每一次迭代的最后，使用估计的模型参数检查误差函数。如果相对于上一次迭代，错误率减少了，可以增大学习率，用5%作为增大的幅度，如果相对于上一次迭代，错误率增大了，也就是跳过了最优值，那么应该重新设置上一轮迭代的权重wi，并且减少学习率到之前的50% 多项式分类器 过拟合过拟合，高阶多项式为了避免犯任何错误，可能很深地切入了其他类的区域，会导致有些样本被错分 线性回归一元线性回归和线性分类器类似，都是用一条直线去拟合数据，高维的情况也是一样，寻找一个超平面来拟合数据，目的都是求解出这个超平面方程，也就是求解出所有的参数wi,和常数项b 但是求解的过程不同，线性回归的求解过程是通过引入均方误差来实现的，均方误差代表样本中所有点到直线的距离之和，w、b的选取应该使均方误差达到最小。通过对w求偏导，可以直接导出w和b的结果。 过程： 引入均方误差： 求解参数： 逻辑回归之所以叫逻辑回归，是因为用到了逻辑函数sigmoid，逻辑回归和svm有相似之处，都是根据已知的（xi，yi）这样的二元组，在空间上进行拟合，确定一条曲线，但是由于是分类问题，确定了曲线之后还需要阶跃函数，确定类标号，如果是二分类的话，根据（x,y）和曲线的位置关系，可以确定标号，阶跃函数为 z＜0，0，z＝0，0.5，z＞0，1，但是这个函数是不连续的，不利于计算优化，所以取sigmiod函数作为阶跃函数，sigmiod函数在＜0时取值大于0小于0.5，在＞0时，取值大于0.5小于1，所以只需要比较和0.5的关系即可。z的值越大，表明元组的空间位置距离分类面越远，他就越可能属于类1，所以图中z越大，函数值也就越接近1；同理，z越小，表明元组越不可能属于类1。 与线性回归区别逻辑回归用于分类，而不是回归。 线性回归模型中，输出一般是连续的，对于每一个x，都有一个对应的输出y。模型的定义域与值域都可以是无穷。 逻辑回归输入可以是连续的无穷，但是输出一般是离散的，通常只有{0，1} 支持向量机SVMsvm，支持向量机，既可用于回归又可用于分类 在深度学习出现之前，svm被认为是机器学习最好，最成功的算法 SVM是指将实例映射为二维中的点，以二分类举例的话，svm的目的就是画出一条线，来区分这两类点，理想的情况下，即使后来加入了新的点，这条线也能够进行很好的区分。理论上这条线有无数种画法，但他们有好坏的区分。期望的最理想的这条线叫做划分超平面，(叫做超平面是因为特征可能是高维的)。svm寻找可以区分两个类，并且使边际最大的超平面。边际指的是某一条线距离它两侧最近的点的距离之和。在边际最大的情况下，选取的平面应该是到两侧最近点距离相等的平面。 因为SVM要映射到高维空间，再来求分离超平面，但是这样的话，运算量会非常庞大，又因为上面的核函数和和映射到高维空间的解类似，所以求SVM分离超平面时，可以用求核函数方法代替在高维空间中计算，从而实现在一维平面上计算达到高维空间计算的效果 决策树 构建决策树]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[next主题Google验证]]></title>
    <url>%2F2019%2F02%2F23%2Fhexo-google-verify%2F</url>
    <content type="text"><![CDATA[Google验证urlhttps://www.google.com/webmasters 修改配置文件使用html标签验证，方法同baidu验证 在站点配置文件中添加 google_site_verification: 123xxxxxx321 使用hexo d提交，刷新页面，查看源代码，如果能看到一下内容，证明标签已经成功添加： 进行验证 添加sitemap添加sitemap]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>google</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo_image]]></title>
    <url>%2F2019%2F02%2F19%2Fhexo-image%2F</url>
    <content type="text"><![CDATA[hexo md文档添加图片修改站点配置文件post_asset_folder 字段置为true 修改后，当进入到/source/_posts 下使用 hexo n xxx 建立新的文章时，会自动生成一个相同命名的文件夹，用于存放文章中引用的图片等资源， 在md文档中引用时，使用相对路径 插件安装安装插件 使用命令 npm install https://github.com/CodeFalling/hexo-asset-image --save 保存预览hexo g hexo s]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
</search>
